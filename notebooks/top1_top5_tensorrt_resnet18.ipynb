{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bfee7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ torch_tensorrt imported successfully.\n",
      "Evaluation will run on: cuda\n",
      "✓ Simple evaluation function defined.\n",
      "🚀 Starting ResNet-18 Distilled+TRT Model Accuracy Evaluation (Simple Method)...\n",
      "\n",
      "Loading validation dataset with drop_last=True...\n",
      "✓ Dataset loaded. Evaluating on 3904/3923 images across 122 batches.\n",
      "⚠️ WARNING: 19 images from the last batch are being ignored.\n",
      "\n",
      "==================================================\n",
      "Processing Model: Distilled TRT FP32\n",
      "==================================================\n",
      "  -> Processing batch 122/122\n",
      "  -> ✅ (Incomplete) Result: Top-1 = 53.74%, Top-5 = 80.23%\n",
      "\n",
      "==================================================\n",
      "Processing Model: Distilled TRT FP16\n",
      "==================================================\n",
      "  -> Model identified as FP16. Input tensors will be converted to half-precision.\n",
      "  -> Processing batch 122/122\n",
      "  -> ✅ (Incomplete) Result: Top-1 = 53.79%, Top-5 = 80.23%\n",
      "\n",
      "\n",
      "==================================================\n",
      "📋 INITIAL (INCOMPLETE) ACCURACY REPORT\n",
      "==================================================\n",
      "             Model Top-1 Accuracy (%) Top-5 Accuracy (%)\n",
      "Distilled TRT FP32              53.74              80.23\n",
      "Distilled TRT FP16              53.79              80.23\n",
      "\n",
      "Analysis of the previous result:\n",
      "The `drop_last=True` approach is fast but inaccurate because it ignores the final batch of images.\n",
      "To get the true accuracy, we must evaluate all images. This requires 'padding' the last batch to match the static size required by the TensorRT engine.\n",
      "\n",
      "Defining a new, more robust evaluation function that handles this padding...\n",
      "\n",
      "✓ Robust evaluation function is now defined.\n",
      "🚀 Rerunning evaluation with the robust padding method to include all images...\n",
      "\n",
      "Loading validation dataset with drop_last=False to include all images...\n",
      "✓ Dataset loaded. Evaluating on all 3923 images across 123 batches.\n",
      "\n",
      "==================================================\n",
      "Processing Model: Distilled TRT FP32\n",
      "==================================================\n",
      "  -> Processing batch 123/123 (Padding from 19 to 32)\n",
      "\n",
      "  -> ✅ (Complete) Result: Top-1 = 53.785%, Top-5 = 80.270%\n",
      "\n",
      "==================================================\n",
      "Processing Model: Distilled TRT FP16\n",
      "==================================================\n",
      "  -> Processing batch 123/123 (Padding from 19 to 32)\n",
      "\n",
      "  -> ✅ (Complete) Result: Top-1 = 53.836%, Top-5 = 80.270%\n",
      "\n",
      "\n",
      "============================================================\n",
      "📋 FINAL & COMPLETE ACCURACY REPORT (ResNet-18 TRT)\n",
      "============================================================\n",
      "             Model Top-1 Accuracy (%) Top-5 Accuracy (%)\n",
      "Distilled TRT FP32             53.785             80.270\n",
      "Distilled TRT FP16             53.836             80.270\n",
      "\n",
      "🎉 Full evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "#                      IMPORTS AND SETUP\n",
    "# ===================================================================\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "# Imports for data loading and transformations\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check for torch_tensorrt installation\n",
    "try:\n",
    "    import torch_tensorrt\n",
    "    print(\"✓ torch_tensorrt imported successfully.\")\n",
    "except ImportError:\n",
    "    print(\"✗ WARNING: torch_tensorrt is not installed. This script may not work.\")\n",
    "\n",
    "# Set the primary device for evaluation\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Evaluation will run on: {DEVICE}\")\n",
    "\n",
    "if DEVICE.type == 'cpu':\n",
    "    print(\"⚠️ WARNING: TensorRT models are optimized for GPU. Running on CPU will be slow and is not a typical use case.\")\n",
    "# %%\n",
    "# ===================================================================\n",
    "#                        CONFIGURATION\n",
    "# ===================================================================\n",
    "\n",
    "# --- 1. SET THE PATH TO YOUR VALIDATION DATASET ---\n",
    "BASE_DIR = Path('/workspace')\n",
    "VALIDATION_DATA_PATH = BASE_DIR / 'imagenet-mini' / 'val'\n",
    "\n",
    "# --- 2. ‼️ MODEL PATHS FOR RESNET-18 TENSORRT MODELS ‼️ ---\n",
    "SAVED_MODELS_DIR = BASE_DIR / 'saved_models_and_logs'\n",
    "MODEL_PATHS = {\n",
    "    'Distilled TRT FP32': SAVED_MODELS_DIR / 'kd_tensorrt' / 'resnet18_distilled_trt_fp32.ts',\n",
    "    'Distilled TRT FP16': SAVED_MODELS_DIR / 'kd_tensorrt' / 'resnet18_distilled_trt_fp16.ts'\n",
    "}\n",
    "\n",
    "# --- 3. EVALUATION PARAMETERS ---\n",
    "# This batch size MUST match the static batch size used during TensorRT compilation.\n",
    "REQUIRED_BATCH_SIZE_FOR_TRT = 32\n",
    "NUM_WORKERS = 4 if DEVICE.type == 'cuda' else 0\n",
    "\n",
    "# --- 4. DATA TRANSFORMS ---\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# %%\n",
    "# ===================================================================\n",
    "#    CELL 3: ACCURACY EVALUATION FUNCTION (SIMPLE 'drop_last' VERSION)\n",
    "# ===================================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_accuracy_simple(model, model_name, data_loader, device):\n",
    "    \"\"\"\n",
    "    A simple evaluation function that assumes all batches are the same size.\n",
    "    This requires the DataLoader to use `drop_last=True`.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct_top1, correct_top5, total = 0, 0, 0\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    is_fp16 = 'FP16' in model_name.upper()\n",
    "    if is_fp16:\n",
    "        print(\"  -> Model identified as FP16. Input tensors will be converted to half-precision.\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        if is_fp16:\n",
    "            images = images.half()\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, pred = outputs.topk(k=5, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
    "\n",
    "        correct_top1 += correct[:1].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "        correct_top5 += correct[:5].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        print(f\"\\r  -> Processing batch {i+1}/{num_batches}\", end=\"\")\n",
    "            \n",
    "    print() # Newline after progress bar\n",
    "    top1_acc = (correct_top1 / total) * 100.0 if total > 0 else 0.0\n",
    "    top5_acc = (correct_top5 / total) * 100.0 if total > 0 else 0.0\n",
    "    return top1_acc, top5_acc\n",
    "\n",
    "print(\"✓ Simple evaluation function defined.\")\n",
    "# %%\n",
    "# ===================================================================\n",
    "#      CELL 4: MAIN EXECUTION (SIMPLE, FLAWED METHOD)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"🚀 Starting ResNet-18 Distilled+TRT Model Accuracy Evaluation (Simple Method)...\")\n",
    "\n",
    "print(f\"\\nLoading validation dataset with drop_last=True...\")\n",
    "if not VALIDATION_DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Validation data path not found: {VALIDATION_DATA_PATH}\")\n",
    "\n",
    "val_dataset_simple = ImageFolder(VALIDATION_DATA_PATH, eval_transforms)\n",
    "# NOTE: Using drop_last=True here for simplicity, but this is flawed.\n",
    "val_loader_simple = DataLoader(\n",
    "    val_dataset_simple,\n",
    "    batch_size=REQUIRED_BATCH_SIZE_FOR_TRT, # Batch size must match static TRT engine\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if DEVICE.type == 'cuda' else False,\n",
    "    drop_last=True  # <-- THE KEY FLAW\n",
    ")\n",
    "ignored_images = len(val_dataset_simple) % REQUIRED_BATCH_SIZE_FOR_TRT\n",
    "effective_images = len(val_dataset_simple) - ignored_images\n",
    "\n",
    "print(f\"✓ Dataset loaded. Evaluating on {effective_images}/{len(val_dataset_simple)} images across {len(val_loader_simple)} batches.\")\n",
    "print(f\"⚠️ WARNING: {ignored_images} images from the last batch are being ignored.\")\n",
    "\n",
    "# --- Evaluate Models with the simple function ---\n",
    "results_list_simple = []\n",
    "for model_name, model_path in MODEL_PATHS.items():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Processing Model: {model_name}\")\n",
    "    print(\"=\"*50)\n",
    "    if not model_path.exists():\n",
    "        print(f\"✗ ERROR: Model file not found at '{model_path}'. Skipping.\")\n",
    "        results_list_simple.append({'Model': model_name, 'Top-1 Accuracy (%)': 'File Not Found', 'Top-5 Accuracy (%)': 'File Not Found'})\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        model = torch.jit.load(model_path).to(DEVICE)\n",
    "        top1, top5 = evaluate_model_accuracy_simple(model, model_name, val_loader_simple, DEVICE)\n",
    "        print(f\"  -> ✅ (Incomplete) Result: Top-1 = {top1:.2f}%, Top-5 = {top5:.2f}%\")\n",
    "        results_list_simple.append({'Model': model_name, 'Top-1 Accuracy (%)': f\"{top1:.2f}\", 'Top-5 Accuracy (%)': f\"{top5:.2f}\"})\n",
    "    except Exception as e:\n",
    "        print(f\"✗ ERROR: An error occurred while processing {model_name}: {e}\")\n",
    "        results_list_simple.append({'Model': model_name, 'Top-1 Accuracy (%)': 'Evaluation Failed', 'Top-5 Accuracy (%)': 'Evaluation Failed'})\n",
    "    finally:\n",
    "        if 'model' in locals(): del model\n",
    "        gc.collect()\n",
    "        if DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "\n",
    "# --- Display Initial, Flawed Report ---\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"📋 INITIAL (INCOMPLETE) ACCURACY REPORT\")\n",
    "print(\"=\"*50)\n",
    "if results_list_simple:\n",
    "    results_df_simple = pd.DataFrame(results_list_simple)\n",
    "    print(results_df_simple.to_string(index=False))\n",
    "# %%\n",
    "# ===================================================================\n",
    "#    CELL 5: CORRECTING THE FLAW - EVALUATING ALL IMAGES\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\nAnalysis of the previous result:\")\n",
    "print(\"The `drop_last=True` approach is fast but inaccurate because it ignores the final batch of images.\")\n",
    "print(\"To get the true accuracy, we must evaluate all images. This requires 'padding' the last batch to match the static size required by the TensorRT engine.\")\n",
    "print(\"\\nDefining a new, more robust evaluation function that handles this padding...\\n\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_accuracy_robust(model, model_name, data_loader, device, required_batch_size):\n",
    "    \"\"\"\n",
    "    A robust evaluation function that handles static batch sizes by padding the last batch.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct_top1, correct_top5, total = 0, 0, 0\n",
    "    num_batches = len(data_loader)\n",
    "    is_fp16 = 'FP16' in model_name.upper()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        current_batch_size = images.shape[0]\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # --- PADDING LOGIC ---\n",
    "        if current_batch_size < required_batch_size:\n",
    "            print(f\"\\r  -> Processing batch {i+1}/{num_batches} (Padding from {current_batch_size} to {required_batch_size})\", end=\"\")\n",
    "            padding_tensor = torch.zeros(required_batch_size - current_batch_size, *images.shape[1:], device=device, dtype=images.dtype)\n",
    "            images = torch.cat((images, padding_tensor), dim=0)\n",
    "        else:\n",
    "             print(f\"\\r  -> Processing batch {i+1}/{num_batches}\", end=\"\")\n",
    "\n",
    "        if is_fp16:\n",
    "            images = images.half()\n",
    "\n",
    "        outputs = model(images)\n",
    "        outputs = outputs[:current_batch_size] # Slice to remove padding results\n",
    "\n",
    "        _, pred = outputs.topk(k=5, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
    "\n",
    "        correct_top1 += correct[:1].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "        correct_top5 += correct[:5].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(\"\\n\") # Newline after progress bar\n",
    "    top1_acc = (correct_top1 / total) * 100.0 if total > 0 else 0.0\n",
    "    top5_acc = (correct_top5 / total) * 100.0 if total > 0 else 0.0\n",
    "    return top1_acc, top5_acc\n",
    "\n",
    "print(\"✓ Robust evaluation function is now defined.\")\n",
    "# %%\n",
    "# ===================================================================\n",
    "#           CELL 6: RERUNNING EVALUATION (ROBUST METHOD)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"🚀 Rerunning evaluation with the robust padding method to include all images...\")\n",
    "\n",
    "if not VALIDATION_DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Validation data path not found: {VALIDATION_DATA_PATH}\")\n",
    "\n",
    "print(f\"\\nLoading validation dataset with drop_last=False to include all images...\")\n",
    "val_dataset_robust = ImageFolder(VALIDATION_DATA_PATH, eval_transforms)\n",
    "val_loader_robust = DataLoader(\n",
    "    val_dataset_robust,\n",
    "    batch_size=REQUIRED_BATCH_SIZE_FOR_TRT,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if DEVICE.type == 'cuda' else False,\n",
    "    drop_last=False # <-- THE FIX\n",
    ")\n",
    "print(f\"✓ Dataset loaded. Evaluating on all {len(val_dataset_robust)} images across {len(val_loader_robust)} batches.\")\n",
    "\n",
    "# --- Evaluate Models with the robust function ---\n",
    "results_list_robust = []\n",
    "for model_name, model_path in MODEL_PATHS.items():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Processing Model: {model_name}\")\n",
    "    print(\"=\"*50)\n",
    "    if not model_path.exists():\n",
    "        print(f\"✗ ERROR: Model file not found at '{model_path}'. Skipping.\")\n",
    "        results_list_robust.append({'Model': model_name, 'Top-1 Accuracy (%)': 'File Not Found', 'Top-5 Accuracy (%)': 'File Not Found'})\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        model = torch.jit.load(model_path).to(DEVICE)\n",
    "        top1, top5 = evaluate_model_accuracy_robust(model, model_name, val_loader_robust, DEVICE, REQUIRED_BATCH_SIZE_FOR_TRT)\n",
    "        print(f\"  -> ✅ (Complete) Result: Top-1 = {top1:.3f}%, Top-5 = {top5:.3f}%\")\n",
    "        results_list_robust.append({'Model': model_name, 'Top-1 Accuracy (%)': f\"{top1:.3f}\", 'Top-5 Accuracy (%)': f\"{top5:.3f}\"})\n",
    "    except Exception as e:\n",
    "        print(f\"✗ ERROR: An error occurred while processing {model_name}: {e}\")\n",
    "        results_list_robust.append({'Model': model_name, 'Top-1 Accuracy (%)': 'Evaluation Failed', 'Top-5 Accuracy (%)': 'Evaluation Failed'})\n",
    "    finally:\n",
    "        if 'model' in locals(): del model\n",
    "        gc.collect()\n",
    "        if DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "\n",
    "# --- Display Final, Correct Report ---\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"📋 FINAL & COMPLETE ACCURACY REPORT (ResNet-18 TRT)\")\n",
    "print(\"=\"*60)\n",
    "if results_list_robust:\n",
    "    results_df_robust = pd.DataFrame(results_list_robust)\n",
    "    print(results_df_robust.to_string(index=False))\n",
    "\n",
    "print(\"\\n🎉 Full evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba96f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
