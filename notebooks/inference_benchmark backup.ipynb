{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38fcf4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Notebook Setup: Imports completed ---\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import time\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import torch_pruning as tp\n",
    "import re\n",
    "\n",
    "print(\"--- Notebook Setup: Imports completed ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "ROOT_DIR = \"saved_models_and_logs\"\n",
    "OUTPUT_CSV_NB = \"model_advanced_inference_benchmark.csv\" # New output file name\n",
    "DEFAULT_NUM_CLASSES = 1000\n",
    "FIXED_NUM_CLASSES = 1000 # For model reconstruction consistency\n",
    "\n",
    "# --- BENCHMARKING Configuration ---\n",
    "# Using the parameters from your provided script\n",
    "DUMMY_INPUT_SHAPE = (32, 3, 224, 224) # Batch Size of 32 for higher throughput measurement\n",
    "NUM_WARMUP_RUNS = 1\n",
    "NUM_BENCHMARK_RUNS = 2\n",
    "\n",
    "# --- Device and Input Tensors ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "INPUT_TENSOR_CPU = torch.randn(DUMMY_INPUT_SHAPE)\n",
    "\n",
    "# Your list of models that are unstable on GPU\n",
    "GPU_UNSTABLE_QUANTIZED_MODELS = [\n",
    "    \"resnet18pretrained_distilled_quant_ptq_int8_perchannel_post\",\n",
    "    \"resnet18pretrained_distilled_quant_ptq_int8_pertensor_post\",\n",
    "    \"resnet18pretrained_distilled_quant_qat_int8_epochs8\",\n",
    "    \"resnet50_quant_ptq_int8_perchannel_post\",\n",
    "    \"resnet50_quant_ptq_int8_pertensor_post\",\n",
    "    \"resnet50_quant_qat_int8_epochs8\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4337f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Core model loading infrastructure is defined ---\n"
     ]
    }
   ],
   "source": [
    "# --- Helper: Model File ---\n",
    "def get_model_file_path_nb(experiment_path_str):\n",
    "    experiment_path = Path(experiment_path_str)\n",
    "    specific_model_file = experiment_path / \"model_final.pth\"\n",
    "    if specific_model_file.exists(): return str(specific_model_file)\n",
    "    pth_files = list(experiment_path.glob(\"*.pth\"))\n",
    "    if pth_files:\n",
    "        if any(\"baseline_ft_imagenetmini_final.pth\" in p.name for p in pth_files):\n",
    "            return str([p for p in pth_files if \"baseline_ft_imagenetmini_final.pth\" in p.name][0])\n",
    "        return str(pth_files[0])\n",
    "    return None\n",
    "\n",
    "# --- Model Definition and Pruning Application ---\n",
    "def get_base_resnet50_model_for_reconstruction_nb():\n",
    "    return models.resnet50(weights=None, num_classes=FIXED_NUM_CLASSES)\n",
    "\n",
    "def apply_structured_pruning_to_model_for_reconstruction_nb(model, example_inputs, rate, device_obj):\n",
    "    model.to(device_obj)\n",
    "    example_inputs = example_inputs.to(device_obj)\n",
    "    ignored_layers = [m for m in model.modules() if isinstance(m, nn.Linear) and m.out_features == FIXED_NUM_CLASSES]\n",
    "    pruner = tp.pruner.MagnitudePruner(\n",
    "        model=model, example_inputs=example_inputs, importance=tp.importance.MagnitudeImportance(p=1),\n",
    "        iterative_steps=1, pruning_ratio=rate, global_pruning=False, ignored_layers=ignored_layers\n",
    "    )\n",
    "    pruner.step()\n",
    "    return model\n",
    "\n",
    "def get_pruning_config_from_log_for_reconstruction_nb(log_file_path_str):\n",
    "    if not Path(log_file_path_str).exists(): return None\n",
    "    try:\n",
    "        with open(log_file_path_str, 'r') as f: log_data = json.load(f)\n",
    "        cfg = log_data.get('config_details', {})\n",
    "        if cfg.get('target_filter_pruning_rate_per_layer') is not None:\n",
    "            return {'type': 'one-shot', 'rate': float(cfg['target_filter_pruning_rate_per_layer'])}\n",
    "        if cfg.get('applied_step_rate_for_this_stage') is not None:\n",
    "            return {'type': 'iterative_step', 'rate': float(cfg['applied_step_rate_for_this_stage'])}\n",
    "    except Exception: return None\n",
    "    return None\n",
    "\n",
    "def _reconstruct_model_arch_and_load_weights_nb(model_path, device, pruning_config, exp_id=\"\"):\n",
    "    if not pruning_config: return None\n",
    "    reconstructed_model = get_base_resnet50_model_for_reconstruction_nb()\n",
    "    example_inputs = torch.randn(1, 3, 224, 224, device=device) # small tensor for reconstruction\n",
    "    try:\n",
    "        if pruning_config['type'] == 'one-shot':\n",
    "            reconstructed_model = apply_structured_pruning_to_model_for_reconstruction_nb(reconstructed_model, example_inputs, pruning_config['rate'], device)\n",
    "        elif pruning_config['type'] == 'iterative':\n",
    "            for rate in pruning_config.get('step_rates', []):\n",
    "                reconstructed_model = apply_structured_pruning_to_model_for_reconstruction_nb(reconstructed_model, example_inputs, rate, device)\n",
    "        else: return None\n",
    "        if reconstructed_model is None: return None\n",
    "        \n",
    "        state_dict = torch.load(model_path, map_location=device, weights_only=True)\n",
    "        if all(k.startswith('module.') for k in state_dict): state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "        reconstructed_model.load_state_dict(state_dict)\n",
    "        reconstructed_model.eval()\n",
    "        return reconstructed_model\n",
    "    except Exception as e:\n",
    "        print(f\"      ERROR in reconstruction for {exp_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Central Model Loading Function ---\n",
    "def load_model_for_experiment_nb(exp_info, all_experiments_df, target_device_str='cpu'):\n",
    "    model_path = exp_info.get('Model_File_Path')\n",
    "    exp_id = exp_info.get('Experiment_ID', 'Unknown_Exp')\n",
    "    if not model_path or not os.path.exists(model_path):\n",
    "        print(f\"      ERROR ({exp_id}): Model file not found at {model_path}\")\n",
    "        return None\n",
    "    device_to_load_on = torch.device(target_device_str)\n",
    "    \n",
    "    try: # Try JIT first\n",
    "        return torch.jit.load(model_path, map_location=device_to_load_on).eval()\n",
    "    except Exception: pass\n",
    "\n",
    "    if exp_info.get('Is_Structured_Pruning', False):\n",
    "        pruning_config = None\n",
    "        base_exp_name = exp_info.get('Base_Exp_Name_Iterative')\n",
    "        stage_num = exp_info.get('Stage_Num_Iterative')\n",
    "        if base_exp_name and stage_num is not None: # Iterative\n",
    "            stages_info = all_experiments_df[(all_experiments_df['Base_Exp_Name_Iterative'] == base_exp_name) & (all_experiments_df['Stage_Num_Iterative'] <= stage_num)].sort_values(by='Stage_Num_Iterative')\n",
    "            rates = [get_pruning_config_from_log_for_reconstruction_nb(row.get('Log_Path'))['rate'] for _, row in stages_info.iterrows()]\n",
    "            if rates: pruning_config = {'type': 'iterative', 'step_rates': rates}\n",
    "        else: # One-shot\n",
    "            pruning_config = get_pruning_config_from_log_for_reconstruction_nb(exp_info.get('Log_Path'))\n",
    "        \n",
    "        if pruning_config:\n",
    "            reconstructed = _reconstruct_model_arch_and_load_weights_nb(model_path, device_to_load_on, pruning_config, exp_id)\n",
    "            if reconstructed: return reconstructed\n",
    "\n",
    "    try: # Fallback to standard loading\n",
    "        base_arch = exp_info.get('Base_Model_Arch')\n",
    "        num_classes = exp_info.get('Num_Classes', DEFAULT_NUM_CLASSES)\n",
    "        if base_arch == \"ResNet18\": model_instance = models.resnet18(weights=None, num_classes=num_classes)\n",
    "        elif base_arch == \"ResNet50\": model_instance = models.resnet50(weights=None, num_classes=num_classes)\n",
    "        else: return None\n",
    "        \n",
    "        state_dict = torch.load(model_path, map_location=device_to_load_on)\n",
    "        if isinstance(state_dict, dict) and 'model_state_dict' in state_dict: state_dict = state_dict['model_state_dict']\n",
    "        if any(k.startswith('module.') for k in state_dict): state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "        model_instance.load_state_dict(state_dict)\n",
    "        return model_instance.to(device_to_load_on).eval()\n",
    "    except Exception as e:\n",
    "        print(f\"      ERROR ({exp_id}): Fallback loading failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"--- Core model loading infrastructure is defined ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a7da5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Discovering experiments in: saved_models_and_logs ---\n",
      "Skipping TensorRT directory: kd_tensorrt\n",
      "Skipping TensorRT directory: tensorrt\n",
      "--- Discovery finished. Found 23 non-TensorRT experiments. ---\n"
     ]
    }
   ],
   "source": [
    "def discover_experiments_nb():\n",
    "    print(f\"--- Discovering experiments in: {ROOT_DIR} ---\")\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        print(f\"ERROR: ROOT_DIR '{ROOT_DIR}' does not exist!\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    discovered_experiments = []\n",
    "    for cat_name in os.listdir(ROOT_DIR):\n",
    "        cat_path = os.path.join(ROOT_DIR, cat_name)\n",
    "        if not os.path.isdir(cat_path): continue\n",
    "        if cat_name.endswith(('_trt', 'tensorrt')):\n",
    "            print(f\"Skipping TensorRT directory: {cat_name}\")\n",
    "            continue\n",
    "\n",
    "        for exp_name in os.listdir(cat_path):\n",
    "            exp_path_str = os.path.join(cat_path, exp_name)\n",
    "            if not os.path.isdir(exp_path_str): continue\n",
    "            \n",
    "            base_arch = \"ResNet50\" if \"resnet50\" in exp_name.lower() else \"ResNet18\" if \"resnet18\" in exp_name.lower() else \"Unknown\"\n",
    "            model_file = get_model_file_path_nb(exp_path_str)\n",
    "            log_path = os.path.join(exp_path_str, \"log.json\")\n",
    "            \n",
    "            is_structured = \"pruning_structured\" in cat_name.lower()\n",
    "            base_exp_name_iter, stage_num_iter = None, None\n",
    "            if is_structured and (\"iterative\" in cat_name.lower() or \"_it_\" in exp_name.lower() or \"_stage\" in exp_name.lower()):\n",
    "                match = re.search(r\"(.+?)(?:_|-)(?:stage|s)(\\d+)\", exp_name.lower())\n",
    "                if match:\n",
    "                    base_exp_name_iter = match.group(1)\n",
    "                    stage_num_iter = int(match.group(2))\n",
    "\n",
    "            num_classes = DEFAULT_NUM_CLASSES\n",
    "            if os.path.exists(log_path):\n",
    "                try:\n",
    "                    with open(log_path, 'r') as f: log_data = json.load(f)\n",
    "                    num_classes = log_data.get('config_details', {}).get('num_classes', DEFAULT_NUM_CLASSES)\n",
    "                except Exception: pass\n",
    "            \n",
    "            exp_data = {\n",
    "                \"Experiment_ID\": exp_name, \"Experiment_Path\": exp_path_str, \"Log_Path\": log_path,\n",
    "                \"Model_File_Path\": model_file, \"Base_Model_Arch\": base_arch, \"Num_Classes\": num_classes,\n",
    "                \"Is_Structured_Pruning\": is_structured,\n",
    "                \"Base_Exp_Name_Iterative\": base_exp_name_iter, \"Stage_Num_Iterative\": stage_num_iter\n",
    "            }\n",
    "            discovered_experiments.append(exp_data)\n",
    "\n",
    "    df = pd.DataFrame(discovered_experiments)\n",
    "    if not df.empty:\n",
    "        df['Stage_Num_Iterative'] = pd.to_numeric(df['Stage_Num_Iterative'], errors='coerce')\n",
    "        df = df.set_index(\"Experiment_ID\", drop=False)\n",
    "    print(f\"--- Discovery finished. Found {len(df)} non-TensorRT experiments. ---\")\n",
    "    return df\n",
    "\n",
    "# Initialize/Re-initialize the global DataFrame\n",
    "results_df = discover_experiments_nb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6247973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Advanced benchmarking utilities are defined ---\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "#                      BENCHMARKING UTILITIES\n",
    "# ===================================================================\n",
    "def warm_up_model(model, input_tensor, device, num_warmup=NUM_WARMUP_RUNS):\n",
    "    \"\"\"Warms up the model for stable performance measurements.\"\"\"\n",
    "    model.to(device)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_warmup):\n",
    "            _ = model(input_tensor)\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "def benchmark_gpu(model, input_tensor_cpu, num_runs=NUM_BENCHMARK_RUNS, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Performs a detailed benchmark on the GPU, returning detailed statistics.\n",
    "    (This is your provided function, slightly adapted).\n",
    "    \"\"\"\n",
    "    print(f\"  -> Benchmarking '{model_name}' on GPU...\")\n",
    "    device_obj = torch.device(\"cuda\")\n",
    "    input_tensor = input_tensor_cpu.clone().to(device_obj)\n",
    "    model.to(device_obj)\n",
    "\n",
    "    # FP16 handling is not in your original file list, but this is good practice\n",
    "    if 'FP16' in model_name.upper():\n",
    "        print(\"     ... converting model and input to FP16.\")\n",
    "        model.half()\n",
    "        input_tensor = input_tensor.half()\n",
    "\n",
    "    warm_up_model(model, input_tensor, device_obj)\n",
    "    torch.cuda.reset_peak_memory_stats(device_obj)\n",
    "    \n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            start_event = torch.cuda.Event(enable_timing=True)\n",
    "            end_event = torch.cuda.Event(enable_timing=True)\n",
    "            start_event.record()\n",
    "            _ = model(input_tensor)\n",
    "            end_event.record()\n",
    "            torch.cuda.synchronize(device_obj)\n",
    "            times.append(start_event.elapsed_time(end_event)) # in milliseconds\n",
    "            \n",
    "    mem_used = torch.cuda.max_memory_allocated(device_obj) / 1024**2\n",
    "    times_ms = np.array(times)\n",
    "    stats = {\n",
    "        'mean_ms': np.mean(times_ms), \n",
    "        'std_ms': np.std(times_ms), \n",
    "        'median_ms': np.median(times_ms), \n",
    "        'throughput_fps': (1000 / np.mean(times_ms)) * input_tensor.shape[0], \n",
    "        'memory_mb': mem_used\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "def benchmark_cpu(model, input_tensor_cpu, num_runs=NUM_BENCHMARK_RUNS, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Performs a detailed benchmark on the CPU, mirroring the GPU function's output.\n",
    "    \"\"\"\n",
    "    print(f\"  -> Benchmarking '{model_name}' on CPU...\")\n",
    "    device_obj = torch.device(\"cpu\")\n",
    "    # Ensure model and tensor are float32 for CPU\n",
    "    model.to(device_obj).float()\n",
    "    input_tensor = input_tensor_cpu.clone().to(device_obj)\n",
    "\n",
    "    warm_up_model(model, input_tensor, device_obj)\n",
    "    \n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            start_time = time.perf_counter()\n",
    "            _ = model(input_tensor)\n",
    "            end_time = time.perf_counter()\n",
    "            times.append((end_time - start_time) * 1000) # convert to ms\n",
    "            \n",
    "    times_ms = np.array(times)\n",
    "    stats = {\n",
    "        'mean_ms': np.mean(times_ms), \n",
    "        'std_ms': np.std(times_ms), \n",
    "        'median_ms': np.median(times_ms), \n",
    "        'throughput_fps': (1000 / np.mean(times_ms)) * input_tensor.shape[0], \n",
    "        'memory_mb': \"N/A\" # Peak memory not easily tracked on CPU\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "print(\"--- Advanced benchmarking utilities are defined ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb2b56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== RUNNING BENCHMARK WITH INPUT SHAPE: (32, 3, 224, 224) ====================\n",
      "\n",
      "--- Processing: resnet18pretrained_distilled_quant_kmeans_256clusters_post ---\n",
      "  -> Benchmarking 'resnet18pretrained_distilled_quant_kmeans_256clusters_post' on CPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\Temp\\ipykernel_2924\\432790959.py:97: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device_to_load_on)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Benchmarking 'resnet18pretrained_distilled_quant_kmeans_256clusters_post' on GPU...\n",
      "\n",
      "--- Processing: resnet18pretrained_distilled_quant_ptq_int8_perchannel_post ---\n",
      "  -> Benchmarking 'resnet18pretrained_distilled_quant_ptq_int8_perchannel_post' on CPU...\n",
      "  -> Skipping GPU benchmark (known unstable model).\n",
      "\n",
      "--- Processing: resnet18pretrained_distilled_quant_ptq_int8_pertensor_post ---\n",
      "  -> Benchmarking 'resnet18pretrained_distilled_quant_ptq_int8_pertensor_post' on CPU...\n",
      "  -> Skipping GPU benchmark (known unstable model).\n",
      "\n",
      "--- Processing: resnet18pretrained_distilled_quant_qat_int8_epochs8 ---\n",
      "  -> Benchmarking 'resnet18pretrained_distilled_quant_qat_int8_epochs8' on CPU...\n",
      "  -> Skipping GPU benchmark (known unstable model).\n",
      "\n",
      "--- Processing: resnet50_to_resnet18pretrained_kd ---\n",
      "      ERROR (resnet50_to_resnet18pretrained_kd): Fallback loading failed: Error(s) in loading state_dict for ResNet:\n",
      "\tMissing key(s) in state_dict: \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\". \n",
      "\tsize mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
      "\tsize mismatch for fc.weight: copying a param with shape torch.Size([1000, 512]) from checkpoint, the shape in current model is torch.Size([1000, 2048]).\n",
      "     ... skipping CPU benchmark due to load failure.\n",
      "      ERROR (resnet50_to_resnet18pretrained_kd): Fallback loading failed: Error(s) in loading state_dict for ResNet:\n",
      "\tMissing key(s) in state_dict: \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\". \n",
      "\tsize mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
      "\tsize mismatch for fc.weight: copying a param with shape torch.Size([1000, 512]) from checkpoint, the shape in current model is torch.Size([1000, 2048]).\n",
      "     ... skipping GPU benchmark due to load failure.\n",
      "\n",
      "--- Processing: resnet50_to_resnet18scratch_kd ---\n",
      "      ERROR (resnet50_to_resnet18scratch_kd): Fallback loading failed: Error(s) in loading state_dict for ResNet:\n",
      "\tMissing key(s) in state_dict: \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\". \n",
      "\tsize mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
      "\tsize mismatch for fc.weight: copying a param with shape torch.Size([1000, 512]) from checkpoint, the shape in current model is torch.Size([1000, 2048]).\n",
      "     ... skipping CPU benchmark due to load failure.\n",
      "      ERROR (resnet50_to_resnet18scratch_kd): Fallback loading failed: Error(s) in loading state_dict for ResNet:\n",
      "\tMissing key(s) in state_dict: \"layer1.0.conv3.weight\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\". \n",
      "\tsize mismatch for layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n",
      "\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n",
      "\tsize mismatch for layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n",
      "\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n",
      "\tsize mismatch for layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
      "\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n",
      "\tsize mismatch for layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n",
      "\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n",
      "\tsize mismatch for fc.weight: copying a param with shape torch.Size([1000, 512]) from checkpoint, the shape in current model is torch.Size([1000, 2048]).\n",
      "     ... skipping GPU benchmark due to load failure.\n",
      "\n",
      "--- Processing: resnet50_prune_nm24_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_nm24_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_nm24_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_struct_os_l1filter_fp30_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_struct_os_l1filter_fp30_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_struct_os_l1filter_fp30_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_struct_os_l1filter_fp55_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_struct_os_l1filter_fp55_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_struct_os_l1filter_fp55_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_struct_os_l1filter_fp70_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_struct_os_l1filter_fp70_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_struct_os_l1filter_fp70_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_unstruct_it_l1_stage1_sp50_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_it_l1_stage1_sp50_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_it_l1_stage1_sp50_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_unstruct_it_l1_stage2_sp75_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_it_l1_stage2_sp75_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_it_l1_stage2_sp75_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_unstruct_it_l1_stage3_sp90_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_it_l1_stage3_sp90_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_it_l1_stage3_sp90_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_unstruct_os_l1_sp50_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_os_l1_sp50_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_os_l1_sp50_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_unstruct_os_l1_sp75_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_os_l1_sp75_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_os_l1_sp75_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_prune_unstruct_os_l1_sp90_ft ---\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_os_l1_sp90_ft' on CPU...\n",
      "  -> Benchmarking 'resnet50_prune_unstruct_os_l1_sp90_ft' on GPU...\n",
      "\n",
      "--- Processing: resnet50_quant_kmeans_256clusters_post ---\n",
      "  -> Benchmarking 'resnet50_quant_kmeans_256clusters_post' on CPU...\n",
      "  -> Benchmarking 'resnet50_quant_kmeans_256clusters_post' on GPU...\n",
      "\n",
      "--- Processing: resnet50_quant_ptq_int8_perchannel_post ---\n",
      "  -> Benchmarking 'resnet50_quant_ptq_int8_perchannel_post' on CPU...\n",
      "  -> Skipping GPU benchmark (known unstable model).\n",
      "\n",
      "--- Processing: resnet50_quant_ptq_int8_pertensor_post ---\n",
      "  -> Benchmarking 'resnet50_quant_ptq_int8_pertensor_post' on CPU...\n",
      "  -> Skipping GPU benchmark (known unstable model).\n",
      "\n",
      "--- Processing: resnet50_quant_qat_int8_epochs8 ---\n",
      "  -> Benchmarking 'resnet50_quant_qat_int8_epochs8' on CPU...\n",
      "  -> Skipping GPU benchmark (known unstable model).\n",
      "\n",
      "--- All Benchmarking Finished ---\n"
     ]
    }
   ],
   "source": [
    "if not results_df.empty:\n",
    "    print(f\"\\n{'='*20} RUNNING BENCHMARK WITH INPUT SHAPE: {DUMMY_INPUT_SHAPE} {'='*20}\")\n",
    "    \n",
    "    all_benchmark_results = []\n",
    "\n",
    "    for exp_id, row in results_df.iterrows():\n",
    "        print(f\"\\n--- Processing: {exp_id} ---\")\n",
    "        \n",
    "        # --- Run CPU Benchmark ---\n",
    "        try:\n",
    "            model_cpu = load_model_for_experiment_nb(row, results_df, target_device_str='cpu')\n",
    "            if model_cpu:\n",
    "                cpu_stats = benchmark_cpu(model_cpu, INPUT_TENSOR_CPU, model_name=exp_id)\n",
    "                cpu_stats['Experiment_ID'] = exp_id\n",
    "                cpu_stats['device'] = 'CPU'\n",
    "                all_benchmark_results.append(cpu_stats)\n",
    "                del model_cpu\n",
    "                gc.collect()\n",
    "            else:\n",
    "                print(\"     ... skipping CPU benchmark due to load failure.\")\n",
    "        except Exception as e:\n",
    "            print(f\"     ERROR during CPU benchmark for {exp_id}: {e}\")\n",
    "\n",
    "        # --- Run GPU Benchmark ---\n",
    "        if DEVICE.type == 'cuda':\n",
    "            if exp_id in GPU_UNSTABLE_QUANTIZED_MODELS:\n",
    "                print(\"  -> Skipping GPU benchmark (known unstable model).\")\n",
    "                continue\n",
    "            try:\n",
    "                # Reload model for GPU to ensure clean state and correct device placement\n",
    "                model_gpu = load_model_for_experiment_nb(row, results_df, target_device_str='cuda')\n",
    "                if model_gpu:\n",
    "                    gpu_stats = benchmark_gpu(model_gpu, INPUT_TENSOR_CPU, model_name=exp_id)\n",
    "                    gpu_stats['Experiment_ID'] = exp_id\n",
    "                    gpu_stats['device'] = 'GPU'\n",
    "                    all_benchmark_results.append(gpu_stats)\n",
    "                    del model_gpu\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                else:\n",
    "                    print(\"     ... skipping GPU benchmark due to load failure.\")\n",
    "            except Exception as e:\n",
    "                print(f\"     ERROR during GPU benchmark for {exp_id}: {e}\")\n",
    "                \n",
    "    # Create the final DataFrame from all collected results\n",
    "    final_results_df = pd.DataFrame(all_benchmark_results)\n",
    "    print(\"\\n--- All Benchmarking Finished ---\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame is empty. Nothing to benchmark.\")\n",
    "    final_results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81dd129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Benchmark Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Base_Model_Arch</th>\n",
       "      <th>device</th>\n",
       "      <th>mean_ms</th>\n",
       "      <th>median_ms</th>\n",
       "      <th>std_ms</th>\n",
       "      <th>throughput_fps</th>\n",
       "      <th>memory_mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>resnet50_prune_struct_it_l1filter_stage3_appro...</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>373.500</td>\n",
       "      <td>373.500</td>\n",
       "      <td>0.667</td>\n",
       "      <td>85.676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>resnet50_prune_struct_os_l1filter_fp70_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>373.940</td>\n",
       "      <td>373.940</td>\n",
       "      <td>0.462</td>\n",
       "      <td>85.575</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>CPU</td>\n",
       "      <td>620.041</td>\n",
       "      <td>620.041</td>\n",
       "      <td>22.564</td>\n",
       "      <td>51.609</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>CPU</td>\n",
       "      <td>626.923</td>\n",
       "      <td>626.923</td>\n",
       "      <td>25.852</td>\n",
       "      <td>51.043</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resnet18pretrained_distilled_quant_qat_int8_ep...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>CPU</td>\n",
       "      <td>639.530</td>\n",
       "      <td>639.530</td>\n",
       "      <td>23.374</td>\n",
       "      <td>50.037</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>resnet50_prune_struct_os_l1filter_fp55_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>669.311</td>\n",
       "      <td>669.311</td>\n",
       "      <td>1.226</td>\n",
       "      <td>47.810</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resnet50_prune_struct_it_l1filter_stage2_appro...</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>722.171</td>\n",
       "      <td>722.171</td>\n",
       "      <td>18.843</td>\n",
       "      <td>44.311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>CPU</td>\n",
       "      <td>795.614</td>\n",
       "      <td>795.614</td>\n",
       "      <td>4.292</td>\n",
       "      <td>40.221</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>resnet50_prune_struct_os_l1filter_fp30_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>1231.045</td>\n",
       "      <td>1231.045</td>\n",
       "      <td>12.973</td>\n",
       "      <td>25.994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>resnet50_prune_struct_it_l1filter_stage1_appro...</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>1232.246</td>\n",
       "      <td>1232.246</td>\n",
       "      <td>3.246</td>\n",
       "      <td>25.969</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>resnet50_quant_ptq_int8_perchannel_post</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>1423.300</td>\n",
       "      <td>1423.300</td>\n",
       "      <td>65.718</td>\n",
       "      <td>22.483</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>resnet50_quant_ptq_int8_pertensor_post</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>1450.143</td>\n",
       "      <td>1450.143</td>\n",
       "      <td>55.196</td>\n",
       "      <td>22.067</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>resnet50_quant_qat_int8_epochs8</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>1470.296</td>\n",
       "      <td>1470.296</td>\n",
       "      <td>59.680</td>\n",
       "      <td>21.764</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>resnet50_prune_unstruct_it_l1_stage1_sp50_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>2039.654</td>\n",
       "      <td>2039.654</td>\n",
       "      <td>4.467</td>\n",
       "      <td>15.689</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>resnet50_prune_unstruct_os_l1_sp50_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>2040.504</td>\n",
       "      <td>2040.504</td>\n",
       "      <td>16.464</td>\n",
       "      <td>15.682</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>resnet50_prune_unstruct_os_l1_sp90_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>2048.779</td>\n",
       "      <td>2048.779</td>\n",
       "      <td>11.888</td>\n",
       "      <td>15.619</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>resnet50_quant_kmeans_256clusters_post</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>2054.327</td>\n",
       "      <td>2054.327</td>\n",
       "      <td>14.872</td>\n",
       "      <td>15.577</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>resnet50_prune_unstruct_os_l1_sp75_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>2063.435</td>\n",
       "      <td>2063.435</td>\n",
       "      <td>9.711</td>\n",
       "      <td>15.508</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet50_prune_nm24_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>2065.116</td>\n",
       "      <td>2065.116</td>\n",
       "      <td>2.935</td>\n",
       "      <td>15.496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>resnet50_prune_unstruct_it_l1_stage3_sp90_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>2074.503</td>\n",
       "      <td>2074.503</td>\n",
       "      <td>8.602</td>\n",
       "      <td>15.425</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>resnet50_prune_unstruct_it_l1_stage2_sp75_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>CPU</td>\n",
       "      <td>2108.380</td>\n",
       "      <td>2108.380</td>\n",
       "      <td>55.910</td>\n",
       "      <td>15.178</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>resnet50_prune_struct_it_l1filter_stage3_appro...</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>12.315</td>\n",
       "      <td>12.315</td>\n",
       "      <td>0.151</td>\n",
       "      <td>2598.537</td>\n",
       "      <td>487.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>GPU</td>\n",
       "      <td>14.625</td>\n",
       "      <td>14.625</td>\n",
       "      <td>0.690</td>\n",
       "      <td>2187.992</td>\n",
       "      <td>268.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resnet50_prune_struct_it_l1filter_stage2_appro...</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>20.279</td>\n",
       "      <td>20.279</td>\n",
       "      <td>0.613</td>\n",
       "      <td>1577.959</td>\n",
       "      <td>514.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>resnet50_prune_struct_os_l1filter_fp30_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>31.023</td>\n",
       "      <td>31.023</td>\n",
       "      <td>0.853</td>\n",
       "      <td>1031.489</td>\n",
       "      <td>501.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>resnet50_prune_struct_it_l1filter_stage1_appro...</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>32.313</td>\n",
       "      <td>32.313</td>\n",
       "      <td>1.754</td>\n",
       "      <td>990.319</td>\n",
       "      <td>501.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>resnet50_prune_unstruct_it_l1_stage1_sp50_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>42.224</td>\n",
       "      <td>42.224</td>\n",
       "      <td>2.341</td>\n",
       "      <td>757.870</td>\n",
       "      <td>443.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>resnet50_prune_unstruct_os_l1_sp75_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>42.399</td>\n",
       "      <td>42.399</td>\n",
       "      <td>0.174</td>\n",
       "      <td>754.739</td>\n",
       "      <td>443.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet50_prune_unstruct_it_l1_stage3_sp90_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>43.006</td>\n",
       "      <td>43.006</td>\n",
       "      <td>2.536</td>\n",
       "      <td>744.083</td>\n",
       "      <td>443.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>resnet50_prune_unstruct_it_l1_stage2_sp75_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>43.587</td>\n",
       "      <td>43.587</td>\n",
       "      <td>0.027</td>\n",
       "      <td>734.171</td>\n",
       "      <td>443.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>resnet50_quant_kmeans_256clusters_post</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>44.134</td>\n",
       "      <td>44.134</td>\n",
       "      <td>1.181</td>\n",
       "      <td>725.058</td>\n",
       "      <td>443.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>resnet50_prune_unstruct_os_l1_sp90_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>44.172</td>\n",
       "      <td>44.172</td>\n",
       "      <td>0.369</td>\n",
       "      <td>724.444</td>\n",
       "      <td>443.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>resnet50_prune_unstruct_os_l1_sp50_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>44.507</td>\n",
       "      <td>44.507</td>\n",
       "      <td>2.224</td>\n",
       "      <td>718.994</td>\n",
       "      <td>443.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>resnet50_prune_nm24_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>44.910</td>\n",
       "      <td>44.910</td>\n",
       "      <td>1.365</td>\n",
       "      <td>712.543</td>\n",
       "      <td>443.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>resnet50_prune_struct_os_l1filter_fp70_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>48.784</td>\n",
       "      <td>48.784</td>\n",
       "      <td>3.322</td>\n",
       "      <td>655.954</td>\n",
       "      <td>316.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>resnet50_prune_struct_os_l1filter_fp55_ft</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>GPU</td>\n",
       "      <td>52.323</td>\n",
       "      <td>52.323</td>\n",
       "      <td>3.969</td>\n",
       "      <td>611.582</td>\n",
       "      <td>385.280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Experiment_ID Base_Model_Arch device  \\\n",
       "11  resnet50_prune_struct_it_l1filter_stage3_appro...        ResNet50    CPU   \n",
       "17          resnet50_prune_struct_os_l1filter_fp70_ft        ResNet50    CPU   \n",
       "3   resnet18pretrained_distilled_quant_ptq_int8_pe...        ResNet18    CPU   \n",
       "2   resnet18pretrained_distilled_quant_ptq_int8_pe...        ResNet18    CPU   \n",
       "4   resnet18pretrained_distilled_quant_qat_int8_ep...        ResNet18    CPU   \n",
       "15          resnet50_prune_struct_os_l1filter_fp55_ft        ResNet50    CPU   \n",
       "9   resnet50_prune_struct_it_l1filter_stage2_appro...        ResNet50    CPU   \n",
       "0   resnet18pretrained_distilled_quant_kmeans_256c...        ResNet18    CPU   \n",
       "13          resnet50_prune_struct_os_l1filter_fp30_ft        ResNet50    CPU   \n",
       "7   resnet50_prune_struct_it_l1filter_stage1_appro...        ResNet50    CPU   \n",
       "33            resnet50_quant_ptq_int8_perchannel_post        ResNet50    CPU   \n",
       "34             resnet50_quant_ptq_int8_pertensor_post        ResNet50    CPU   \n",
       "35                    resnet50_quant_qat_int8_epochs8        ResNet50    CPU   \n",
       "19       resnet50_prune_unstruct_it_l1_stage1_sp50_ft        ResNet50    CPU   \n",
       "25              resnet50_prune_unstruct_os_l1_sp50_ft        ResNet50    CPU   \n",
       "29              resnet50_prune_unstruct_os_l1_sp90_ft        ResNet50    CPU   \n",
       "31             resnet50_quant_kmeans_256clusters_post        ResNet50    CPU   \n",
       "27              resnet50_prune_unstruct_os_l1_sp75_ft        ResNet50    CPU   \n",
       "5                              resnet50_prune_nm24_ft        ResNet50    CPU   \n",
       "23       resnet50_prune_unstruct_it_l1_stage3_sp90_ft        ResNet50    CPU   \n",
       "21       resnet50_prune_unstruct_it_l1_stage2_sp75_ft        ResNet50    CPU   \n",
       "12  resnet50_prune_struct_it_l1filter_stage3_appro...        ResNet50    GPU   \n",
       "1   resnet18pretrained_distilled_quant_kmeans_256c...        ResNet18    GPU   \n",
       "10  resnet50_prune_struct_it_l1filter_stage2_appro...        ResNet50    GPU   \n",
       "14          resnet50_prune_struct_os_l1filter_fp30_ft        ResNet50    GPU   \n",
       "8   resnet50_prune_struct_it_l1filter_stage1_appro...        ResNet50    GPU   \n",
       "20       resnet50_prune_unstruct_it_l1_stage1_sp50_ft        ResNet50    GPU   \n",
       "28              resnet50_prune_unstruct_os_l1_sp75_ft        ResNet50    GPU   \n",
       "24       resnet50_prune_unstruct_it_l1_stage3_sp90_ft        ResNet50    GPU   \n",
       "22       resnet50_prune_unstruct_it_l1_stage2_sp75_ft        ResNet50    GPU   \n",
       "32             resnet50_quant_kmeans_256clusters_post        ResNet50    GPU   \n",
       "30              resnet50_prune_unstruct_os_l1_sp90_ft        ResNet50    GPU   \n",
       "26              resnet50_prune_unstruct_os_l1_sp50_ft        ResNet50    GPU   \n",
       "6                              resnet50_prune_nm24_ft        ResNet50    GPU   \n",
       "18          resnet50_prune_struct_os_l1filter_fp70_ft        ResNet50    GPU   \n",
       "16          resnet50_prune_struct_os_l1filter_fp55_ft        ResNet50    GPU   \n",
       "\n",
       "    mean_ms  median_ms  std_ms  throughput_fps  memory_mb  \n",
       "11  373.500    373.500   0.667          85.676        NaN  \n",
       "17  373.940    373.940   0.462          85.575        NaN  \n",
       "3   620.041    620.041  22.564          51.609        NaN  \n",
       "2   626.923    626.923  25.852          51.043        NaN  \n",
       "4   639.530    639.530  23.374          50.037        NaN  \n",
       "15  669.311    669.311   1.226          47.810        NaN  \n",
       "9   722.171    722.171  18.843          44.311        NaN  \n",
       "0   795.614    795.614   4.292          40.221        NaN  \n",
       "13 1231.045   1231.045  12.973          25.994        NaN  \n",
       "7  1232.246   1232.246   3.246          25.969        NaN  \n",
       "33 1423.300   1423.300  65.718          22.483        NaN  \n",
       "34 1450.143   1450.143  55.196          22.067        NaN  \n",
       "35 1470.296   1470.296  59.680          21.764        NaN  \n",
       "19 2039.654   2039.654   4.467          15.689        NaN  \n",
       "25 2040.504   2040.504  16.464          15.682        NaN  \n",
       "29 2048.779   2048.779  11.888          15.619        NaN  \n",
       "31 2054.327   2054.327  14.872          15.577        NaN  \n",
       "27 2063.435   2063.435   9.711          15.508        NaN  \n",
       "5  2065.116   2065.116   2.935          15.496        NaN  \n",
       "23 2074.503   2074.503   8.602          15.425        NaN  \n",
       "21 2108.380   2108.380  55.910          15.178        NaN  \n",
       "12   12.315     12.315   0.151        2598.537    487.483  \n",
       "1    14.625     14.625   0.690        2187.992    268.065  \n",
       "10   20.279     20.279   0.613        1577.959    514.761  \n",
       "14   31.023     31.023   0.853        1031.489    501.213  \n",
       "8    32.313     32.313   1.754         990.319    501.213  \n",
       "20   42.224     42.224   2.341         757.870    443.603  \n",
       "28   42.399     42.399   0.174         754.739    443.603  \n",
       "24   43.006     43.006   2.536         744.083    443.603  \n",
       "22   43.587     43.587   0.027         734.171    443.603  \n",
       "32   44.134     44.134   1.181         725.058    443.603  \n",
       "30   44.172     44.172   0.369         724.444    443.603  \n",
       "26   44.507     44.507   2.224         718.994    443.603  \n",
       "6    44.910     44.910   1.365         712.543    443.603  \n",
       "18   48.784     48.784   3.322         655.954    316.518  \n",
       "16   52.323     52.323   3.969         611.582    385.280  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Benchmark summary saved to model_advanced_inference_benchmark.csv ---\n",
      "\n",
      "--- Notebook processing finished ---\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "#                      CELL 6 (CORRECTED)\n",
    "# ===================================================================\n",
    "if not final_results_df.empty:\n",
    "    print(\"\\n--- Final Benchmark Results ---\")\n",
    "    \n",
    "    # Merge with original data to get Base_Model_Arch\n",
    "    # FIX: Use left_on and right_index to resolve the ambiguity\n",
    "    final_df_merged = pd.merge(\n",
    "        final_results_df,\n",
    "        results_df[['Base_Model_Arch']], # Only need the column we want to add\n",
    "        left_on='Experiment_ID',\n",
    "        right_index=True,\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Define the columns we want in our final output and their order\n",
    "    final_columns = [\n",
    "        'Experiment_ID', 'Base_Model_Arch', 'device', 'mean_ms', 'median_ms', 'std_ms',\n",
    "        'throughput_fps', 'memory_mb'\n",
    "    ]\n",
    "    \n",
    "    final_df_display = final_df_merged[final_columns].copy()\n",
    "\n",
    "    # Convert timing columns to numeric, making errors into 'NaN'\n",
    "    for col in ['mean_ms', 'median_ms', 'std_ms', 'throughput_fps', 'memory_mb']:\n",
    "        final_df_display[col] = pd.to_numeric(final_df_display[col], errors='coerce')\n",
    "\n",
    "    # Set display format for better readability\n",
    "    pd.options.display.float_format = '{:.3f}'.format\n",
    "    \n",
    "    # Sort by device, then by performance for easier comparison\n",
    "    display(final_df_display.sort_values(by=['device', 'throughput_fps'], ascending=[True, False]))\n",
    "    \n",
    "    # Save to CSV\n",
    "    try:\n",
    "        final_df_display.to_csv(OUTPUT_CSV_NB, index=False, float_format='%.5f')\n",
    "        print(f\"\\n--- Benchmark summary saved to {OUTPUT_CSV_NB} ---\")\n",
    "    except Exception as e_csv:\n",
    "        print(f\"Error saving CSV: {e_csv}\")\n",
    "else:\n",
    "    print(\"No benchmark results were generated. Nothing to save.\")\n",
    "\n",
    "print(\"\\n--- Notebook processing finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
