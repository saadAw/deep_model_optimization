{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries for notebook interaction\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Optional: Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format) # Format floats to 3 decimal places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a9565a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment processing script (using %run)...\n",
      "--- Metrics Generator Script Starting (v3 - Full) ---\n",
      "Using device: cuda\n",
      "--- Initializing... ---\n",
      "--- Pass 1: Processing Baselines to establish FLOPs/Params references ---\n",
      "\n",
      "--- Baseline references populated: {} ---\n",
      "\n",
      "--- Pass 2: Processing ALL other (non-baseline) experiments ---\n",
      "\n",
      "  Processing experiment: resnet18pretrained_distilled_quant_kmeans_256clusters_post from category 'combined_distilled_quantized'\n",
      "      WARNING (resnet18pretrained_distilled_quant_kmeans_256clusters_post): Baseline FLOPs/Params for ResNet18 not found for quantized model.\n",
      "\n",
      "  Processing experiment: resnet18pretrained_distilled_quant_ptq_int8_perchannel_post from category 'combined_distilled_quantized'\n",
      "      INFO (resnet18pretrained_distilled_quant_ptq_int8_perchannel_post): Attempting to set quantized engine to 'x86'.\n",
      "      ERROR (resnet18pretrained_distilled_quant_ptq_int8_perchannel_post): General torch.load also failed: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript, serialized code (most recent call last):\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 72, in __setstate__\n",
      "    self.groups = (state)[8]\n",
      "    self.padding_mode = (state)[9]\n",
      "    _7 = (self).set_weight_bias((state)[10], (state)[11], )\n",
      "          ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    self.scale = (state)[12]\n",
      "    self.zero_point = (state)[13]\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 94, in set_weight_bias\n",
      "      _13 = [_11, _12]\n",
      "      _14, _15, = dilation\n",
      "      _16 = ops.quantized.conv2d_prepack(w, b, _10, _13, [_14, _15], groups)\n",
      "            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "      self._packed_params = _16\n",
      "    else:\n",
      "\n",
      "Traceback of TorchScript, original code (most recent call last):\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 230, in __setstate__\n",
      "        self.groups = state[8]\n",
      "        self.padding_mode = state[9]\n",
      "        self.set_weight_bias(state[10], state[11])\n",
      "        ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "        self.scale = state[12]\n",
      "        self.zero_point = state[13]\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 568, in set_weight_bias\n",
      "    def set_weight_bias(self, w: torch.Tensor, b: Optional[torch.Tensor]) -> None:\n",
      "        if self.padding_mode == \"zeros\":\n",
      "            self._packed_params = torch.ops.quantized.conv2d_prepack(\n",
      "                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "                w, b, self.stride, self.padding, self.dilation, self.groups\n",
      "            )\n",
      "RuntimeError: Unsupported qscheme: per_channel_affine\n",
      "\n",
      "      FINAL ERROR (resnet18pretrained_distilled_quant_ptq_int8_perchannel_post): Could not prepare any model for measurement.\n",
      "\n",
      "  Processing experiment: resnet18pretrained_distilled_quant_ptq_int8_pertensor_post from category 'combined_distilled_quantized'\n",
      "      INFO (resnet18pretrained_distilled_quant_ptq_int8_pertensor_post): Attempting to set quantized engine to 'x86'.\n",
      "      ERROR (resnet18pretrained_distilled_quant_ptq_int8_pertensor_post): General torch.load also failed: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript, serialized code (most recent call last):\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 72, in __setstate__\n",
      "    self.groups = (state)[8]\n",
      "    self.padding_mode = (state)[9]\n",
      "    _7 = (self).set_weight_bias((state)[10], (state)[11], )\n",
      "          ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    self.scale = (state)[12]\n",
      "    self.zero_point = (state)[13]\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 94, in set_weight_bias\n",
      "      _13 = [_11, _12]\n",
      "      _14, _15, = dilation\n",
      "      _16 = ops.quantized.conv2d_prepack(w, b, _10, _13, [_14, _15], groups)\n",
      "            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "      self._packed_params = _16\n",
      "    else:\n",
      "\n",
      "Traceback of TorchScript, original code (most recent call last):\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 230, in __setstate__\n",
      "        self.groups = state[8]\n",
      "        self.padding_mode = state[9]\n",
      "        self.set_weight_bias(state[10], state[11])\n",
      "        ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "        self.scale = state[12]\n",
      "        self.zero_point = state[13]\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 568, in set_weight_bias\n",
      "    def set_weight_bias(self, w: torch.Tensor, b: Optional[torch.Tensor]) -> None:\n",
      "        if self.padding_mode == \"zeros\":\n",
      "            self._packed_params = torch.ops.quantized.conv2d_prepack(\n",
      "                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "                w, b, self.stride, self.padding, self.dilation, self.groups\n",
      "            )\n",
      "RuntimeError: Unsupported qscheme: per_channel_affine\n",
      "\n",
      "      FINAL ERROR (resnet18pretrained_distilled_quant_ptq_int8_pertensor_post): Could not prepare any model for measurement.\n",
      "\n",
      "  Processing experiment: resnet18pretrained_distilled_quant_qat_int8_epochs8 from category 'combined_distilled_quantized'\n",
      "      INFO (resnet18pretrained_distilled_quant_qat_int8_epochs8): Attempting to set quantized engine to 'x86'.\n",
      "      ERROR (resnet18pretrained_distilled_quant_qat_int8_epochs8): General torch.load also failed: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript, serialized code (most recent call last):\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 72, in __setstate__\n",
      "    self.groups = (state)[8]\n",
      "    self.padding_mode = (state)[9]\n",
      "    _7 = (self).set_weight_bias((state)[10], (state)[11], )\n",
      "          ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    self.scale = (state)[12]\n",
      "    self.zero_point = (state)[13]\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 94, in set_weight_bias\n",
      "      _13 = [_11, _12]\n",
      "      _14, _15, = dilation\n",
      "      _16 = ops.quantized.conv2d_prepack(w, b, _10, _13, [_14, _15], groups)\n",
      "            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "      self._packed_params = _16\n",
      "    else:\n",
      "\n",
      "Traceback of TorchScript, original code (most recent call last):\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 230, in __setstate__\n",
      "        self.groups = state[8]\n",
      "        self.padding_mode = state[9]\n",
      "        self.set_weight_bias(state[10], state[11])\n",
      "        ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "        self.scale = state[12]\n",
      "        self.zero_point = state[13]\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 568, in set_weight_bias\n",
      "    def set_weight_bias(self, w: torch.Tensor, b: Optional[torch.Tensor]) -> None:\n",
      "        if self.padding_mode == \"zeros\":\n",
      "            self._packed_params = torch.ops.quantized.conv2d_prepack(\n",
      "                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "                w, b, self.stride, self.padding, self.dilation, self.groups\n",
      "            )\n",
      "RuntimeError: Unsupported qscheme: per_channel_affine\n",
      "\n",
      "      FINAL ERROR (resnet18pretrained_distilled_quant_qat_int8_epochs8): Could not prepare any model for measurement.\n",
      "\n",
      "  Processing experiment: resnet50_to_resnet18pretrained_kd from category 'knowledge_distillation'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\serialization.py:1328: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing experiment: resnet50_to_resnet18scratch_kd from category 'knowledge_distillation'\n",
      "\n",
      "  Processing experiment: resnet50_prune_nm24_ft from category 'pruning_nm_sparsity'\n",
      "\n",
      "  Processing experiment: resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft from category 'pruning_structured_iterative'\n",
      "\n",
      "  Processing experiment: resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft from category 'pruning_structured_iterative'\n",
      "\n",
      "  Processing experiment: resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft from category 'pruning_structured_iterative'\n",
      "\n",
      "  Processing experiment: resnet50_prune_struct_os_l1filter_fp30_ft from category 'pruning_structured_oneshot'\n",
      "\n",
      "  Processing experiment: resnet50_prune_struct_os_l1filter_fp55_ft from category 'pruning_structured_oneshot'\n",
      "\n",
      "  Processing experiment: resnet50_prune_struct_os_l1filter_fp70_ft from category 'pruning_structured_oneshot'\n",
      "\n",
      "  Processing experiment: resnet50_prune_unstruct_it_l1_stage1_sp50_ft from category 'pruning_unstructured_iterative'\n",
      "\n",
      "  Processing experiment: resnet50_prune_unstruct_it_l1_stage2_sp75_ft from category 'pruning_unstructured_iterative'\n",
      "\n",
      "  Processing experiment: resnet50_prune_unstruct_it_l1_stage3_sp90_ft from category 'pruning_unstructured_iterative'\n",
      "\n",
      "  Processing experiment: resnet50_prune_unstruct_os_l1_sp50_ft from category 'pruning_unstructured_oneshot'\n",
      "\n",
      "  Processing experiment: resnet50_prune_unstruct_os_l1_sp75_ft from category 'pruning_unstructured_oneshot'\n",
      "\n",
      "  Processing experiment: resnet50_prune_unstruct_os_l1_sp90_ft from category 'pruning_unstructured_oneshot'\n",
      "\n",
      "  Processing experiment: resnet50_quant_kmeans_256clusters_post from category 'quantization_kmeans'\n",
      "      WARNING (resnet50_quant_kmeans_256clusters_post): Baseline FLOPs/Params for ResNet50 not found for quantized model.\n",
      "\n",
      "  Processing experiment: resnet50_quant_ptq_int8_perchannel_post from category 'quantization_ptq_int8'\n",
      "      INFO (resnet50_quant_ptq_int8_perchannel_post): Attempting to set quantized engine to 'x86'.\n",
      "      ERROR (resnet50_quant_ptq_int8_perchannel_post): General torch.load also failed: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript, serialized code (most recent call last):\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 72, in __setstate__\n",
      "    self.groups = (state)[8]\n",
      "    self.padding_mode = (state)[9]\n",
      "    _7 = (self).set_weight_bias((state)[10], (state)[11], )\n",
      "          ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    self.scale = (state)[12]\n",
      "    self.zero_point = (state)[13]\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 94, in set_weight_bias\n",
      "      _13 = [_11, _12]\n",
      "      _14, _15, = dilation\n",
      "      _16 = ops.quantized.conv2d_prepack(w, b, _10, _13, [_14, _15], groups)\n",
      "            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "      self._packed_params = _16\n",
      "    else:\n",
      "\n",
      "Traceback of TorchScript, original code (most recent call last):\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 230, in __setstate__\n",
      "        self.groups = state[8]\n",
      "        self.padding_mode = state[9]\n",
      "        self.set_weight_bias(state[10], state[11])\n",
      "        ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "        self.scale = state[12]\n",
      "        self.zero_point = state[13]\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 568, in set_weight_bias\n",
      "    def set_weight_bias(self, w: torch.Tensor, b: Optional[torch.Tensor]) -> None:\n",
      "        if self.padding_mode == \"zeros\":\n",
      "            self._packed_params = torch.ops.quantized.conv2d_prepack(\n",
      "                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "                w, b, self.stride, self.padding, self.dilation, self.groups\n",
      "            )\n",
      "RuntimeError: Unsupported qscheme: per_channel_affine\n",
      "\n",
      "      FINAL ERROR (resnet50_quant_ptq_int8_perchannel_post): Could not prepare any model for measurement.\n",
      "\n",
      "  Processing experiment: resnet50_quant_ptq_int8_pertensor_post from category 'quantization_ptq_int8'\n",
      "      INFO (resnet50_quant_ptq_int8_pertensor_post): Attempting to set quantized engine to 'x86'.\n",
      "      ERROR (resnet50_quant_ptq_int8_pertensor_post): General torch.load also failed: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript, serialized code (most recent call last):\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 72, in __setstate__\n",
      "    self.groups = (state)[8]\n",
      "    self.padding_mode = (state)[9]\n",
      "    _7 = (self).set_weight_bias((state)[10], (state)[11], )\n",
      "          ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    self.scale = (state)[12]\n",
      "    self.zero_point = (state)[13]\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 94, in set_weight_bias\n",
      "      _13 = [_11, _12]\n",
      "      _14, _15, = dilation\n",
      "      _16 = ops.quantized.conv2d_prepack(w, b, _10, _13, [_14, _15], groups)\n",
      "            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "      self._packed_params = _16\n",
      "    else:\n",
      "\n",
      "Traceback of TorchScript, original code (most recent call last):\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 230, in __setstate__\n",
      "        self.groups = state[8]\n",
      "        self.padding_mode = state[9]\n",
      "        self.set_weight_bias(state[10], state[11])\n",
      "        ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "        self.scale = state[12]\n",
      "        self.zero_point = state[13]\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 568, in set_weight_bias\n",
      "    def set_weight_bias(self, w: torch.Tensor, b: Optional[torch.Tensor]) -> None:\n",
      "        if self.padding_mode == \"zeros\":\n",
      "            self._packed_params = torch.ops.quantized.conv2d_prepack(\n",
      "                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "                w, b, self.stride, self.padding, self.dilation, self.groups\n",
      "            )\n",
      "RuntimeError: Unsupported qscheme: per_channel_affine\n",
      "\n",
      "      FINAL ERROR (resnet50_quant_ptq_int8_pertensor_post): Could not prepare any model for measurement.\n",
      "\n",
      "  Processing experiment: resnet50_quant_qat_int8_epochs8 from category 'quantization_qat_int8'\n",
      "      INFO (resnet50_quant_qat_int8_epochs8): Attempting to set quantized engine to 'x86'.\n",
      "      ERROR (resnet50_quant_qat_int8_epochs8): General torch.load also failed: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript, serialized code (most recent call last):\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 72, in __setstate__\n",
      "    self.groups = (state)[8]\n",
      "    self.padding_mode = (state)[9]\n",
      "    _7 = (self).set_weight_bias((state)[10], (state)[11], )\n",
      "          ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "    self.scale = (state)[12]\n",
      "    self.zero_point = (state)[13]\n",
      "  File \"code/__torch__/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py\", line 94, in set_weight_bias\n",
      "      _13 = [_11, _12]\n",
      "      _14, _15, = dilation\n",
      "      _16 = ops.quantized.conv2d_prepack(w, b, _10, _13, [_14, _15], groups)\n",
      "            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "      self._packed_params = _16\n",
      "    else:\n",
      "\n",
      "Traceback of TorchScript, original code (most recent call last):\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 230, in __setstate__\n",
      "        self.groups = state[8]\n",
      "        self.padding_mode = state[9]\n",
      "        self.set_weight_bias(state[10], state[11])\n",
      "        ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "        self.scale = state[12]\n",
      "        self.zero_point = state[13]\n",
      "  File \"C:\\Users\\Saad\\miniconda3\\envs\\dl-opt\\Lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\conv.py\", line 568, in set_weight_bias\n",
      "    def set_weight_bias(self, w: torch.Tensor, b: Optional[torch.Tensor]) -> None:\n",
      "        if self.padding_mode == \"zeros\":\n",
      "            self._packed_params = torch.ops.quantized.conv2d_prepack(\n",
      "                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "                w, b, self.stride, self.padding, self.dilation, self.groups\n",
      "            )\n",
      "RuntimeError: Unsupported qscheme: per_channel_affine\n",
      "\n",
      "      FINAL ERROR (resnet50_quant_qat_int8_epochs8): Could not prepare any model for measurement.\n",
      "\n",
      "--- Remeasured critical metrics saved to remeasured_critical_metrics_v3.csv ---\n",
      "\n",
      "First 5 rows of the remeasured metrics:\n",
      "                                                 Experiment_ID FLOPs_GMACs Params_Millions Inference_Time_ms_CPU (Batch 1) Inference_Time_ms_GPU (Batch 1)\n",
      "0   resnet18pretrained_distilled_quant_kmeans_256clusters_post        <NA>            <NA>                        40.35535                         3.35592\n",
      "1  resnet18pretrained_distilled_quant_ptq_int8_perchannel_post        <NA>            <NA>                            <NA>                            <NA>\n",
      "2   resnet18pretrained_distilled_quant_ptq_int8_pertensor_post        <NA>            <NA>                            <NA>                            <NA>\n",
      "3          resnet18pretrained_distilled_quant_qat_int8_epochs8        <NA>            <NA>                            <NA>                            <NA>\n",
      "4                            resnet50_to_resnet18pretrained_kd    1.824034       11.689512                        37.11543                         3.61753\n",
      "--- Metrics Generator Script Finished ---\n",
      "Script execution finished (using %run).\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Run the processing script\n",
    "print(\"Running experiment processing script (using %run)...\")\n",
    "%run metrics.py\n",
    "print(\"Script execution finished (using %run).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load and display the generated CSV\n",
    "csv_file_path = \"model_optimization_summary_uniform_eval.csv\"\n",
    "\n",
    "if os.path.exists(csv_file_path):\n",
    "    print(f\"\\nLoading data from {csv_file_path}...\")\n",
    "    df_summary = pd.read_csv(csv_file_path)\n",
    "\n",
    "    print(\"\\n--- DataFrame Head ---\")\n",
    "    display(df_summary.head())\n",
    "\n",
    "    print(\"\\n--- DataFrame Info ---\")\n",
    "    df_summary.info()\n",
    "\n",
    "    print(\"\\n--- DataFrame Description (Numerical Columns) ---\")\n",
    "    # Select numeric columns for describe, handling potential non-numeric inference times\n",
    "    numeric_cols = df_summary.select_dtypes(include=np.number).columns\n",
    "    display(df_summary[numeric_cols].describe())\n",
    "    \n",
    "    # Identify columns that were expected to be numeric but might have errors\n",
    "    potential_numeric_issues = []\n",
    "    for col in ['Final_Val_Accuracy', 'Model_Size_MB_Disk', 'Inference_Time_ms_CPU (Batch 1)']:\n",
    "         if df_summary[col].dtype == 'object': # if it's not numeric\n",
    "            try:\n",
    "                pd.to_numeric(df_summary[col]) # test conversion\n",
    "            except ValueError:\n",
    "                potential_numeric_issues.append(col)\n",
    "    if potential_numeric_issues:\n",
    "        print(f\"\\nWarning: Columns {potential_numeric_issues} contain non-numeric 'Measurement Error' or 'N/A' values.\")\n",
    "        print(\"Consider cleaning these (e.g., replacing with NaN) for numerical analysis/plotting if needed.\")\n",
    "        # Example: df_summary['Inference_Time_ms_CPU (Batch 1)'] = pd.to_numeric(df_summary['Inference_Time_ms_CPU (Batch 1)'], errors='coerce')\n",
    "\n",
    "\n",
    "else:\n",
    "    print(f\"Error: {csv_file_path} not found. Ensure the script ran successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Example Visualizations (add more as needed for your presentation)\n",
    "if 'df_summary' in locals() and not df_summary.empty:\n",
    "    print(\"\\n--- Example Visualizations ---\")\n",
    "    \n",
    "    # Convert relevant columns to numeric, coercing errors for plotting\n",
    "    plot_df = df_summary.copy()\n",
    "    cols_to_numeric = [\n",
    "        'Final_Val_Accuracy', 'Model_Size_MB_Disk', \n",
    "        'Inference_Time_ms_CPU (Batch 1)', 'Achieved_Sparsity_Percent',\n",
    "        'Accuracy_Change_vs_Baseline_pp', 'Model_Size_Reduction_vs_Baseline_Percent',\n",
    "        'Inference_Speedup_vs_Baseline_CPU'\n",
    "    ]\n",
    "    for col in cols_to_numeric:\n",
    "        if col in plot_df.columns:\n",
    "             plot_df[col] = pd.to_numeric(plot_df[col], errors='coerce')\n",
    "\n",
    "    # Filter out baselines for some plots to see effect of optimizations\n",
    "    optimized_df = plot_df[plot_df['Optimization_Category'] != 'Baseline'].copy()\n",
    "\n",
    "    # 1. Accuracy vs. Model Size\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=optimized_df, x='Model_Size_MB_Disk', y='Final_Val_Accuracy', hue='Optimization_Category', size='Inference_Time_ms_CPU (Batch 1)', style='Base_Model_Arch')\n",
    "    plt.title('Final Validation Accuracy vs. Model Size (MB on Disk)')\n",
    "    plt.xlabel('Model Size (MB)')\n",
    "    plt.ylabel('Final Validation Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Accuracy Retention vs. Model Size Reduction (for optimized models)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=optimized_df, x='Model_Size_Reduction_vs_Baseline_Percent', y='Accuracy_Retention_Percent', hue='Specific_Technique', style='Base_Model_Arch')\n",
    "    plt.title('Accuracy Retention vs. Model Size Reduction (Compared to Baseline)')\n",
    "    plt.xlabel('Model Size Reduction (%)')\n",
    "    plt.ylabel('Accuracy Retention (%)')\n",
    "    plt.axhline(100, color='gray', linestyle='--', label='100% Retention')\n",
    "    plt.axvline(0, color='gray', linestyle='--')\n",
    "    plt.grid(True)\n",
    "    plt.legend(title='Specific Technique', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Inference Speedup vs. Accuracy Change (CPU)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=optimized_df, x='Inference_Speedup_vs_Baseline_CPU', y='Accuracy_Change_vs_Baseline_pp', hue='Optimization_Category', style='Base_Model_Arch')\n",
    "    plt.title('CPU Inference Speedup vs. Accuracy Change (pp from Baseline)')\n",
    "    plt.xlabel('Inference Speedup (Factor over Baseline)')\n",
    "    plt.ylabel('Accuracy Change (Percentage Points)')\n",
    "    plt.axhline(0, color='gray', linestyle='--', label='No Accuracy Change')\n",
    "    plt.axvline(1, color='gray', linestyle='--', label='No Speedup')\n",
    "    plt.grid(True)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Bar plot of Final Accuracy by Specific Technique (Top N techniques)\n",
    "    if not optimized_df.empty:\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        # Sort by accuracy and take top N or all\n",
    "        top_techniques = optimized_df.groupby('Specific_Technique')['Final_Val_Accuracy'].mean().sort_values(ascending=False)\n",
    "        sns.barplot(x=top_techniques.index, y=top_techniques.values, palette=\"viridis\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.title('Average Final Validation Accuracy by Specific Technique')\n",
    "        plt.ylabel('Average Final Validation Accuracy')\n",
    "        plt.xlabel('Specific Technique')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame could not be loaded or is empty, skipping visualizations.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
