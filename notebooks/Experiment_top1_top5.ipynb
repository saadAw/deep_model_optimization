{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "new_cell_1_markdown",
   "metadata": {},
   "source": [
    "Cell 1: Imports and Global Configuration (Simplified for Accuracy Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "new_cell_1_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Notebook Setup: Imports completed ---\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import time # Still used by some loading/evaluation functions, though not for timing inference directly\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import torch_pruning as tp # Needed for structured pruning reconstruction\n",
    "import re\n",
    "import traceback # Keep for detailed error messages\n",
    "\n",
    "print(\"--- Notebook Setup: Imports completed ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "ROOT_DIR = \"saved_models_and_logs\" # Parent directory of your experiments\n",
    "OUTPUT_CSV_ACCURACY = \"model_accuracy_summary.csv\" # New CSV for accuracy results\n",
    "DEFAULT_NUM_CLASSES = 1000\n",
    "FIXED_NUM_CLASSES = 1000 # For model reconstruction consistency in structured pruning\n",
    "\n",
    "# --- Uniform Evaluation Configuration ---\n",
    "VALIDATION_DATA_PATH = \"imagenet-mini/val\" # MAKE SURE THIS PATH IS CORRECT\n",
    "BATCH_SIZE_EVAL = 32\n",
    "NUM_WORKERS_EVAL = 0 # Set to 0 for Windows or if issues, >0 for Linux if beneficial\n",
    "MAX_EVAL_BATCHES = 125 # Max batches for accuracy evaluation (set to float('inf') for all)\n",
    "\n",
    "# --- Device and Input Tensors ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# INPUT_TENSOR_CPU is needed for torch_pruning's example_inputs during reconstruction\n",
    "INPUT_TENSOR_CPU = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# List of models known to be unstable on GPU for evaluation (e.g. certain JIT quantized models)\n",
    "# Accuracy for these will be evaluated on CPU.\n",
    "GPU_UNSTABLE_QUANTIZED_MODELS = [\n",
    "    \"resnet18pretrained_distilled_quant_ptq_int8_perchannel_post\",\n",
    "    \"resnet18pretrained_distilled_quant_ptq_int8_pertensor_post\",\n",
    "    \"resnet18pretrained_distilled_quant_qat_int8_epochs8\",\n",
    "    \"resnet50_quant_ptq_int8_perchannel_post\",\n",
    "    \"resnet50_quant_ptq_int8_pertensor_post\",\n",
    "    \"resnet50_quant_qat_int8_epochs8\",\n",
    "]\n",
    "\n",
    "# --- DataFrame to store results ---\n",
    "accuracy_results_df = pd.DataFrame()\n",
    "current_eval_experiment_id_nb = \"\" # For logging within evaluate_model_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_cell_2_markdown",
   "metadata": {},
   "source": [
    "Cell 2: Core Helper Functions (Path, Pruning Reconstruction Logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "new_cell_2_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Helper functions for model path and reconstruction defined ---\n"
     ]
    }
   ],
   "source": [
    "# --- Helper: Image Transforms ---\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), normalize,\n",
    "])\n",
    "\n",
    "# --- Helper: Model File ---\n",
    "def get_model_file_path_nb(experiment_path_str):\n",
    "    experiment_path = Path(experiment_path_str)\n",
    "    specific_model_file = experiment_path / \"model_final.pth\"\n",
    "    if specific_model_file.exists():\n",
    "        return str(specific_model_file)\n",
    "    pth_files = list(experiment_path.glob(\"*.pth\"))\n",
    "    if pth_files:\n",
    "        for common_name in [\"model_quantized.pth\"]:\n",
    "            for p_file in pth_files:\n",
    "                if p_file.name == common_name: return str(p_file)\n",
    "        for p_file in pth_files:\n",
    "            if \"baseline_ft_imagenetmini_final.pth\" in p_file.name: return str(p_file)\n",
    "        return str(pth_files[0])\n",
    "    return None\n",
    "\n",
    "# --- Model Definition and Pruning Application (FROM SCRIPT 1, needed for structured pruning reconstruction) ---\n",
    "def get_base_resnet50_model_for_reconstruction_nb():\n",
    "    model = models.resnet50(weights=None, num_classes=FIXED_NUM_CLASSES)\n",
    "    return model\n",
    "\n",
    "def apply_structured_pruning_to_model_for_reconstruction_nb(\n",
    "    model_to_prune, example_inputs, target_pruning_rate_per_layer, device_obj\n",
    "):\n",
    "    model_to_prune.to(device_obj)\n",
    "    example_inputs = example_inputs.to(device_obj)\n",
    "    ignored_layers = []\n",
    "    for name, m in model_to_prune.named_modules():\n",
    "        if isinstance(m, nn.Linear) and m.out_features == FIXED_NUM_CLASSES:\n",
    "            ignored_layers.append(m)\n",
    "    try:\n",
    "        importance = tp.importance.MagnitudeImportance(p=1) # L1 norm\n",
    "        pruner = tp.pruner.MagnitudePruner(\n",
    "            model=model_to_prune, example_inputs=example_inputs, importance=importance,\n",
    "            iterative_steps=1, pruning_ratio=target_pruning_rate_per_layer,\n",
    "            global_pruning=False, ignored_layers=ignored_layers,\n",
    "        )\n",
    "        pruner.step()\n",
    "    except Exception as e_prune:\n",
    "        print(f\"      ERROR during tp.pruner.MagnitudePruner step (rate {target_pruning_rate_per_layer}): {e_prune}\")\n",
    "        return None # Indicate failure\n",
    "    return model_to_prune\n",
    "\n",
    "def get_pruning_config_from_log_for_reconstruction_nb(log_file_path_str):\n",
    "    log_file_path = Path(log_file_path_str)\n",
    "    if not log_file_path.exists(): return None\n",
    "    try:\n",
    "        with open(log_file_path, 'r') as f: log_data = json.load(f)\n",
    "        if 'config_details' in log_data and 'target_filter_pruning_rate_per_layer' in log_data['config_details']:\n",
    "            rate = log_data['config_details']['target_filter_pruning_rate_per_layer']\n",
    "            if rate is not None: return {'type': 'one-shot', 'rate': float(rate)}\n",
    "        if 'config_details' in log_data and 'applied_step_rate_for_this_stage' in log_data['config_details']:\n",
    "            rate = log_data['config_details']['applied_step_rate_for_this_stage']\n",
    "            if rate is not None: return {'type': 'iterative_step', 'rate': float(rate)}\n",
    "        if 'config_details' in log_data and 'target_overall_sparsity_approx_for_this_stage' in log_data['config_details']:\n",
    "            rate = log_data['config_details']['target_overall_sparsity_approx_for_this_stage']\n",
    "            if rate is not None: return {'type': 'iterative_step', 'rate': float(rate)}\n",
    "    except Exception as e:\n",
    "        print(f\"    Error processing log {log_file_path} for pruning config: {e}\")\n",
    "    return None\n",
    "\n",
    "def _reconstruct_model_arch_and_load_weights_nb(model_path_str, device_obj, pruning_config, exp_id_for_log=\"\"):\n",
    "    if not pruning_config: return None\n",
    "    reconstructed_model = get_base_resnet50_model_for_reconstruction_nb()\n",
    "    reconstructed_model.to(device_obj)\n",
    "    # INPUT_TENSOR_CPU is defined globally\n",
    "    example_inputs_local = INPUT_TENSOR_CPU.to(device_obj)\n",
    "    try:\n",
    "        if pruning_config['type'] == 'one-shot':\n",
    "            rate = pruning_config['rate']\n",
    "            reconstructed_model = apply_structured_pruning_to_model_for_reconstruction_nb(\n",
    "                reconstructed_model, example_inputs_local, rate, device_obj)\n",
    "        elif pruning_config['type'] == 'iterative':\n",
    "            step_rates = pruning_config.get('step_rates', [])\n",
    "            if not step_rates: return None\n",
    "            current_arch_model = reconstructed_model\n",
    "            for i, step_rate in enumerate(step_rates):\n",
    "                current_arch_model = apply_structured_pruning_to_model_for_reconstruction_nb(\n",
    "                    current_arch_model, example_inputs_local, step_rate, device_obj)\n",
    "                if current_arch_model is None: return None\n",
    "            reconstructed_model = current_arch_model\n",
    "        else: return None\n",
    "        if reconstructed_model is None: return None\n",
    "\n",
    "        state_dict = torch.load(model_path_str, map_location=device_obj, weights_only=True)\n",
    "        if all(key.startswith('module.') for key in state_dict.keys()):\n",
    "            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "        if 'model' in state_dict and isinstance(state_dict['model'], dict): state_dict = state_dict['model']\n",
    "        elif 'state_dict' in state_dict and isinstance(state_dict['state_dict'], dict): state_dict = state_dict['state_dict']\n",
    "        reconstructed_model.load_state_dict(state_dict)\n",
    "        reconstructed_model.eval()\n",
    "        return reconstructed_model\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR in _reconstruct_model_arch_and_load_weights_nb for {model_path_str} ({exp_id_for_log}): {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"--- Helper functions for model path and reconstruction defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_cell_3_markdown",
   "metadata": {},
   "source": [
    "Cell 3: Central Model Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "new_cell_3_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Central model loader defined ---\n"
     ]
    }
   ],
   "source": [
    "def load_model_for_experiment_nb(exp_info, all_experiments_df, target_device_str='cpu'):\n",
    "    model_path = exp_info.get('Model_File_Path')\n",
    "    base_arch = exp_info.get('Base_Model_Arch')\n",
    "    num_classes = exp_info.get('Num_Classes', DEFAULT_NUM_CLASSES)\n",
    "    is_structured = exp_info.get('Is_Structured_Pruning', False)\n",
    "    exp_id = exp_info.get('Experiment_ID', 'Unknown_Exp')\n",
    "\n",
    "    if not model_path or not os.path.exists(model_path) or os.path.getsize(model_path) == 0:\n",
    "        print(f\"      ERROR ({exp_id}): Model file invalid: {model_path}\")\n",
    "        return None\n",
    "\n",
    "    device_to_load_on = torch.device(target_device_str)\n",
    "    loaded_model = None\n",
    "    \n",
    "    try:\n",
    "        loaded_model = torch.jit.load(model_path, map_location=device_to_load_on)\n",
    "        loaded_model.eval()\n",
    "        return loaded_model\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if is_structured:\n",
    "        pruning_config_for_reconstruction = None\n",
    "        base_exp_name_iter = exp_info.get('Base_Exp_Name_Iterative')\n",
    "        stage_num_iter = exp_info.get('Stage_Num_Iterative')\n",
    "\n",
    "        if base_exp_name_iter and stage_num_iter is not None:\n",
    "            cumulative_step_rates = []\n",
    "            relevant_stages_info = all_experiments_df[\n",
    "                (all_experiments_df['Base_Exp_Name_Iterative'] == base_exp_name_iter) &\n",
    "                (all_experiments_df['Stage_Num_Iterative'] <= stage_num_iter) &\n",
    "                (all_experiments_df['Stage_Num_Iterative'].notna())\n",
    "            ].sort_values(by='Stage_Num_Iterative')\n",
    "            for _, stage_row in relevant_stages_info.iterrows():\n",
    "                stage_log_path = stage_row.get('Log_Path')\n",
    "                stage_log_pruning_info = get_pruning_config_from_log_for_reconstruction_nb(stage_log_path)\n",
    "                if stage_log_pruning_info and stage_log_pruning_info.get('type') == 'iterative_step':\n",
    "                    cumulative_step_rates.append(stage_log_pruning_info['rate'])\n",
    "                else:\n",
    "                    cumulative_step_rates = [] \n",
    "                    break \n",
    "            if cumulative_step_rates:\n",
    "                pruning_config_for_reconstruction = {'type': 'iterative', 'step_rates': cumulative_step_rates}\n",
    "        else: \n",
    "            log_path_current_exp = exp_info.get('Log_Path')\n",
    "            one_shot_pruning_info = get_pruning_config_from_log_for_reconstruction_nb(log_path_current_exp)\n",
    "            if one_shot_pruning_info and one_shot_pruning_info.get('type') == 'one-shot':\n",
    "                pruning_config_for_reconstruction = one_shot_pruning_info\n",
    "            elif one_shot_pruning_info and one_shot_pruning_info.get('type') == 'iterative_step':\n",
    "                 pruning_config_for_reconstruction = {'type': 'one-shot', 'rate': one_shot_pruning_info['rate']}\n",
    "\n",
    "        if pruning_config_for_reconstruction:\n",
    "            reconstructed = _reconstruct_model_arch_and_load_weights_nb(\n",
    "                model_path, device_to_load_on, pruning_config_for_reconstruction, exp_id)\n",
    "            if reconstructed:\n",
    "                reconstructed.eval()\n",
    "                return reconstructed\n",
    "            else:\n",
    "                 print(f\"      WARNING ({exp_id}): Failed structured reconstruction. Fallback attempt...\")\n",
    "        else:\n",
    "             print(f\"      WARNING ({exp_id}): No valid pruning_config for structured. Fallback attempt...\")\n",
    "\n",
    "    try:\n",
    "        _raw_loaded_content = torch.load(model_path, map_location=device_to_load_on, weights_only=False) # False needed if model saved directly\n",
    "        if isinstance(_raw_loaded_content, torch.nn.Module):\n",
    "            loaded_model = _raw_loaded_content\n",
    "        elif isinstance(_raw_loaded_content, dict):\n",
    "            if base_arch == \"ResNet18\": model_instance = models.resnet18(weights=None, num_classes=num_classes)\n",
    "            elif base_arch == \"ResNet50\": model_instance = models.resnet50(weights=None, num_classes=num_classes)\n",
    "            else:\n",
    "                print(f\"      ERROR ({exp_id}): Unknown base_arch '{base_arch}' for fallback state_dict load.\")\n",
    "                return None\n",
    "            state_dict = _raw_loaded_content\n",
    "            if any(k.startswith('module.') for k in state_dict.keys()):\n",
    "                state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "            if 'model' in state_dict and isinstance(state_dict['model'], dict): state_dict = state_dict['model']\n",
    "            elif 'state_dict' in state_dict and isinstance(state_dict['state_dict'], dict): state_dict = state_dict['state_dict']\n",
    "            model_instance.load_state_dict(state_dict)\n",
    "            loaded_model = model_instance\n",
    "        else: return None\n",
    "        \n",
    "        if loaded_model:\n",
    "            loaded_model.eval()\n",
    "            return loaded_model.to(device_to_load_on)\n",
    "    except Exception as e_load:\n",
    "        print(f\"      ERROR ({exp_id}): During fallback model loading: {str(e_load).splitlines()[0]}\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"      ERROR ({exp_id}): Model could not be loaded by any method.\")\n",
    "    return None\n",
    "\n",
    "print(\"--- Central model loader defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_cell_4_markdown",
   "metadata": {},
   "source": [
    "Cell 4: Experiment Discovery and DataFrame Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "new_cell_4_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Discovering experiments in: saved_models_and_logs ---\n",
      "--- Discovery finished. Found 25 experiments. ---\n",
      "\n",
      "--- Discovered Experiments Sample (columns relevant for loading/accuracy): ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Base_Model_Arch</th>\n",
       "      <th>Is_Structured_Pruning</th>\n",
       "      <th>Model_File_Path</th>\n",
       "      <th>Num_Classes</th>\n",
       "      <th>Base_Exp_Name_Iterative</th>\n",
       "      <th>Stage_Num_Iterative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>False</td>\n",
       "      <td>saved_models_and_logs\\resnet18_baseline\\resnet...</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>False</td>\n",
       "      <td>saved_models_and_logs\\resnet50_baseline\\resnet...</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>False</td>\n",
       "      <td>saved_models_and_logs\\combined_distilled_quant...</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>False</td>\n",
       "      <td>saved_models_and_logs\\combined_distilled_quant...</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>False</td>\n",
       "      <td>saved_models_and_logs\\combined_distilled_quant...</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                   Base_Model_Arch  \\\n",
       "Experiment_ID                                                        \n",
       "resnet18_baseline                                         ResNet18   \n",
       "resnet50_baseline                                         ResNet50   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...        ResNet18   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...        ResNet18   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...        ResNet18   \n",
       "\n",
       "                                                    Is_Structured_Pruning  \\\n",
       "Experiment_ID                                                               \n",
       "resnet18_baseline                                                   False   \n",
       "resnet50_baseline                                                   False   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                  False   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                  False   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                  False   \n",
       "\n",
       "                                                                                      Model_File_Path  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                   saved_models_and_logs\\resnet18_baseline\\resnet...   \n",
       "resnet50_baseline                                   saved_models_and_logs\\resnet50_baseline\\resnet...   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  saved_models_and_logs\\combined_distilled_quant...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  saved_models_and_logs\\combined_distilled_quant...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  saved_models_and_logs\\combined_distilled_quant...   \n",
       "\n",
       "                                                    Num_Classes  \\\n",
       "Experiment_ID                                                     \n",
       "resnet18_baseline                                          1000   \n",
       "resnet50_baseline                                          1000   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...         1000   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...         1000   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...         1000   \n",
       "\n",
       "                                                   Base_Exp_Name_Iterative  \\\n",
       "Experiment_ID                                                                \n",
       "resnet18_baseline                                                     None   \n",
       "resnet50_baseline                                                     None   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                    None   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                    None   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                    None   \n",
       "\n",
       "                                                    Stage_Num_Iterative  \n",
       "Experiment_ID                                                            \n",
       "resnet18_baseline                                                   NaN  \n",
       "resnet50_baseline                                                   NaN  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                  NaN  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                  NaN  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def discover_experiments_nb():\n",
    "    print(f\"--- Discovering experiments in: {ROOT_DIR} ---\")\n",
    "    discovered_experiments = []\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        print(f\"ERROR: ROOT_DIR '{ROOT_DIR}' does not exist!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Process baselines first\n",
    "    for cat_name_outer in os.listdir(ROOT_DIR):\n",
    "        cat_path_outer = os.path.join(ROOT_DIR, cat_name_outer)\n",
    "        if os.path.isdir(cat_path_outer) and (\"baseline\" in cat_name_outer.lower()):\n",
    "            exp_name = cat_name_outer\n",
    "            exp_path = cat_path_outer\n",
    "            base_arch = \"ResNet18\" if \"resnet18\" in exp_name.lower() else \"ResNet50\" if \"resnet50\" in exp_name.lower() else \"Unknown\"\n",
    "            model_file = get_model_file_path_nb(exp_path)\n",
    "            log_path = os.path.join(exp_path, \"log.json\")\n",
    "            num_classes, config_details = DEFAULT_NUM_CLASSES, {}\n",
    "            if os.path.exists(log_path):\n",
    "                try:\n",
    "                    with open(log_path, 'r') as f: log_data_temp = json.load(f)\n",
    "                    config_details = log_data_temp.get('config_details', {})\n",
    "                    num_classes = config_details.get('num_classes', DEFAULT_NUM_CLASSES)\n",
    "                except Exception as e: print(f\"  Warn: Log parsing error for baseline {exp_name}: {e}\")\n",
    "\n",
    "            exp_data = {\n",
    "                \"Experiment_ID\": exp_name, \"Experiment_Path\": exp_path, \"Log_Path\": log_path,\n",
    "                \"Model_File_Path\": model_file, \"Base_Model_Arch\": base_arch,\n",
    "                \"Is_Structured_Pruning\": False, \"Base_Exp_Name_Iterative\": None, \"Stage_Num_Iterative\": None,\n",
    "                \"Num_Classes\": num_classes,\n",
    "                \"Config_Details_From_Log\": config_details # Keep for num_classes, other potential debug\n",
    "                # No need for Training_Summary_From_Log or Original_Eval_Metrics_From_Log for accuracy only\n",
    "            }\n",
    "            discovered_experiments.append(exp_data)\n",
    "\n",
    "    # Process other experiments\n",
    "    for cat_name in os.listdir(ROOT_DIR):\n",
    "        cat_path = os.path.join(ROOT_DIR, cat_name)\n",
    "        if not os.path.isdir(cat_path) or \"baseline\" in cat_name.lower(): continue\n",
    "        is_cat_structured = \"pruning_structured\" in cat_name.lower()\n",
    "\n",
    "        for exp_name in os.listdir(cat_path):\n",
    "            exp_path_str = os.path.join(cat_path, exp_name)\n",
    "            if not os.path.isdir(exp_path_str): continue\n",
    "\n",
    "            base_arch = \"ResNet18\" if \"resnet18\" in exp_name.lower() else \"ResNet50\"\n",
    "            if cat_name == \"combined_distilled_quantized\" and \"resnet18\" in exp_name.lower(): base_arch = \"ResNet18\"\n",
    "\n",
    "            model_file = get_model_file_path_nb(exp_path_str)\n",
    "            log_path_str_current = os.path.join(exp_path_str, \"log.json\")\n",
    "            \n",
    "            current_exp_is_structured = is_cat_structured or \\\n",
    "                                       \"prune_struct_it\" in exp_name.lower() or \\\n",
    "                                       \"prune_struct_os\" in exp_name.lower() or \\\n",
    "                                       \"structured_l1_filter\" in exp_name.lower()\n",
    "            \n",
    "            base_exp_name_iterative, stage_num_iterative = None, None\n",
    "            if current_exp_is_structured and (\"iterative\" in cat_name.lower() or \"it\" in exp_name.lower() or \"_stage\" in exp_name.lower()):\n",
    "                match = re.search(r\"(.+?)(?:_|-)(?:stage|s)(\\d+)\", exp_name.lower())\n",
    "                if match:\n",
    "                    base_exp_name_iterative = match.group(1)\n",
    "                    stage_num_iterative = int(match.group(2))\n",
    "\n",
    "            num_classes, config_details = DEFAULT_NUM_CLASSES, {}\n",
    "            if os.path.exists(log_path_str_current):\n",
    "                try:\n",
    "                    with open(log_path_str_current, 'r') as f: log_data_temp = json.load(f)\n",
    "                    config_details = log_data_temp.get('config_details', {})\n",
    "                    num_classes = config_details.get('num_classes', DEFAULT_NUM_CLASSES)\n",
    "                    if 'student_config' in config_details and isinstance(config_details['student_config'], dict):\n",
    "                        num_classes = config_details['student_config'].get('num_classes', num_classes)\n",
    "                except Exception as e: print(f\"  Warn: Log parsing error for {exp_name}: {e}\")\n",
    "\n",
    "            exp_data = {\n",
    "                \"Experiment_ID\": exp_name, \"Experiment_Path\": exp_path_str, \"Log_Path\": log_path_str_current,\n",
    "                \"Model_File_Path\": model_file, \"Base_Model_Arch\": base_arch,\n",
    "                \"Is_Structured_Pruning\": current_exp_is_structured,\n",
    "                \"Base_Exp_Name_Iterative\": base_exp_name_iterative, \"Stage_Num_Iterative\": stage_num_iterative,      \n",
    "                \"Num_Classes\": num_classes,\n",
    "                \"Config_Details_From_Log\": config_details # Keep for num_classes and reconstruction logic\n",
    "            }\n",
    "            discovered_experiments.append(exp_data)\n",
    "\n",
    "    df = pd.DataFrame(discovered_experiments)\n",
    "    if not df.empty:\n",
    "        if 'Stage_Num_Iterative' in df.columns:\n",
    "             df['Stage_Num_Iterative'] = pd.to_numeric(df['Stage_Num_Iterative'], errors='coerce')\n",
    "        df = df.set_index(\"Experiment_ID\", drop=False)\n",
    "    print(f\"--- Discovery finished. Found {len(df)} experiments. ---\")\n",
    "    return df\n",
    "\n",
    "accuracy_results_df = discover_experiments_nb()\n",
    "if not accuracy_results_df.empty:\n",
    "    print(\"\\n--- Discovered Experiments Sample (columns relevant for loading/accuracy): ---\")\n",
    "    display_cols = ['Experiment_ID', 'Base_Model_Arch', 'Is_Structured_Pruning', 'Model_File_Path', 'Num_Classes']\n",
    "    # Add iterative info if present\n",
    "    if 'Base_Exp_Name_Iterative' in accuracy_results_df.columns: display_cols.append('Base_Exp_Name_Iterative')\n",
    "    if 'Stage_Num_Iterative' in accuracy_results_df.columns: display_cols.append('Stage_Num_Iterative')\n",
    "    display(accuracy_results_df[display_cols].head())\n",
    "else:\n",
    "    print(\"No experiments discovered. Check ROOT_DIR and folder structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_cell_5_markdown",
   "metadata": {},
   "source": [
    "Cell 5: Calculate Top-1 and Top-5 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "new_cell_5_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Model Accuracies (Top-1 and Top-5) ---\n",
      "  Processing Accuracy for: resnet18_baseline\n",
      "  Processing Accuracy for: resnet50_baseline\n",
      "  Processing Accuracy for: resnet18pretrained_distilled_quant_kmeans_256clusters_post\n",
      "  Processing Accuracy for: resnet18pretrained_distilled_quant_ptq_int8_perchannel_post\n",
      "      INFO (resnet18pretrained_distilled_quant_ptq_int8_perchannel_post): Known GPU unstable. Forcing CPU evaluation.\n",
      "  Processing Accuracy for: resnet18pretrained_distilled_quant_ptq_int8_pertensor_post\n",
      "      INFO (resnet18pretrained_distilled_quant_ptq_int8_pertensor_post): Known GPU unstable. Forcing CPU evaluation.\n",
      "  Processing Accuracy for: resnet18pretrained_distilled_quant_qat_int8_epochs8\n",
      "      INFO (resnet18pretrained_distilled_quant_qat_int8_epochs8): Known GPU unstable. Forcing CPU evaluation.\n",
      "  Processing Accuracy for: resnet50_to_resnet18pretrained_kd\n",
      "  Processing Accuracy for: resnet50_to_resnet18scratch_kd\n",
      "  Processing Accuracy for: resnet50_prune_nm24_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_os_l1filter_fp30_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_os_l1filter_fp55_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_os_l1filter_fp70_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_it_l1_stage1_sp50_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_it_l1_stage2_sp75_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_it_l1_stage3_sp90_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_os_l1_sp50_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_os_l1_sp75_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_os_l1_sp90_ft\n",
      "  Processing Accuracy for: resnet50_quant_kmeans_256clusters_post\n",
      "  Processing Accuracy for: resnet50_quant_ptq_int8_perchannel_post\n",
      "      INFO (resnet50_quant_ptq_int8_perchannel_post): Known GPU unstable. Forcing CPU evaluation.\n",
      "  Processing Accuracy for: resnet50_quant_ptq_int8_pertensor_post\n",
      "      INFO (resnet50_quant_ptq_int8_pertensor_post): Known GPU unstable. Forcing CPU evaluation.\n",
      "  Processing Accuracy for: resnet50_quant_qat_int8_epochs8\n",
      "      INFO (resnet50_quant_qat_int8_epochs8): Known GPU unstable. Forcing CPU evaluation.\n",
      "--- Accuracies calculated and stored. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Top1_Accuracy_Percent</th>\n",
       "      <th>Top5_Accuracy_Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>50.089217</td>\n",
       "      <td>76.319144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>64.950293</td>\n",
       "      <td>87.484068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>53.683406</td>\n",
       "      <td>80.321183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>50.879429</td>\n",
       "      <td>78.078002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>53.301045</td>\n",
       "      <td>80.270201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                    Top1_Accuracy_Percent  \\\n",
       "Experiment_ID                                                               \n",
       "resnet18_baseline                                               50.089217   \n",
       "resnet50_baseline                                               64.950293   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...              53.683406   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...              50.879429   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...              53.301045   \n",
       "\n",
       "                                                    Top5_Accuracy_Percent  \n",
       "Experiment_ID                                                              \n",
       "resnet18_baseline                                               76.319144  \n",
       "resnet50_baseline                                               87.484068  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...              80.321183  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...              78.078002  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...              80.270201  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_accuracies_nb(model, device_str_eval, num_classes_eval, max_batches_to_eval, exp_id_for_log):\n",
    "    global current_eval_experiment_id_nb\n",
    "    current_eval_experiment_id_nb = exp_id_for_log\n",
    "\n",
    "    if not os.path.exists(VALIDATION_DATA_PATH):\n",
    "        print(f\"      ERROR ({current_eval_experiment_id_nb}): Val data path not found: {VALIDATION_DATA_PATH}\")\n",
    "        return \"N/A (Val Data Missing)\", \"N/A (Val Data Missing)\"\n",
    "    try:\n",
    "        val_dataset = ImageFolder(VALIDATION_DATA_PATH, eval_transforms)\n",
    "        if len(val_dataset.classes) != num_classes_eval and num_classes_eval != FIXED_NUM_CLASSES:\n",
    "            # This warning is a bit noisy if model is 1000-class (ImageNet default) and dataset is also (ImageNet-mini has 1000 classes)\n",
    "            # More relevant if num_classes_eval is e.g. 100 for a fine-tuned model and val_dataset is full ImageNet.\n",
    "            # For now, assume FIXED_NUM_CLASSES (1000) is the standard for this dataset if model also has 1000 classes.\n",
    "            pass # print(f\"      INFO ({current_eval_experiment_id_nb}): Dataset classes ({len(val_dataset.classes)}) vs Model classes ({num_classes_eval}). Check consistency.\")\n",
    "        if len(val_dataset) == 0:\n",
    "            print(f\"      WARNING ({current_eval_experiment_id_nb}): Validation dataset at '{VALIDATION_DATA_PATH}' is empty.\")\n",
    "            return 0.0, 0.0\n",
    "        \n",
    "        current_num_workers = NUM_WORKERS_EVAL if DEVICE.type == 'cuda' else 0\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE_EVAL, shuffle=False,\n",
    "                                num_workers=current_num_workers, pin_memory=(True if device_str_eval=='cuda' else False))\n",
    "    except Exception as e:\n",
    "        print(f\"      ERROR ({current_eval_experiment_id_nb}): Could not load validation data: {e}\")\n",
    "        return f\"N/A (Val Data Load Error)\", f\"N/A (Val Data Load Error)\"\n",
    "\n",
    "    device_obj_eval = torch.device(device_str_eval)\n",
    "    model.to(device_obj_eval)\n",
    "    model.eval()\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    batches_processed = 0\n",
    "    \n",
    "    # print(f\"      INFO ({current_eval_experiment_id_nb}): Evaluating on {device_str_eval} for max {max_batches_to_eval} batches.\")\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        try:\n",
    "            images, labels = images.to(device_obj_eval), labels.to(device_obj_eval)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Determine k for top-k, ensuring k is not greater than the number of actual classes in the output\n",
    "            num_model_output_classes = outputs.size(1)\n",
    "            top_k_val = min(5, num_model_output_classes) # Max k is 5, or fewer if model has fewer classes\n",
    "            if top_k_val < 1: top_k_val = 1 # Should not happen with valid models\n",
    "\n",
    "            _, pred = outputs.topk(top_k_val, 1, True, True)\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
    "\n",
    "            correct_top1 += correct[:1].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "            if top_k_val >= 5: # Only sum up to 5 if available\n",
    "                 correct_top5 += correct[:5].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "            elif top_k_val > 0 : # if top_k_val is < 5, top_5 is effectively top_k_val\n",
    "                 correct_top5 += correct[:top_k_val].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            batches_processed += 1\n",
    "            if batches_processed >= max_batches_to_eval:\n",
    "                break\n",
    "        except Exception as e_batch:\n",
    "            print(f\"      ERROR ({current_eval_experiment_id_nb}) during batch {batches_processed} eval: {e_batch}\")\n",
    "            return \"N/A (Batch Eval Error)\", \"N/A (Batch Eval Error)\"\n",
    "\n",
    "    accuracy_top1 = (correct_top1 / total) * 100.0 if total > 0 else 0.0\n",
    "    accuracy_top5 = (correct_top5 / total) * 100.0 if total > 0 else 0.0\n",
    "    # print(f\"      INFO ({current_eval_experiment_id_nb}): Top-1 Acc = {accuracy_top1:.2f}%, Top-5 Acc = {accuracy_top5:.2f}%\")\n",
    "    return accuracy_top1, accuracy_top5\n",
    "\n",
    "def calculate_and_store_accuracies(df_to_update):\n",
    "    if df_to_update.empty:\n",
    "        print(\"Experiment DataFrame is empty. Run discovery cell first.\")\n",
    "        return\n",
    "    if not os.path.exists(VALIDATION_DATA_PATH):\n",
    "        print(f\"ERROR: Validation data path '{VALIDATION_DATA_PATH}' not found. Cannot calculate accuracy.\")\n",
    "        df_to_update['Top1_Accuracy_Percent'] = \"N/A (Val Data Missing)\"\n",
    "        df_to_update['Top5_Accuracy_Percent'] = \"N/A (Val Data Missing)\"\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Calculating Model Accuracies (Top-1 and Top-5) ---\")\n",
    "    top1_accuracies = {}\n",
    "    top5_accuracies = {}\n",
    "\n",
    "    for exp_id, row in df_to_update.iterrows():\n",
    "        print(f\"  Processing Accuracy for: {exp_id}\")\n",
    "        \n",
    "        is_gpu_unstable = exp_id in GPU_UNSTABLE_QUANTIZED_MODELS\n",
    "        eval_device_str = 'cpu' if is_gpu_unstable else DEVICE.type\n",
    "        if is_gpu_unstable and DEVICE.type == 'cuda': \n",
    "            print(f\"      INFO ({exp_id}): Known GPU unstable. Forcing CPU evaluation.\")\n",
    "\n",
    "        model_obj = load_model_for_experiment_nb(row, df_to_update, target_device_str=eval_device_str)\n",
    "        \n",
    "        current_top1_acc = \"N/A (Load Error)\"\n",
    "        current_top5_acc = \"N/A (Load Error)\"\n",
    "        if model_obj:\n",
    "            num_classes_for_eval = row.get('Num_Classes', DEFAULT_NUM_CLASSES)\n",
    "            current_top1_acc, current_top5_acc = evaluate_model_accuracies_nb(\n",
    "                model_obj, eval_device_str, num_classes_for_eval, MAX_EVAL_BATCHES, exp_id\n",
    "            )\n",
    "            del model_obj\n",
    "            if DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        top1_accuracies[exp_id] = current_top1_acc\n",
    "        top5_accuracies[exp_id] = current_top5_acc\n",
    "\n",
    "    df_to_update['Top1_Accuracy_Percent'] = pd.Series(top1_accuracies)\n",
    "    df_to_update['Top5_Accuracy_Percent'] = pd.Series(top5_accuracies)\n",
    "    print(\"--- Accuracies calculated and stored. ---\")\n",
    "    display(df_to_update[['Experiment_ID', 'Top1_Accuracy_Percent', 'Top5_Accuracy_Percent']].head())\n",
    "\n",
    "if not accuracy_results_df.empty:\n",
    "    calculate_and_store_accuracies(accuracy_results_df)\n",
    "else:\n",
    "    print(\"Skipping accuracy calculation as no experiments were discovered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_cell_6_markdown",
   "metadata": {},
   "source": [
    "Cell 6: Final Review and Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "new_cell_6_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Accuracy DataFrame Review (First 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Top1_Accuracy_Percent</th>\n",
       "      <th>Top5_Accuracy_Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>50.0892</td>\n",
       "      <td>76.3191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>64.9503</td>\n",
       "      <td>87.4841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>53.6834</td>\n",
       "      <td>80.3212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>50.8794</td>\n",
       "      <td>78.0780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>53.3010</td>\n",
       "      <td>80.2702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                    Top1_Accuracy_Percent  \\\n",
       "Experiment_ID                                                               \n",
       "resnet18_baseline                                                 50.0892   \n",
       "resnet50_baseline                                                 64.9503   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                53.6834   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                50.8794   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                53.3010   \n",
       "\n",
       "                                                    Top5_Accuracy_Percent  \n",
       "Experiment_ID                                                              \n",
       "resnet18_baseline                                                 76.3191  \n",
       "resnet50_baseline                                                 87.4841  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                80.3212  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                78.0780  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                80.2702  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Accuracy summary saved to model_accuracy_summary.csv ---\n",
      "Total experiments processed: 25\n",
      "\n",
      "--- Notebook processing for accuracy finished ---\n"
     ]
    }
   ],
   "source": [
    "if not accuracy_results_df.empty:\n",
    "    print(\"\\n--- Final Accuracy DataFrame Review (First 5 rows) ---\")\n",
    "    \n",
    "    # Define columns for the final CSV output\n",
    "    output_columns = ['Experiment_ID', 'Top1_Accuracy_Percent', 'Top5_Accuracy_Percent']\n",
    "    \n",
    "    # Ensure these columns exist, coercing to numeric for consistent display/saving\n",
    "    for col in ['Top1_Accuracy_Percent', 'Top5_Accuracy_Percent']:\n",
    "        if col in accuracy_results_df.columns:\n",
    "            accuracy_results_df[col] = pd.to_numeric(accuracy_results_df[col], errors='coerce')\n",
    "        else:\n",
    "            accuracy_results_df[col] = pd.NA # Add column if missing\n",
    "\n",
    "    # Set float_format for display and CSV saving\n",
    "    pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "    # Display the relevant columns\n",
    "    display(accuracy_results_df[output_columns].head())\n",
    "    \n",
    "    # Save to CSV\n",
    "    try:\n",
    "        # Select only the desired columns for saving\n",
    "        accuracy_results_df_to_save = accuracy_results_df[output_columns]\n",
    "        accuracy_results_df_to_save.to_csv(OUTPUT_CSV_ACCURACY, index=False, lineterminator='\\n', float_format='%.5f')\n",
    "        print(f\"\\n--- Accuracy summary saved to {OUTPUT_CSV_ACCURACY} ---\")\n",
    "        print(f\"Total experiments processed: {len(accuracy_results_df_to_save)}\")\n",
    "    except Exception as e_csv:\n",
    "        print(f\"Error saving CSV: {e_csv}\")\n",
    "else:\n",
    "    print(\"Accuracy DataFrame is empty. Nothing to save.\")\n",
    "\n",
    "print(\"\\n--- Notebook processing for accuracy finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
