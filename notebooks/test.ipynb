{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "620a24ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.bias', 'fc.weight'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\Temp\\ipykernel_12096\\2492164618.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "checkpoint_path = '../saved_models_and_logs/pruning_unstructured_iterative/resnet50_pruned_90_iterative_l1_ft.pth'\n",
    "if os.path.exists(checkpoint_path):\n",
    "\tcheckpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\tprint(checkpoint.keys())\n",
    "\t# This will show you the top-level keys in the saved dictionary,\n",
    "\t# e.g., dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'loss'])\n",
    "else:\n",
    "\tprint(f\"File not found: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cfcf1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing directory: ../saved_models_and_logs/pruning_unstructured_iterative/resnet50_prune_unstruct_it_l1_stage3_sp90_ft ---\n",
      "  Found one model file: model_final.pth\n",
      "  Selected checkpoint for processing: model_final.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\Temp\\ipykernel_19020\\2667900925.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(original_checkpoint_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saving extracted model_state_dict to: ../saved_models_and_logs/pruning_unstructured_iterative/resnet50_prune_unstruct_it_l1_stage3_sp90_ft\\model_final.pth\n",
      "  Successfully saved lean model to ../saved_models_and_logs/pruning_unstructured_iterative/resnet50_prune_unstruct_it_l1_stage3_sp90_ft\\model_final.pth\n",
      "  Overwrote 'model_final.pth' with its lean version.\n",
      "\n",
      "Successfully processed: ../saved_models_and_logs/pruning_unstructured_iterative/resnet50_prune_unstruct_it_l1_stage3_sp90_ft\n",
      "\n",
      "--- Script finished ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob\n",
    "\n",
    "MODEL_STATE_DICT_KEY = 'model_state_dict' # Based on your dict_keys\n",
    "TARGET_MODEL_FILENAME = \"model_final.pth\" # The desired final lean model name\n",
    "\n",
    "def process_single_checkpoint_dir(dir_path):\n",
    "    \"\"\"\n",
    "    Loads a checkpoint from dir_path, extracts the model_state_dict,\n",
    "    saves it as TARGET_MODEL_FILENAME, and optionally deletes the original.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(dir_path):\n",
    "        print(f\"Error: Directory not found: {dir_path}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"--- Processing directory: {dir_path} ---\")\n",
    "\n",
    "    # Find existing model/checkpoint files (.pth or .pt)\n",
    "    potential_checkpoints = glob.glob(os.path.join(dir_path, \"*.pth\")) + \\\n",
    "                            glob.glob(os.path.join(dir_path, \"*.pt\"))\n",
    "\n",
    "    original_checkpoint_path = None\n",
    "\n",
    "    if not potential_checkpoints:\n",
    "        print(f\"  Warning: No .pth or .pt file found in {dir_path}. Skipping.\")\n",
    "        return False\n",
    "\n",
    "    # Logic to select the checkpoint to process:\n",
    "    # If model_final.pth exists and is a checkpoint, process it.\n",
    "    # Otherwise, if only one other .pth/.pt file, process it.\n",
    "    # If multiple, ask user or pick one (for now, let's try to be smart or ask)\n",
    "    target_path_if_exists = os.path.join(dir_path, TARGET_MODEL_FILENAME)\n",
    "\n",
    "    if len(potential_checkpoints) == 1:\n",
    "        original_checkpoint_path = potential_checkpoints[0]\n",
    "        print(f\"  Found one model file: {os.path.basename(original_checkpoint_path)}\")\n",
    "    elif target_path_if_exists in potential_checkpoints:\n",
    "        original_checkpoint_path = target_path_if_exists\n",
    "        print(f\"  Found existing '{TARGET_MODEL_FILENAME}', will attempt to process it.\")\n",
    "    else:\n",
    "        # Filter out the target filename if it exists as a non-checkpoint (e.g., already processed)\n",
    "        candidates = [p for p in potential_checkpoints if os.path.basename(p) != TARGET_MODEL_FILENAME]\n",
    "        if len(candidates) == 1:\n",
    "            original_checkpoint_path = candidates[0]\n",
    "            print(f\"  Found one candidate checkpoint: {os.path.basename(original_checkpoint_path)}\")\n",
    "        elif len(candidates) > 1:\n",
    "            print(f\"  Multiple potential checkpoint files found (excluding '{TARGET_MODEL_FILENAME}'):\")\n",
    "            for i, p_path in enumerate(candidates):\n",
    "                print(f\"    {i}: {os.path.basename(p_path)}\")\n",
    "            while True:\n",
    "                try:\n",
    "                    choice = int(input(f\"  Please enter the number of the checkpoint to process: \"))\n",
    "                    if 0 <= choice < len(candidates):\n",
    "                        original_checkpoint_path = candidates[choice]\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"  Invalid choice.\")\n",
    "                except ValueError:\n",
    "                    print(\"  Invalid input. Please enter a number.\")\n",
    "        elif not candidates and target_path_if_exists in potential_checkpoints:\n",
    "             # This case means only model_final.pth exists, and it was found in potential_checkpoints\n",
    "             original_checkpoint_path = target_path_if_exists\n",
    "             print(f\"  Only '{TARGET_MODEL_FILENAME}' found. Will attempt to process it (in case it's a full checkpoint).\")\n",
    "        else: # No clear candidate\n",
    "            print(f\"  Warning: Could not automatically determine a unique checkpoint file to process among: {[os.path.basename(p) for p in potential_checkpoints]}.\")\n",
    "            print(f\"  Skipping this directory. Please ensure there's a clear checkpoint file or clean up existing files.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    if not original_checkpoint_path:\n",
    "        print(f\"  No checkpoint selected or found for processing. Skipping.\")\n",
    "        return False\n",
    "\n",
    "    print(f\"  Selected checkpoint for processing: {os.path.basename(original_checkpoint_path)}\")\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(original_checkpoint_path, map_location='cpu')\n",
    "\n",
    "        if not isinstance(checkpoint, dict) or MODEL_STATE_DICT_KEY not in checkpoint:\n",
    "            # Check if it's already the target file and just a state_dict (already processed)\n",
    "            if os.path.basename(original_checkpoint_path) == TARGET_MODEL_FILENAME and \\\n",
    "               not isinstance(checkpoint, dict) and \\\n",
    "               isinstance(checkpoint, (dict, torch.nn.Module)): # state_dict is a dict, or it could be a whole model\n",
    "                print(f\"  '{TARGET_MODEL_FILENAME}' seems to be already a lean model/state_dict. No action needed for this file.\")\n",
    "                return True # Indicate success as it's already in desired state\n",
    "            else:\n",
    "                print(f\"  Error: Loaded file '{os.path.basename(original_checkpoint_path)}' is not a recognized checkpoint dictionary (missing '{MODEL_STATE_DICT_KEY}' or not a dict).\")\n",
    "                print(f\"  Type of loaded data: {type(checkpoint)}\")\n",
    "                return False\n",
    "\n",
    "        model_state_dict = checkpoint[MODEL_STATE_DICT_KEY]\n",
    "        new_model_path = os.path.join(dir_path, TARGET_MODEL_FILENAME)\n",
    "\n",
    "        print(f\"  Saving extracted model_state_dict to: {new_model_path}\")\n",
    "        torch.save(model_state_dict, new_model_path)\n",
    "        print(f\"  Successfully saved lean model to {new_model_path}\")\n",
    "\n",
    "        # --- Decision to delete the original large checkpoint ---\n",
    "        if os.path.abspath(original_checkpoint_path) != os.path.abspath(new_model_path):\n",
    "            user_choice = input(f\"  Delete original large checkpoint '{os.path.basename(original_checkpoint_path)}'? (yes/no): \").strip().lower()\n",
    "            if user_choice == 'yes':\n",
    "                os.remove(original_checkpoint_path)\n",
    "                print(f\"  Deleted original large checkpoint: {os.path.basename(original_checkpoint_path)}\")\n",
    "            else:\n",
    "                print(f\"  Original checkpoint '{os.path.basename(original_checkpoint_path)}' was NOT deleted.\")\n",
    "        elif os.path.abspath(original_checkpoint_path) == os.path.abspath(new_model_path) and isinstance(checkpoint, dict):\n",
    "             print(f\"  Overwrote '{TARGET_MODEL_FILENAME}' with its lean version.\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {original_checkpoint_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- How to use ---\n",
    "if __name__ == \"__main__\":\n",
    "    # **IMPORTANT**: Replace this with the actual path to the directory you want to process\n",
    "    # Example paths (use only one at a time by uncommenting):\n",
    "\n",
    "    # path_to_process = \"saved_models_and_logs/pruning_unstructured_iterative/resnet50_prune_unstruct_it_l1_stage1_sp50_ft\"\n",
    "    # path_to_process = \"saved_models_and_logs/pruning_unstructured_iterative/resnet50_prune_unstruct_it_l1_stage2_sp75_ft\"\n",
    "    # path_to_process = \"saved_models_and_logs/pruning_unstructured_iterative/resnet50_prune_unstruct_it_l1_stage3_sp90_ft\"\n",
    "\n",
    "    # --- SET THE PATH HERE ---\n",
    "    path_to_process = '../saved_models_and_logs/pruning_unstructured_iterative/resnet50_prune_unstruct_it_l1_stage3_sp90_ft' # <--- *** PASTE YOUR DIRECTORY PATH HERE ***\n",
    "\n",
    "    if not path_to_process:\n",
    "        print(\"Please set the 'path_to_process' variable in the script.\")\n",
    "    else:\n",
    "        success = process_single_checkpoint_dir(path_to_process)\n",
    "        if success:\n",
    "            print(f\"\\nSuccessfully processed: {path_to_process}\")\n",
    "        else:\n",
    "            print(f\"\\nProcessing encountered issues for: {path_to_process}\")\n",
    "\n",
    "    print(\"\\n--- Script finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eacc826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n"
     ]
    }
   ],
   "source": [
    "# ============== Notebook Cell 1: Imports (No custom model definition needed here now) ==============\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import os\n",
    "import glob\n",
    "from collections import OrderedDict # To inspect keys easily\n",
    "import shutil # For safely moving the original file\n",
    "from torchvision import models # <--- IMPORT TORCHVISION MODELS\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9df8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Notebook Cell 2: Configuration and Helper Function ==============\n",
    "MODEL_STATE_DICT_KEY_IN_CHECKPOINT = 'model_state_dict'\n",
    "TARGET_LEAN_MODEL_FILENAME = \"model_final.pth\" # This will be the name of the cleaned model\n",
    "\n",
    "def clean_pruned_model_in_directory(directory_path, model_architecture_instance_factory, num_classes_for_model): # num_classes_for_model is passed here\n",
    "    \"\"\"\n",
    "    Processes a checkpoint in the given directory to make pruning permanent.\n",
    "    Saves a lean model and backs up the original.\n",
    "    model_architecture_instance_factory is a function that returns a new model instance e.g. lambda actual_num_classes: models.resnet50(num_classes=actual_num_classes)\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(directory_path):\n",
    "        print(f\"❌ Error: Directory not found: {directory_path}\")\n",
    "        return False\n",
    "    print(f\"\\nProcessing Directory: {directory_path}\")\n",
    "    potential_files = glob.glob(os.path.join(directory_path, \"*.pth\")) + \\\n",
    "                      glob.glob(os.path.join(directory_path, \"*.pt\"))\n",
    "    checkpoint_to_process_path = None\n",
    "    if not potential_files:\n",
    "        print(f\"  🟡 Warning: No .pth or .pt files found in {directory_path}.\")\n",
    "        return False\n",
    "\n",
    "    if len(potential_files) == 1:\n",
    "        checkpoint_to_process_path = potential_files[0]\n",
    "    else:\n",
    "        print(\"  Multiple files found. Please select the checkpoint to process:\")\n",
    "        candidates = []\n",
    "        for i, f_path in enumerate(potential_files):\n",
    "            fname = os.path.basename(f_path)\n",
    "            fsize_mb = os.path.getsize(f_path) / (1024 * 1024)\n",
    "            print(f\"    {i}: {fname} ({fsize_mb:.2f} MB)\")\n",
    "            candidates.append(f_path)\n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"  Enter the number of the file to process: \"))\n",
    "                if 0 <= choice < len(candidates):\n",
    "                    checkpoint_to_process_path = candidates[choice]\n",
    "                    break\n",
    "                else: print(\"    Invalid choice.\")\n",
    "            except ValueError: print(\"    Invalid input.\")\n",
    "    if not checkpoint_to_process_path:\n",
    "        print(\"  No file selected.\"); return False\n",
    "\n",
    "    original_filename_to_backup = os.path.basename(checkpoint_to_process_path)\n",
    "    print(f\"  Selected for processing: {original_filename_to_backup}\")\n",
    "    lean_model_save_path = os.path.join(directory_path, TARGET_LEAN_MODEL_FILENAME)\n",
    "    backup_file_path = os.path.join(directory_path, f\"{os.path.splitext(original_filename_to_backup)[0]}_full_checkpoint_backup{os.path.splitext(original_filename_to_backup)[1]}\")\n",
    "\n",
    "    if os.path.exists(backup_file_path) and os.path.basename(checkpoint_to_process_path) != TARGET_LEAN_MODEL_FILENAME:\n",
    "        print(f\"  🟡 Backup file '{os.path.basename(backup_file_path)}' already exists for '{original_filename_to_backup}'.\")\n",
    "        if input(f\"     Reprocess '{original_filename_to_backup}' anyway? (yes/no): \").strip().lower() != 'yes':\n",
    "            print(\"     Skipping reprocessing.\"); return True\n",
    "    try:\n",
    "        print(f\"  Loading checkpoint: {checkpoint_to_process_path}...\")\n",
    "        full_checkpoint_data = torch.load(checkpoint_to_process_path, map_location='cpu') # Load to CPU\n",
    "        model_state_dict_from_checkpoint = None\n",
    "        if isinstance(full_checkpoint_data, dict) and MODEL_STATE_DICT_KEY_IN_CHECKPOINT in full_checkpoint_data:\n",
    "            model_state_dict_from_checkpoint = full_checkpoint_data[MODEL_STATE_DICT_KEY_IN_CHECKPOINT]\n",
    "        elif isinstance(full_checkpoint_data, (OrderedDict, dict)): # If it's already a state_dict\n",
    "            model_state_dict_from_checkpoint = full_checkpoint_data\n",
    "        else:\n",
    "            print(f\"  ❌ Error: Loaded file type not recognized: {type(full_checkpoint_data)}\"); return False\n",
    "\n",
    "        # Create a new, clean model instance for this operation\n",
    "        # Call the factory with the num_classes_for_model value positionally\n",
    "        current_model_instance = model_architecture_instance_factory(num_classes_for_model) # <--- CORRECTED CALL\n",
    "        print(f\"  Created a new model instance (e.g., resnet50 with num_classes={num_classes_for_model}).\")\n",
    "\n",
    "\n",
    "        print(\"  Loading state_dict into model instance (strict=False)...\")\n",
    "        cleaned_sd_for_loading = OrderedDict()\n",
    "        has_module_prefix = any(k.startswith('module.') for k in model_state_dict_from_checkpoint.keys())\n",
    "        if has_module_prefix:\n",
    "            print(\"  Detected 'module.' prefix in state_dict keys, removing it...\")\n",
    "            for k, v in model_state_dict_from_checkpoint.items():\n",
    "                name = k[7:] if k.startswith('module.') else k\n",
    "                cleaned_sd_for_loading[name] = v\n",
    "        else:\n",
    "            cleaned_sd_for_loading = model_state_dict_from_checkpoint\n",
    "        \n",
    "        current_model_instance.load_state_dict(cleaned_sd_for_loading, strict=False)\n",
    "\n",
    "\n",
    "        print(\"  Making pruning permanent by applying prune.remove()...\")\n",
    "        for module_name, module_obj in current_model_instance.named_modules():\n",
    "            for param_name_to_check in ['weight', 'bias']:\n",
    "                try:\n",
    "                    if hasattr(module_obj, param_name_to_check + \"_orig\"):\n",
    "                        prune.remove(module_obj, param_name_to_check)\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "                except Exception as e_prune:\n",
    "                    pass\n",
    "        print(\"  Pruning removal process completed.\")\n",
    "        \n",
    "        final_cleaned_state_dict = current_model_instance.state_dict()\n",
    "        print(f\"  Cleaned state_dict has {len(final_cleaned_state_dict.keys())} keys.\")\n",
    "\n",
    "        if os.path.exists(checkpoint_to_process_path):\n",
    "            if checkpoint_to_process_path != backup_file_path:\n",
    "                print(f\"  Backing up original file '{os.path.basename(checkpoint_to_process_path)}' to '{os.path.basename(backup_file_path)}'...\")\n",
    "                shutil.move(checkpoint_to_process_path, backup_file_path)\n",
    "        else:\n",
    "            print(f\"  Warning: Original file '{os.path.basename(checkpoint_to_process_path)}' not found for backup.\")\n",
    "\n",
    "\n",
    "        print(f\"  Saving lean model to: {lean_model_save_path}\")\n",
    "        torch.save(final_cleaned_state_dict, lean_model_save_path)\n",
    "        new_size_mb = os.path.getsize(lean_model_save_path) / (1024 * 1024)\n",
    "        print(f\"  ✅ Successfully saved lean model: {os.path.basename(lean_model_save_path)} ({new_size_mb:.2f} MB)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error during processing of {checkpoint_to_process_path}: {e}\")\n",
    "        import traceback; traceback.print_exc()\n",
    "        if os.path.exists(backup_file_path) and not os.path.exists(checkpoint_to_process_path):\n",
    "            try: shutil.move(backup_file_path, checkpoint_to_process_path); print(f\"  Restored '{os.path.basename(checkpoint_to_process_path)}'.\")\n",
    "            except Exception as e_restore: print(f\"  Could not restore: {e_restore}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d92ea20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use standard torchvision.models.resnet50 with num_classes=1000 as the architecture.\n"
     ]
    }
   ],
   "source": [
    "# ============== Notebook Cell 3: Define Model Instantiation and Parameters (Run Once) ==============\n",
    "# --- !!! ACTION REQUIRED: PART 1 - SET NUMBER OF CLASSES !!! ---\n",
    "# This NUM_CLASSES should match the output dimension of the final fully connected layer\n",
    "# of your ResNet50 models that were pruned.\n",
    "# For full ImageNet, this is 1000. If you fine-tuned on a dataset with a\n",
    "# different number of classes (e.g., ImageNet-mini if it has fewer, or CIFAR-10/100),\n",
    "# set this value correctly.\n",
    "NUM_CLASSES_FOR_PRUNED_MODELS = 1000  # <--- ADJUST IF YOUR PRUNED MODELS HAVE A DIFFERENT NUMBER OF CLASSES\n",
    "\n",
    "# This lambda function will create a new instance of the standard ResNet50.\n",
    "# We pass `weights=None` because we are going to load our own pruned weights.\n",
    "# The `num_classes` will be passed from the `NUM_CLASSES_FOR_PRUNED_MODELS` variable.\n",
    "resnet50_factory = lambda nc: models.resnet50(weights=None, num_classes=nc)\n",
    "\n",
    "print(f\"Will use standard torchvision.models.resnet50 with num_classes={NUM_CLASSES_FOR_PRUNED_MODELS} as the architecture.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "466fac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to process directory: C:\\Uni\\deep_model_optimization\\saved_models_and_logs\\pruning_unstructured_iterative\\resnet50_prune_unstruct_it_l1_stage3_sp90_ft\n",
      "\n",
      "Processing Directory: C:\\Uni\\deep_model_optimization\\saved_models_and_logs\\pruning_unstructured_iterative\\resnet50_prune_unstruct_it_l1_stage3_sp90_ft\n",
      "  Selected for processing: model_final.pth\n",
      "  Loading checkpoint: C:\\Uni\\deep_model_optimization\\saved_models_and_logs\\pruning_unstructured_iterative\\resnet50_prune_unstruct_it_l1_stage3_sp90_ft\\model_final.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\Temp\\ipykernel_12096\\275312137.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  full_checkpoint_data = torch.load(checkpoint_to_process_path, map_location='cpu') # Load to CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created a new model instance (e.g., resnet50 with num_classes=1000).\n",
      "  Loading state_dict into model instance (strict=False)...\n",
      "  Making pruning permanent by applying prune.remove()...\n",
      "  Pruning removal process completed.\n",
      "  Cleaned state_dict has 320 keys.\n",
      "  Backing up original file 'model_final.pth' to 'model_final_full_checkpoint_backup.pth'...\n",
      "  Saving lean model to: C:\\Uni\\deep_model_optimization\\saved_models_and_logs\\pruning_unstructured_iterative\\resnet50_prune_unstruct_it_l1_stage3_sp90_ft\\model_final.pth\n",
      "  ✅ Successfully saved lean model: model_final.pth (97.79 MB)\n",
      "\n",
      "✅ Processing finished for C:\\Uni\\deep_model_optimization\\saved_models_and_logs\\pruning_unstructured_iterative\\resnet50_prune_unstruct_it_l1_stage3_sp90_ft\n"
     ]
    }
   ],
   "source": [
    "# ============== Notebook Cell 4: Process a Single Directory (Run for each directory) ==============\n",
    "# --- !!! ACTION REQUIRED: PART 2 - SET THE DIRECTORY PATH !!! ---\n",
    "# Set `directory_to_process` to the full path of one of your\n",
    "# \"pruning_unstructured_iterative/...\" subdirectories that contains a large checkpoint.\n",
    "\n",
    "# Use a raw string (r\"...\") for Windows paths\n",
    "directory_to_process = r\"C:\\Uni\\deep_model_optimization\\saved_models_and_logs\\pruning_unstructured_iterative\\resnet50_prune_unstruct_it_l1_stage3_sp90_ft\" # <--- Path to the FOLDER\n",
    "\n",
    "# OR use forward slashes:\n",
    "# directory_to_process = \"C:/Uni/deep_model_optimization/saved_models_and_logs/pruning_unstructured_iterative/resnet50_prune_unstruct_it_l1_stage1_sp50_ft\" # <--- Path to the FOLDER\n",
    "\n",
    "\n",
    "if not directory_to_process:\n",
    "    print(\"⚠️ Please set 'directory_to_process' in Cell 4 with the path to the target directory.\")\n",
    "elif not os.path.exists(directory_to_process): # This checks if the DIRECTORY exists\n",
    "    print(f\"❌ Error: The DIRECTORY '{directory_to_process}' does not exist. Please check the path.\")\n",
    "elif not os.path.isdir(directory_to_process): # Add this check\n",
    "    print(f\"❌ Error: The path '{directory_to_process}' is not a DIRECTORY. Please provide the path to the folder containing the model file.\")\n",
    "else:\n",
    "    print(f\"\\nAttempting to process directory: {directory_to_process}\")\n",
    "    success = clean_pruned_model_in_directory(directory_to_process, resnet50_factory, NUM_CLASSES_FOR_PRUNED_MODELS)\n",
    "    if success:\n",
    "        print(f\"\\n✅ Processing finished for {directory_to_process}\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Processing encountered issues for {directory_to_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36a09094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the new lean model: C:\\Uni\\deep_model_optimization\\saved_models_and_logs\\pruning_unstructured_iterative\\resnet50_prune_unstruct_it_l1_stage1_sp50_ft\\model_final.pth\n",
      "Number of keys in its state_dict: 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\Temp\\ipykernel_12096\\1332426231.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict_check = torch.load(lean_model_path, map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "# Quick check cell\n",
    "import torch\n",
    "from torchvision import models # For the model class\n",
    "\n",
    "lean_model_path = r\"C:\\Uni\\deep_model_optimization\\saved_models_and_logs\\pruning_unstructured_iterative\\resnet50_prune_unstruct_it_l1_stage1_sp50_ft\\model_final.pth\"\n",
    "num_classes = 1000 # Should match NUM_CLASSES_FOR_PRUNED_MODELS\n",
    "\n",
    "model_check = models.resnet50(weights=None, num_classes=num_classes)\n",
    "try:\n",
    "    state_dict_check = torch.load(lean_model_path, map_location='cpu')\n",
    "    model_check.load_state_dict(state_dict_check)\n",
    "    print(f\"Successfully loaded the new lean model: {lean_model_path}\")\n",
    "    print(f\"Number of keys in its state_dict: {len(state_dict_check.keys())}\")\n",
    "    # print(\"First 10 keys:\", list(state_dict_check.keys())[:10])\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or checking the new lean model: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
