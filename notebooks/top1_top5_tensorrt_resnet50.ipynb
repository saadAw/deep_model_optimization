{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d80a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ torch_tensorrt imported successfully.\n",
      "Evaluation will run on: cuda\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "#                      IMPORTS AND SETUP\n",
    "# ===================================================================\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# Imports for data loading and transformations\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check for torch_tensorrt installation\n",
    "try:\n",
    "    import torch_tensorrt\n",
    "    print(\"✓ torch_tensorrt imported successfully.\")\n",
    "except ImportError:\n",
    "    print(\"✗ WARNING: torch_tensorrt is not installed. This script may not work.\")\n",
    "\n",
    "# Set the primary device for evaluation\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Evaluation will run on: {DEVICE}\")\n",
    "\n",
    "if DEVICE.type == 'cpu':\n",
    "    print(\"⚠️ WARNING: TensorRT models are optimized for GPU. Running on CPU will be slow and is not a typical use case.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490a6fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "#                        CONFIGURATION\n",
    "# ===================================================================\n",
    "\n",
    "# --- 1. SET THE PATH TO YOUR VALIDATION DATASET ---\n",
    "VALIDATION_DATA_PATH = '/workspace/imagenet-mini/val'\n",
    "\n",
    "# --- 2. MODEL PATHS ---\n",
    "CONTAINER_DATA_PATH = '/workspace'\n",
    "MODEL_PATHS = {\n",
    "    'TensorRT FP32': os.path.join(CONTAINER_DATA_PATH, r'saved_models_and_logs/tensorrt/resnet50_trt_fp32.ts'),\n",
    "    'TensorRT FP16': os.path.join(CONTAINER_DATA_PATH, r'saved_models_and_logs/tensorrt/resnet50_trt_fp16.ts')\n",
    "}\n",
    "\n",
    "# --- 3. EVALUATION PARAMETERS ---\n",
    "EVAL_BATCH_SIZE = 64\n",
    "REQUIRED_BATCH_SIZE_FOR_TRT = 32\n",
    "NUM_WORKERS = 2 if DEVICE.type == 'cuda' else 0\n",
    "\n",
    "# --- 4. DATA TRANSFORMS ---\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9d1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Simple evaluation function defined.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "#    CELL 3: ACCURACY EVALUATION FUNCTION (SIMPLE 'drop_last' VERSION)\n",
    "# ===================================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_accuracy_simple(model, model_name, data_loader, device):\n",
    "    \"\"\"\n",
    "    A simple evaluation function that assumes all batches are the same size.\n",
    "    This requires the DataLoader to use `drop_last=True`.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    is_fp16 = 'FP16' in model_name.upper()\n",
    "    if is_fp16:\n",
    "        print(\"  -> Model identified as FP16. Input tensors will be converted to half-precision.\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        if is_fp16:\n",
    "            images = images.half()\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, pred = outputs.topk(k=5, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
    "\n",
    "        correct_top1 += correct[:1].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "        correct_top5 += correct[:5].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        print(f\"\\r  -> Processing batch {i+1}/{num_batches}\", end=\"\")\n",
    "            \n",
    "    print() # Newline after progress bar\n",
    "    top1_acc = (correct_top1 / total) * 100.0 if total > 0 else 0.0\n",
    "    top5_acc = (correct_top5 / total) * 100.0 if total > 0 else 0.0\n",
    "    return top1_acc, top5_acc\n",
    "\n",
    "print(\"✓ Simple evaluation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625a2bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Initial TensorRT Model Accuracy Evaluation (Simple Method)...\n",
      "\n",
      "Loading validation dataset with drop_last=True...\n",
      "✓ Dataset loaded. Evaluating on 3904/3923 images across 122 batches.\n",
      "⚠️ WARNING: 19 images from the last batch are being ignored.\n",
      "\n",
      "==================================================\n",
      "Processing Model: TensorRT FP32\n",
      "==================================================\n",
      "  -> Processing batch 122/122\n",
      "  -> ✅ (Incomplete) Result: Top-1 = 64.93%, Top-5 = 87.50%\n",
      "\n",
      "==================================================\n",
      "Processing Model: TensorRT FP16\n",
      "==================================================\n",
      "  -> Model identified as FP16. Input tensors will be converted to half-precision.\n",
      "  -> Processing batch 122/122\n",
      "  -> ✅ (Incomplete) Result: Top-1 = 65.06%, Top-5 = 87.45%\n",
      "\n",
      "\n",
      "==================================================\n",
      "📋 INITIAL (INCOMPLETE) ACCURACY REPORT\n",
      "==================================================\n",
      "        Model Top-1 Accuracy (%) Top-5 Accuracy (%)\n",
      "TensorRT FP32              64.93              87.50\n",
      "TensorRT FP16              65.06              87.45\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "#      CELL 4: MAIN EXECUTION (SIMPLE, INCOMPLETE ATTEMPT)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"🚀 Starting Initial TensorRT Model Accuracy Evaluation (Simple Method)...\")\n",
    "\n",
    "print(f\"\\nLoading validation dataset with drop_last=True...\")\n",
    "if not os.path.exists(VALIDATION_DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Validation data path not found: {VALIDATION_DATA_PATH}\")\n",
    "\n",
    "val_dataset_simple = ImageFolder(VALIDATION_DATA_PATH, eval_transforms)\n",
    "# NOTE: Using drop_last=True here for simplicity, but this is flawed.\n",
    "val_loader_simple = DataLoader(\n",
    "    val_dataset_simple,\n",
    "    batch_size=REQUIRED_BATCH_SIZE_FOR_TRT, # Batch size must match static TRT engine\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if DEVICE.type == 'cuda' else False,\n",
    "    drop_last=True  # <-- THE KEY FLAW\n",
    ")\n",
    "ignored_images = len(val_dataset_simple) % REQUIRED_BATCH_SIZE_FOR_TRT\n",
    "effective_images = len(val_dataset_simple) - ignored_images\n",
    "\n",
    "print(f\"✓ Dataset loaded. Evaluating on {effective_images}/{len(val_dataset_simple)} images across {len(val_loader_simple)} batches.\")\n",
    "print(f\"⚠️ WARNING: {ignored_images} images from the last batch are being ignored.\")\n",
    "\n",
    "# --- Evaluate Models with the simple function ---\n",
    "results_list_simple = []\n",
    "for model_name, model_path in MODEL_PATHS.items():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Processing Model: {model_name}\")\n",
    "    print(\"=\"*50)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"✗ ERROR: Model file not found at '{model_path}'. Skipping.\")\n",
    "        results_list_simple.append({'Model': model_name, 'Top-1 Accuracy (%)': 'File Not Found', 'Top-5 Accuracy (%)': 'File Not Found'})\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        model = torch.jit.load(model_path).to(DEVICE)\n",
    "        top1, top5 = evaluate_model_accuracy_simple(model, model_name, val_loader_simple, DEVICE)\n",
    "        print(f\"  -> ✅ (Incomplete) Result: Top-1 = {top1:.2f}%, Top-5 = {top5:.2f}%\")\n",
    "        results_list_simple.append({'Model': model_name, 'Top-1 Accuracy (%)': f\"{top1:.2f}\", 'Top-5 Accuracy (%)': f\"{top5:.2f}\"})\n",
    "    except Exception as e:\n",
    "        print(f\"✗ ERROR: An error occurred while processing {model_name}: {e}\")\n",
    "        results_list_simple.append({'Model': model_name, 'Top-1 Accuracy (%)': 'Evaluation Failed', 'Top-5 Accuracy (%)': 'Evaluation Failed'})\n",
    "    finally:\n",
    "        if 'model' in locals(): del model\n",
    "        gc.collect()\n",
    "\n",
    "# --- Display Initial, Flawed Report ---\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"📋 INITIAL (INCOMPLETE) ACCURACY REPORT\")\n",
    "print(\"=\"*50)\n",
    "if results_list_simple:\n",
    "    results_df_simple = pd.DataFrame(results_list_simple)\n",
    "    print(results_df_simple.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25dc756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of the previous result:\n",
      "The `drop_last=True` approach is fast but inaccurate because it ignores the final batch of images.\n",
      "To get the true accuracy, we must evaluate all images. This requires 'padding' the last batch to match the static size required by the TensorRT engine.\n",
      "\n",
      "Defining a new, more robust evaluation function that handles this padding...\n",
      "\n",
      "✓ Robust evaluation function is now defined.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "#    CELL 5: CORRECTING THE FLAW - EVALUATING ALL IMAGES\n",
    "# ===================================================================\n",
    "\n",
    "print(\"Analysis of the previous result:\")\n",
    "print(\"The `drop_last=True` approach is fast but inaccurate because it ignores the final batch of images.\")\n",
    "print(\"To get the true accuracy, we must evaluate all images. This requires 'padding' the last batch to match the static size required by the TensorRT engine.\")\n",
    "print(\"\\nDefining a new, more robust evaluation function that handles this padding...\\n\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model_accuracy_robust(model, model_name, data_loader, device, required_batch_size):\n",
    "    \"\"\"\n",
    "    A robust evaluation function that handles static batch sizes by padding the last batch.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = 0\n",
    "    num_batches = len(data_loader)\n",
    "\n",
    "    is_fp16 = 'FP16' in model_name.upper()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        current_batch_size = images.shape[0]\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # --- PADDING LOGIC ---\n",
    "        if current_batch_size < required_batch_size:\n",
    "            print(f\"\\r  -> Processing batch {i+1}/{num_batches} (Padding from {current_batch_size} to {required_batch_size})\", end=\"\")\n",
    "            padding_size = required_batch_size - current_batch_size\n",
    "            padding_tensor = torch.zeros(padding_size, *images.shape[1:], device=device, dtype=images.dtype)\n",
    "            images = torch.cat((images, padding_tensor), dim=0)\n",
    "        else:\n",
    "             print(f\"\\r  -> Processing batch {i+1}/{num_batches}\", end=\"\")\n",
    "\n",
    "        if is_fp16:\n",
    "            images = images.half()\n",
    "\n",
    "        outputs = model(images)\n",
    "        outputs = outputs[:current_batch_size] # Slice to remove padding results\n",
    "\n",
    "        _, pred = outputs.topk(k=5, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
    "\n",
    "        correct_top1 += correct[:1].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "        correct_top5 += correct[:5].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(\"\\n\") # Newline after progress bar\n",
    "    top1_acc = (correct_top1 / total) * 100.0 if total > 0 else 0.0\n",
    "    top5_acc = (correct_top5 / total) * 100.0 if total > 0 else 0.0\n",
    "    return top1_acc, top5_acc\n",
    "\n",
    "print(\"✓ Robust evaluation function is now defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b6a898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Rerunning evaluation with the robust padding method to include all images...\n",
      "\n",
      "Loading validation dataset with drop_last=False to include all images...\n",
      "✓ Dataset loaded. Evaluating on all 3923 images across 123 batches.\n",
      "\n",
      "==================================================\n",
      "Processing Model: TensorRT FP32\n",
      "==================================================\n",
      "  -> Processing batch 123/123 (Padding from 19 to 32)\n",
      "\n",
      "  -> ✅ (Complete) Result: Top-1 = 64.92%, Top-5 = 87.51%\n",
      "\n",
      "==================================================\n",
      "Processing Model: TensorRT FP16\n",
      "==================================================\n",
      "  -> Processing batch 123/123 (Padding from 19 to 32)\n",
      "\n",
      "  -> ✅ (Complete) Result: Top-1 = 65.05%, Top-5 = 87.46%\n",
      "\n",
      "\n",
      "==================================================\n",
      "📋 FINAL & COMPLETE ACCURACY REPORT\n",
      "==================================================\n",
      "        Model Top-1 Accuracy (%) Top-5 Accuracy (%)\n",
      "TensorRT FP32              64.92              87.51\n",
      "TensorRT FP16              65.05              87.46\n",
      "\n",
      "🎉 Full evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ===================================================================\n",
    "#           CELL 6: RERUNNING EVALUATION (ROBUST METHOD)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"🚀 Rerunning evaluation with the robust padding method to include all images...\")\n",
    "\n",
    "if not os.path.exists(VALIDATION_DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Validation data path not found: {VALIDATION_DATA_PATH}\")\n",
    "\n",
    "print(f\"\\nLoading validation dataset with drop_last=False to include all images...\")\n",
    "val_dataset_robust = ImageFolder(VALIDATION_DATA_PATH, eval_transforms)\n",
    "val_loader_robust = DataLoader(\n",
    "    val_dataset_robust,\n",
    "    batch_size=REQUIRED_BATCH_SIZE_FOR_TRT,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if DEVICE.type == 'cuda' else False,\n",
    "    drop_last=False # <-- THE FIX\n",
    ")\n",
    "print(f\"✓ Dataset loaded. Evaluating on all {len(val_dataset_robust)} images across {len(val_loader_robust)} batches.\")\n",
    "\n",
    "# --- Evaluate Models with the robust function ---\n",
    "results_list_robust = []\n",
    "for model_name, model_path in MODEL_PATHS.items():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Processing Model: {model_name}\")\n",
    "    print(\"=\"*50)\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"✗ ERROR: Model file not found at '{model_path}'. Skipping.\")\n",
    "        results_list_robust.append({'Model': model_name, 'Top-1 Accuracy (%)': 'File Not Found', 'Top-5 Accuracy (%)': 'File Not Found'})\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        model = torch.jit.load(model_path).to(DEVICE)\n",
    "        top1, top5 = evaluate_model_accuracy_robust(model, model_name, val_loader_robust, DEVICE, REQUIRED_BATCH_SIZE_FOR_TRT)\n",
    "        print(f\"  -> ✅ (Complete) Result: Top-1 = {top1:.2f}%, Top-5 = {top5:.2f}%\")\n",
    "        results_list_robust.append({'Model': model_name, 'Top-1 Accuracy (%)': f\"{top1:.2f}\", 'Top-5 Accuracy (%)': f\"{top5:.2f}\"})\n",
    "    except Exception as e:\n",
    "        print(f\"✗ ERROR: An error occurred while processing {model_name}: {e}\")\n",
    "        results_list_robust.append({'Model': model_name, 'Top-1 Accuracy (%)': 'Evaluation Failed', 'Top-5 Accuracy (%)': 'Evaluation Failed'})\n",
    "    finally:\n",
    "        if 'model' in locals(): del model\n",
    "        gc.collect()\n",
    "\n",
    "# --- Display Final, Correct Report ---\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"📋 FINAL & COMPLETE ACCURACY REPORT\")\n",
    "print(\"=\"*50)\n",
    "if results_list_robust:\n",
    "    results_df_robust = pd.DataFrame(results_list_robust)\n",
    "    print(results_df_robust.to_string(index=False))\n",
    "\n",
    "print(\"\\n🎉 Full evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
