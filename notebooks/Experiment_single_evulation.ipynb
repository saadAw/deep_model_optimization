{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff9c17b",
   "metadata": {},
   "source": [
    "Cell 1: Imports and Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921ebb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Notebook Setup: Imports completed ---\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import time\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from thop import profile\n",
    "import torch_pruning as tp\n",
    "import re\n",
    "import traceback # Keep for detailed error messages\n",
    "\n",
    "print(\"--- Notebook Setup: Imports completed ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "ROOT_DIR = \"saved_models_and_logs\"\n",
    "OUTPUT_CSV_NB = \"model_optimization_summary_notebook.csv\"\n",
    "DEFAULT_NUM_CLASSES = 1000\n",
    "FIXED_NUM_CLASSES = 1000 # For model reconstruction consistency\n",
    "\n",
    "# --- Uniform Evaluation Configuration ---\n",
    "VALIDATION_DATA_PATH = \"imagenet-mini/val\" # MAKE SURE THIS PATH IS CORRECT\n",
    "BATCH_SIZE_EVAL = 32\n",
    "NUM_WORKERS_EVAL = 0 # Set to 0 for Windows or if issues, >0 for Linux if beneficial\n",
    "MAX_EVAL_BATCHES = 125 # Max batches for accuracy evaluation (set to float('inf') for all)\n",
    "\n",
    "# --- Device and Input Tensors ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "INPUT_TENSOR_CPU = torch.randn(1, 3, 224, 224)\n",
    "INPUT_TENSOR_GPU = None\n",
    "if DEVICE.type == 'cuda':\n",
    "    try:\n",
    "        INPUT_TENSOR_GPU = INPUT_TENSOR_CPU.to(DEVICE)\n",
    "    except Exception as e_cuda_init:\n",
    "        print(f\"ERROR initializing INPUT_TENSOR_GPU on CUDA: {e_cuda_init}\")\n",
    "        INPUT_TENSOR_GPU = None # Ensure it's None if failed\n",
    "\n",
    "WARMUP_INFERENCES = 2\n",
    "TIMED_INFERENCES = 5\n",
    "\n",
    "GPU_UNSTABLE_QUANTIZED_MODELS = [\n",
    "    \"resnet18pretrained_distilled_quant_ptq_int8_perchannel_post\",\n",
    "    \"resnet18pretrained_distilled_quant_ptq_int8_pertensor_post\",\n",
    "    \"resnet18pretrained_distilled_quant_qat_int8_epochs8\",\n",
    "    \"resnet50_quant_ptq_int8_perchannel_post\",\n",
    "    \"resnet50_quant_ptq_int8_pertensor_post\",\n",
    "    \"resnet50_quant_qat_int8_epochs8\",\n",
    "]\n",
    "\n",
    "# --- DataFrame to store all results ---\n",
    "# We'll populate this as we go\n",
    "results_df = pd.DataFrame()\n",
    "current_eval_experiment_id_nb = \"\" # For logging within evaluate_model_uniformly\n",
    "baseline_metrics_nb = {} # To store baseline metrics for relative calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d3ddc",
   "metadata": {},
   "source": [
    "Cell 2: Core Helper Functions (Path, Size, Pruning Reconstruction Logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a36d389e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Helper functions defined ---\n"
     ]
    }
   ],
   "source": [
    "# --- Helper: Image Transforms ---\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "eval_transforms = transforms.Compose([\n",
    "    transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), normalize,\n",
    "])\n",
    "\n",
    "# --- Helper: Model File and Size ---\n",
    "def get_model_file_path_nb(experiment_path_str):\n",
    "    experiment_path = Path(experiment_path_str)\n",
    "    # Prioritize 'model_final.pth' as it's common in your structured pruning logs\n",
    "    specific_model_file = experiment_path / \"model_final.pth\"\n",
    "    if specific_model_file.exists():\n",
    "        return str(specific_model_file)\n",
    "        \n",
    "    pth_files = list(experiment_path.glob(\"*.pth\"))\n",
    "    if pth_files:\n",
    "        for common_name in [\"model_quantized.pth\"]: # Check other common names\n",
    "            for p_file in pth_files:\n",
    "                if p_file.name == common_name: return str(p_file)\n",
    "        for p_file in pth_files: # Specific baseline names\n",
    "            if \"baseline_ft_imagenetmini_final.pth\" in p_file.name: return str(p_file)\n",
    "        # Fallback: return the first .pth file found if common names aren't present\n",
    "        # print(f\"    Note ({experiment_path.name}): Using first .pth file found: {pth_files[0]} as no common/specific name matched.\")\n",
    "        return str(pth_files[0])\n",
    "    # print(f\"    Warning ({experiment_path.name}): No .pth file found in {experiment_path_str}\")\n",
    "    return None\n",
    "\n",
    "def get_model_size_mb_nb(model_path_str):\n",
    "    if model_path_str and os.path.exists(model_path_str):\n",
    "        return os.path.getsize(model_path_str) / (1024 * 1024)\n",
    "    return None\n",
    "\n",
    "# --- Model Definition and Pruning Application (FROM SCRIPT 1) ---\n",
    "def get_base_resnet50_model_for_reconstruction_nb():\n",
    "    model = models.resnet50(weights=None, num_classes=FIXED_NUM_CLASSES)\n",
    "    return model\n",
    "\n",
    "def apply_structured_pruning_to_model_for_reconstruction_nb(\n",
    "    model_to_prune, example_inputs, target_pruning_rate_per_layer, device_obj\n",
    "):\n",
    "    model_to_prune.to(device_obj)\n",
    "    example_inputs = example_inputs.to(device_obj)\n",
    "    ignored_layers = []\n",
    "    for name, m in model_to_prune.named_modules():\n",
    "        if isinstance(m, nn.Linear) and m.out_features == FIXED_NUM_CLASSES:\n",
    "            ignored_layers.append(m)\n",
    "    try:\n",
    "        importance = tp.importance.MagnitudeImportance(p=1) # L1 norm\n",
    "        pruner = tp.pruner.MagnitudePruner(\n",
    "            model=model_to_prune, example_inputs=example_inputs, importance=importance,\n",
    "            iterative_steps=1, pruning_ratio=target_pruning_rate_per_layer,\n",
    "            global_pruning=False, ignored_layers=ignored_layers,\n",
    "        )\n",
    "        pruner.step()\n",
    "    except Exception as e_prune:\n",
    "        print(f\"      ERROR during tp.pruner.MagnitudePruner step (rate {target_pruning_rate_per_layer}): {e_prune}\")\n",
    "        return None # Indicate failure\n",
    "    return model_to_prune\n",
    "\n",
    "def get_pruning_config_from_log_for_reconstruction_nb(log_file_path_str):\n",
    "    \"\"\"Helper to load log and extract key pruning param for a single stage/one-shot.\"\"\"\n",
    "    log_file_path = Path(log_file_path_str)\n",
    "    if not log_file_path.exists():\n",
    "        # print(f\"    Log file not found: {log_file_path}\")\n",
    "        return None\n",
    "    try:\n",
    "        with open(log_file_path, 'r') as f:\n",
    "            log_data = json.load(f)\n",
    "\n",
    "        # For one-shot, directly from config_details\n",
    "        if 'config_details' in log_data and 'target_filter_pruning_rate_per_layer' in log_data['config_details']:\n",
    "            rate = log_data['config_details']['target_filter_pruning_rate_per_layer']\n",
    "            if rate is not None: return {'type': 'one-shot', 'rate': float(rate)}\n",
    "\n",
    "        # For a single iterative stage, get its own applied rate\n",
    "        if 'config_details' in log_data and 'applied_step_rate_for_this_stage' in log_data['config_details']:\n",
    "            rate = log_data['config_details']['applied_step_rate_for_this_stage']\n",
    "            if rate is not None: return {'type': 'iterative_step', 'rate': float(rate)}\n",
    "        \n",
    "        # Fallback for some iterative logs that might only have overall target at a specific stage\n",
    "        if 'config_details' in log_data and 'target_overall_sparsity_approx_for_this_stage' in log_data['config_details']:\n",
    "            rate = log_data['config_details']['target_overall_sparsity_approx_for_this_stage']\n",
    "            if rate is not None:\n",
    "                # print(f\"    Warning: Found 'target_overall_sparsity_approx_for_this_stage' ({rate}) in {log_file_path}. Using for iterative_step reconstruction rate.\")\n",
    "                return {'type': 'iterative_step', 'rate': float(rate)}\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"    Error decoding JSON from {log_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Error processing log {log_file_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Renamed and refactored: Takes a pre-compiled pruning_config\n",
    "def _reconstruct_model_arch_and_load_weights_nb(model_path_str, device_obj, pruning_config, exp_id_for_log=\"\"):\n",
    "    \"\"\"\n",
    "    Reconstructs model architecture based on pruning_config and loads weights.\n",
    "    pruning_config must be pre-determined (cumulative for iterative models).\n",
    "    \"\"\"\n",
    "    # print(f\"    ({exp_id_for_log}) _reconstruct_model_arch_and_load_weights_nb for: {model_path_str} with config: {pruning_config}\")\n",
    "    \n",
    "    if not pruning_config:\n",
    "        print(f\"    ERROR ({exp_id_for_log}): No pruning_config provided for {model_path_str}.\")\n",
    "        return None\n",
    "\n",
    "    reconstructed_model = get_base_resnet50_model_for_reconstruction_nb() # Assuming ResNet50 for structured\n",
    "    reconstructed_model.to(device_obj)\n",
    "    example_inputs_local = INPUT_TENSOR_CPU.to(device_obj) # Use CPU tensor, move to device\n",
    "\n",
    "    try:\n",
    "        if pruning_config['type'] == 'one-shot':\n",
    "            rate = pruning_config['rate']\n",
    "            # print(f\"      ({exp_id_for_log}) Applying one-shot pruning for reconstruction with rate {rate}\")\n",
    "            reconstructed_model = apply_structured_pruning_to_model_for_reconstruction_nb(\n",
    "                reconstructed_model, example_inputs_local, rate, device_obj)\n",
    "        elif pruning_config['type'] == 'iterative':\n",
    "            step_rates = pruning_config.get('step_rates', [])\n",
    "            if not step_rates:\n",
    "                print(f\"    ERROR ({exp_id_for_log}): Iterative pruning_config for {model_path_str} has no step_rates.\")\n",
    "                return None\n",
    "            current_arch_model = reconstructed_model\n",
    "            # print(f\"      ({exp_id_for_log}) Applying iterative reconstruction with rates: {step_rates}\")\n",
    "            for i, step_rate in enumerate(step_rates):\n",
    "                # print(f\"        ({exp_id_for_log}) Applying iterative step {i+1} with rate {step_rate}\")\n",
    "                current_arch_model = apply_structured_pruning_to_model_for_reconstruction_nb(\n",
    "                    current_arch_model, example_inputs_local, step_rate, device_obj)\n",
    "                if current_arch_model is None:\n",
    "                    print(f\"      ERROR ({exp_id_for_log}): Iterative pruning step {i+1} (rate {step_rate}) failed during reconstruction for {model_path_str}.\")\n",
    "                    return None\n",
    "            reconstructed_model = current_arch_model\n",
    "        else:\n",
    "            print(f\"    ERROR ({exp_id_for_log}): Unknown pruning_config type: {pruning_config.get('type')} for {model_path_str}\")\n",
    "            return None\n",
    "        \n",
    "        if reconstructed_model is None:\n",
    "            print(f\"    ERROR ({exp_id_for_log}): Model became None after pruning application for {model_path_str}\")\n",
    "            return None\n",
    "\n",
    "        # Load state_dict with weights_only=True where possible\n",
    "        state_dict = torch.load(model_path_str, map_location=device_obj, weights_only=True)\n",
    "        \n",
    "        if all(key.startswith('module.') for key in state_dict.keys()):\n",
    "            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "        if 'model' in state_dict and isinstance(state_dict['model'], dict): state_dict = state_dict['model']\n",
    "        elif 'state_dict' in state_dict and isinstance(state_dict['state_dict'], dict): state_dict = state_dict['state_dict']\n",
    "        \n",
    "        reconstructed_model.load_state_dict(state_dict)\n",
    "        # print(f\"    ({exp_id_for_log}) State_dict loaded into RECONSTRUCTED structured model: {model_path_str}\")\n",
    "        reconstructed_model.eval()\n",
    "        return reconstructed_model\n",
    "    except Exception as e:\n",
    "        print(f\"    ERROR in _reconstruct_model_arch_and_load_weights_nb for {model_path_str} ({exp_id_for_log}): {e}\")\n",
    "        # import traceback; traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "print(\"--- Helper functions defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc61d7d",
   "metadata": {},
   "source": [
    "Cell 3: Central Model Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd80daec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Central model loader defined ---\n"
     ]
    }
   ],
   "source": [
    "# Added all_experiments_df to signature\n",
    "def load_model_for_experiment_nb(exp_info, all_experiments_df, target_device_str='cpu'):\n",
    "    \"\"\"\n",
    "    Loads a model for a given experiment. Handles structured pruning reconstruction.\n",
    "    exp_info: Pandas Series for the current experiment.\n",
    "    all_experiments_df: The complete DataFrame of all discovered experiments (for lookups).\n",
    "    target_device_str: 'cpu' or 'cuda'.\n",
    "    Returns: loaded_model_obj or None\n",
    "    \"\"\"\n",
    "    model_path = exp_info.get('Model_File_Path')\n",
    "    exp_path_str = exp_info.get('Experiment_Path') # Directory of the experiment\n",
    "    base_arch = exp_info.get('Base_Model_Arch')\n",
    "    num_classes = exp_info.get('Num_Classes', DEFAULT_NUM_CLASSES)\n",
    "    is_structured = exp_info.get('Is_Structured_Pruning', False)\n",
    "    exp_id = exp_info.get('Experiment_ID', 'Unknown_Exp')\n",
    "\n",
    "    if not model_path or not os.path.exists(model_path):\n",
    "        print(f\"      ERROR ({exp_id}): Model file not found at {model_path}\")\n",
    "        return None\n",
    "    if os.path.getsize(model_path) == 0:\n",
    "        print(f\"      ERROR ({exp_id}): Model file is 0 bytes: {model_path}\")\n",
    "        return None\n",
    "\n",
    "    device_to_load_on = torch.device(target_device_str)\n",
    "    loaded_model = None\n",
    "    \n",
    "    # Attempt 1: JIT load (common for some quantized/pruned models)\n",
    "    try:\n",
    "        loaded_model = torch.jit.load(model_path, map_location=device_to_load_on)\n",
    "        # print(f\"      INFO ({exp_id}): Model loaded using torch.jit.load() on {device_to_load_on}\")\n",
    "        loaded_model.eval()\n",
    "        return loaded_model\n",
    "    except Exception:\n",
    "        pass # Silently try next method\n",
    "\n",
    "    # Attempt 2: Structured Pruning Reconstruction (if applicable)\n",
    "    if is_structured:\n",
    "        # print(f\"      INFO ({exp_id}): Structured pruning experiment. Constructing pruning config.\")\n",
    "        pruning_config_for_reconstruction = None\n",
    "        \n",
    "        base_exp_name_iter = exp_info.get('Base_Exp_Name_Iterative')\n",
    "        stage_num_iter = exp_info.get('Stage_Num_Iterative')\n",
    "\n",
    "        if base_exp_name_iter and stage_num_iter is not None: # It's an iterative model\n",
    "            # print(f\"        Iterative model detected: {base_exp_name_iter}, stage {stage_num_iter}\")\n",
    "            cumulative_step_rates = []\n",
    "            \n",
    "            # Find all stages of this iterative experiment from the main DataFrame\n",
    "            # Ensure we only consider stages up to and including the current one\n",
    "            relevant_stages_info = all_experiments_df[\n",
    "                (all_experiments_df['Base_Exp_Name_Iterative'] == base_exp_name_iter) &\n",
    "                (all_experiments_df['Stage_Num_Iterative'] <= stage_num_iter) &\n",
    "                (all_experiments_df['Stage_Num_Iterative'].notna()) # Ensure stage number is not NaN\n",
    "            ].sort_values(by='Stage_Num_Iterative')\n",
    "            \n",
    "            # print(f\"          Found {len(relevant_stages_info)} stages up to current for '{exp_id}'.\")\n",
    "\n",
    "            for _, stage_row in relevant_stages_info.iterrows():\n",
    "                stage_log_path = stage_row.get('Log_Path')\n",
    "                stage_exp_id = stage_row.get('Experiment_ID') # For logging\n",
    "                # print(f\"            Processing previous/current stage {stage_row.get('Stage_Num_Iterative')} (log: {stage_log_path}) for rate.\")\n",
    "                stage_log_pruning_info = get_pruning_config_from_log_for_reconstruction_nb(stage_log_path)\n",
    "                \n",
    "                if stage_log_pruning_info and stage_log_pruning_info.get('type') == 'iterative_step':\n",
    "                    cumulative_step_rates.append(stage_log_pruning_info['rate'])\n",
    "                else:\n",
    "                    print(f\"        WARNING ({exp_id}): Could not get 'iterative_step' rate for sibling/self '{stage_exp_id}' (stage {stage_row.get('Stage_Num_Iterative')}). Full reconstruction may fail.\")\n",
    "                    cumulative_step_rates = [] # Invalidate if any stage's rate is missing\n",
    "                    break \n",
    "            \n",
    "            if cumulative_step_rates:\n",
    "                pruning_config_for_reconstruction = {'type': 'iterative', 'step_rates': cumulative_step_rates}\n",
    "            else:\n",
    "                 print(f\"        ERROR ({exp_id}): Failed to build cumulative step rates for iterative model. Reconstruction might fail.\")\n",
    "\n",
    "        else: # It's one-shot structured\n",
    "            # print(f\"        One-shot structured model: {exp_id}\")\n",
    "            log_path_current_exp = exp_info.get('Log_Path')\n",
    "            one_shot_pruning_info = get_pruning_config_from_log_for_reconstruction_nb(log_path_current_exp)\n",
    "            if one_shot_pruning_info and one_shot_pruning_info.get('type') == 'one-shot':\n",
    "                pruning_config_for_reconstruction = one_shot_pruning_info\n",
    "            # Handle case where an iterative log might be mistakenly parsed as one-shot if stage info is missing\n",
    "            elif one_shot_pruning_info and one_shot_pruning_info.get('type') == 'iterative_step':\n",
    "                print(f\"        Warning ({exp_id}): Found 'iterative_step' in log but no base_exp_name/stage. Treating as one-shot with rate {one_shot_pruning_info['rate']}.\")\n",
    "                pruning_config_for_reconstruction = {'type': 'one-shot', 'rate': one_shot_pruning_info['rate']}\n",
    "            else:\n",
    "                print(f\"        ERROR ({exp_id}): Could not get 'one-shot' pruning config from log {log_path_current_exp}.\")\n",
    "\n",
    "        if pruning_config_for_reconstruction:\n",
    "            # print(f\"      Attempting reconstruction for {exp_id} with derived config: {pruning_config_for_reconstruction}\")\n",
    "            reconstructed = _reconstruct_model_arch_and_load_weights_nb(\n",
    "                model_path, device_to_load_on, pruning_config_for_reconstruction, exp_id\n",
    "            )\n",
    "            if reconstructed:\n",
    "                # print(f\"      INFO ({exp_id}): Successfully reconstructed structured model on {device_to_load_on}.\")\n",
    "                reconstructed.eval()\n",
    "                return reconstructed\n",
    "            else:\n",
    "                print(f\"      WARNING ({exp_id}): Failed to reconstruct structured model with derived config. Will try standard load as fallback.\")\n",
    "        else:\n",
    "            print(f\"      WARNING ({exp_id}): Could not determine a valid pruning_config_for_reconstruction for structured model. Will try standard load as fallback.\")\n",
    "            # Fall through to standard loading if config determination or reconstruction fails\n",
    "\n",
    "    # Attempt 3: Standard torch.load (full model or state_dict) - Fallback\n",
    "    try:\n",
    "        # For full model (if torch.save(model, path) was used), weights_only must be False (current default)\n",
    "        _raw_loaded_content = torch.load(model_path, map_location=device_to_load_on) # weights_only=False default\n",
    "        if isinstance(_raw_loaded_content, torch.nn.Module):\n",
    "            loaded_model = _raw_loaded_content\n",
    "            # print(f\"      INFO ({exp_id}): Model loaded as full nn.Module on {device_to_load_on} (fallback).\")\n",
    "        elif isinstance(_raw_loaded_content, dict): # Likely a state_dict\n",
    "            # print(f\"      INFO ({exp_id}): Content is dict, attempting state_dict load for {base_arch} on {device_to_load_on} (fallback).\")\n",
    "            if base_arch == \"ResNet18\": model_instance = models.resnet18(weights=None, num_classes=num_classes)\n",
    "            elif base_arch == \"ResNet50\": model_instance = models.resnet50(weights=None, num_classes=num_classes)\n",
    "            else:\n",
    "                print(f\"      ERROR ({exp_id}): Unknown base_arch '{base_arch}' for fallback state_dict load.\")\n",
    "                return None\n",
    "            \n",
    "            state_dict = _raw_loaded_content\n",
    "            if any(k.startswith('module.') for k in state_dict.keys()):\n",
    "                state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "            if 'model' in state_dict and isinstance(state_dict['model'], dict): state_dict = state_dict['model']\n",
    "            elif 'state_dict' in state_dict and isinstance(state_dict['state_dict'], dict): state_dict = state_dict['state_dict']\n",
    "\n",
    "            model_instance.load_state_dict(state_dict) # This might fail if arch is wrong\n",
    "            loaded_model = model_instance\n",
    "            # print(f\"      INFO ({exp_id}): Fallback state_dict loaded into {base_arch} instance on {device_to_load_on}.\")\n",
    "        else:\n",
    "            print(f\"      ERROR ({exp_id}): Fallback loaded object is neither nn.Module nor dict: {type(_raw_loaded_content)}\")\n",
    "            return None\n",
    "        \n",
    "        if loaded_model:\n",
    "            loaded_model.eval()\n",
    "            return loaded_model.to(device_to_load_on)\n",
    "\n",
    "    except RuntimeError as e_load:\n",
    "        if \"Error(s) in loading state_dict\" in str(e_load):\n",
    "             # This is expected if structured pruning reconstruction failed and we try to load into a base model.\n",
    "             print(f\"      INFO ({exp_id}): Fallback state_dict load failed (likely arch mismatch for structured model, as reconstruction may have failed): {str(e_load).splitlines()[0]}\")\n",
    "        else: # Other RuntimeError\n",
    "            print(f\"      ERROR ({exp_id}): During fallback torch.load or state_dict assignment: {str(e_load).splitlines()[0]}\")\n",
    "        return None\n",
    "    except Exception as e_gen_load:\n",
    "        print(f\"      ERROR ({exp_id}): General error during fallback model loading: {str(e_gen_load).splitlines()[0]}\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"      ERROR ({exp_id}): Model could not be loaded by any method.\")\n",
    "    return None\n",
    "\n",
    "print(\"--- Central model loader defined ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e292d9",
   "metadata": {},
   "source": [
    "Cell 4: Experiment Discovery and DataFrame Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9eecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Discovering experiments in: saved_models_and_logs ---\n",
      "--- Discovery finished. Found 25 experiments. ---\n",
      "\n",
      "--- Iterative Model Parsing Check (sample): ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Base_Exp_Name_Iterative</th>\n",
       "      <th>Stage_Num_Iterative</th>\n",
       "      <th>Log_Path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft</th>\n",
       "      <td>resnet50_prune_struct_it_l1filter_stage1_appro...</td>\n",
       "      <td>resnet50_prune_struct_it_l1filter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>saved_models_and_logs\\pruning_structured_itera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft</th>\n",
       "      <td>resnet50_prune_struct_it_l1filter_stage2_appro...</td>\n",
       "      <td>resnet50_prune_struct_it_l1filter</td>\n",
       "      <td>2.0</td>\n",
       "      <td>saved_models_and_logs\\pruning_structured_itera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft</th>\n",
       "      <td>resnet50_prune_struct_it_l1filter_stage3_appro...</td>\n",
       "      <td>resnet50_prune_struct_it_l1filter</td>\n",
       "      <td>3.0</td>\n",
       "      <td>saved_models_and_logs\\pruning_structured_itera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet50_prune_struct_it_l1filter_stage1_approx...  resnet50_prune_struct_it_l1filter_stage1_appro...   \n",
       "resnet50_prune_struct_it_l1filter_stage2_approx...  resnet50_prune_struct_it_l1filter_stage2_appro...   \n",
       "resnet50_prune_struct_it_l1filter_stage3_approx...  resnet50_prune_struct_it_l1filter_stage3_appro...   \n",
       "\n",
       "                                                              Base_Exp_Name_Iterative  \\\n",
       "Experiment_ID                                                                           \n",
       "resnet50_prune_struct_it_l1filter_stage1_approx...  resnet50_prune_struct_it_l1filter   \n",
       "resnet50_prune_struct_it_l1filter_stage2_approx...  resnet50_prune_struct_it_l1filter   \n",
       "resnet50_prune_struct_it_l1filter_stage3_approx...  resnet50_prune_struct_it_l1filter   \n",
       "\n",
       "                                                    Stage_Num_Iterative  \\\n",
       "Experiment_ID                                                             \n",
       "resnet50_prune_struct_it_l1filter_stage1_approx...                  1.0   \n",
       "resnet50_prune_struct_it_l1filter_stage2_approx...                  2.0   \n",
       "resnet50_prune_struct_it_l1filter_stage3_approx...                  3.0   \n",
       "\n",
       "                                                                                             Log_Path  \n",
       "Experiment_ID                                                                                          \n",
       "resnet50_prune_struct_it_l1filter_stage1_approx...  saved_models_and_logs\\pruning_structured_itera...  \n",
       "resnet50_prune_struct_it_l1filter_stage2_approx...  saved_models_and_logs\\pruning_structured_itera...  \n",
       "resnet50_prune_struct_it_l1filter_stage3_approx...  saved_models_and_logs\\pruning_structured_itera...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- All Discovered Experiments Sample: ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Base_Model_Arch</th>\n",
       "      <th>Is_Structured_Pruning</th>\n",
       "      <th>Model_File_Path</th>\n",
       "      <th>Log_Path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>False</td>\n",
       "      <td>saved_models_and_logs\\resnet18_baseline\\resnet...</td>\n",
       "      <td>saved_models_and_logs\\resnet18_baseline\\log.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>False</td>\n",
       "      <td>saved_models_and_logs\\resnet50_baseline\\resnet...</td>\n",
       "      <td>saved_models_and_logs\\resnet50_baseline\\log.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>False</td>\n",
       "      <td>saved_models_and_logs\\combined_distilled_quant...</td>\n",
       "      <td>saved_models_and_logs\\combined_distilled_quant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>False</td>\n",
       "      <td>saved_models_and_logs\\combined_distilled_quant...</td>\n",
       "      <td>saved_models_and_logs\\combined_distilled_quant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>False</td>\n",
       "      <td>saved_models_and_logs\\combined_distilled_quant...</td>\n",
       "      <td>saved_models_and_logs\\combined_distilled_quant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                   Base_Model_Arch  \\\n",
       "Experiment_ID                                                        \n",
       "resnet18_baseline                                         ResNet18   \n",
       "resnet50_baseline                                         ResNet50   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...        ResNet18   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...        ResNet18   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...        ResNet18   \n",
       "\n",
       "                                                    Is_Structured_Pruning  \\\n",
       "Experiment_ID                                                               \n",
       "resnet18_baseline                                                   False   \n",
       "resnet50_baseline                                                   False   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                  False   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                  False   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                  False   \n",
       "\n",
       "                                                                                      Model_File_Path  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                   saved_models_and_logs\\resnet18_baseline\\resnet...   \n",
       "resnet50_baseline                                   saved_models_and_logs\\resnet50_baseline\\resnet...   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  saved_models_and_logs\\combined_distilled_quant...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  saved_models_and_logs\\combined_distilled_quant...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  saved_models_and_logs\\combined_distilled_quant...   \n",
       "\n",
       "                                                                                             Log_Path  \n",
       "Experiment_ID                                                                                          \n",
       "resnet18_baseline                                    saved_models_and_logs\\resnet18_baseline\\log.json  \n",
       "resnet50_baseline                                    saved_models_and_logs\\resnet50_baseline\\log.json  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  saved_models_and_logs\\combined_distilled_quant...  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  saved_models_and_logs\\combined_distilled_quant...  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  saved_models_and_logs\\combined_distilled_quant...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def discover_experiments_nb():\n",
    "    print(f\"--- Discovering experiments in: {ROOT_DIR} ---\")\n",
    "    discovered_experiments = []\n",
    "    if not os.path.exists(ROOT_DIR):\n",
    "        print(f\"ERROR: ROOT_DIR '{ROOT_DIR}' does not exist!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # First, process baselines\n",
    "    for cat_name_outer in os.listdir(ROOT_DIR):\n",
    "        cat_path_outer = os.path.join(ROOT_DIR, cat_name_outer)\n",
    "        if os.path.isdir(cat_path_outer) and (\"baseline\" in cat_name_outer.lower()):\n",
    "            exp_name = cat_name_outer\n",
    "            exp_path = cat_path_outer\n",
    "            \n",
    "            base_arch = \"Unknown\"\n",
    "            if \"resnet18\" in exp_name.lower(): base_arch = \"ResNet18\"\n",
    "            elif \"resnet50\" in exp_name.lower(): base_arch = \"ResNet50\"\n",
    "\n",
    "            model_file = get_model_file_path_nb(exp_path)\n",
    "            log_path = os.path.join(exp_path, \"log.json\")\n",
    "            num_classes = DEFAULT_NUM_CLASSES\n",
    "            config_details, training_summary, original_eval_metrics = {}, {}, {}\n",
    "            if os.path.exists(log_path):\n",
    "                try:\n",
    "                    with open(log_path, 'r') as f: log_data_temp = json.load(f)\n",
    "                    config_details = log_data_temp.get('config_details', {})\n",
    "                    training_summary = log_data_temp.get('training_summary', {})\n",
    "                    original_eval_metrics = log_data_temp.get('original_evaluation_metrics_from_log', {})\n",
    "                    num_classes = config_details.get('num_classes', DEFAULT_NUM_CLASSES)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"    Warning: JSON error in {log_path} for baseline {exp_name}\")\n",
    "                except Exception as e_log_parse_base:\n",
    "                     print(f\"    Warning: Error parsing log {log_path} for baseline {exp_name}: {e_log_parse_base}\")\n",
    "\n",
    "\n",
    "            exp_data = {\n",
    "                \"Experiment_ID\": exp_name,\n",
    "                \"Experiment_Path\": exp_path,\n",
    "                \"Log_Path\": log_path,\n",
    "                \"Model_File_Path\": model_file,\n",
    "                \"Base_Model_Arch\": base_arch,\n",
    "                \"Optimization_Category\": \"Baseline\",\n",
    "                \"Specific_Technique\": \"Baseline\",\n",
    "                \"Key_Parameters\": \"N/A\",\n",
    "                \"Is_Structured_Pruning\": False,\n",
    "                \"Base_Exp_Name_Iterative\": None, # Iterative info not applicable to baselines\n",
    "                \"Stage_Num_Iterative\": None,   # Iterative info not applicable to baselines\n",
    "                \"Num_Classes\": num_classes,\n",
    "                \"Config_Details_From_Log\": config_details,\n",
    "                \"Training_Summary_From_Log\": training_summary,\n",
    "                \"Original_Eval_Metrics_From_Log\": original_eval_metrics\n",
    "            }\n",
    "            discovered_experiments.append(exp_data)\n",
    "\n",
    "    # Then process other experiments\n",
    "    for cat_name in os.listdir(ROOT_DIR):\n",
    "        cat_path = os.path.join(ROOT_DIR, cat_name)\n",
    "        if not os.path.isdir(cat_path) or \"baseline\" in cat_name.lower():\n",
    "            continue\n",
    "\n",
    "        is_cat_structured = \"pruning_structured_iterative\" in cat_name.lower() or \\\n",
    "                            \"pruning_structured_oneshot\" in cat_name.lower()\n",
    "\n",
    "        for exp_name in os.listdir(cat_path):\n",
    "            exp_path_str = os.path.join(cat_path, exp_name) # Use string for Path() later if needed\n",
    "            if not os.path.isdir(exp_path_str):\n",
    "                continue\n",
    "\n",
    "            base_arch = \"ResNet50\" # Default\n",
    "            if \"resnet18\" in exp_name.lower(): base_arch = \"ResNet18\"\n",
    "            if cat_name == \"combined_distilled_quantized\" and \"resnet18\" in exp_name.lower(): base_arch = \"ResNet18\" \n",
    "\n",
    "            model_file = get_model_file_path_nb(exp_path_str)\n",
    "            log_path_str_current = os.path.join(exp_path_str, \"log.json\")\n",
    "            \n",
    "            current_exp_is_structured = is_cat_structured\n",
    "            # More robust check for structured based on experiment name patterns\n",
    "            if not current_exp_is_structured:\n",
    "                if \"prune_struct_it\" in exp_name.lower() or \\\n",
    "                   \"prune_struct_os\" in exp_name.lower() or \\\n",
    "                   \"structured_l1_filter\" in exp_name.lower() or \\\n",
    "                   (base_arch == \"ResNet50\" and (\"pruning_structured\" in cat_name.lower())): # if base is R50 and in struct cat\n",
    "                    current_exp_is_structured = True\n",
    "            \n",
    "            base_exp_name_iterative = None\n",
    "            stage_num_iterative = None\n",
    "            # Check if it's an iterative structured model to parse base name and stage\n",
    "            # This regex tries to capture common patterns like 'name_stageNUMBER...' or 'name_sNUMBER'\n",
    "            if current_exp_is_structured and \\\n",
    "               (\"iterative\" in cat_name.lower() or \"it\" in exp_name.lower() or \"_stage\" in exp_name.lower()):\n",
    "                # Try to match '..._stage<number>...' pattern first\n",
    "                match = re.search(r\"(.+?)(?:_|-)(?:stage|s)(\\d+)\", exp_name.lower())\n",
    "                if match:\n",
    "                    base_exp_name_iterative = match.group(1)\n",
    "                    stage_num_iterative = int(match.group(2))\n",
    "                else: # Fallback if no explicit 'stage' or 's' prefix but seems iterative\n",
    "                    # This part might need refinement based on your specific naming for iterative stages\n",
    "                    # if no clear stage number is found, it won't be treated as iterative by the loader\n",
    "                    # print(f\"  Warning: Could not parse base_name/stage for potential iterative: {exp_name} in {cat_name}\")\n",
    "                    pass\n",
    "            \n",
    "            # Ensure base_arch is correct for structured ResNet50 if not already set\n",
    "            if current_exp_is_structured and base_arch == \"Unknown\" and \"resnet50\" in exp_name.lower():\n",
    "                 base_arch = \"ResNet50\"\n",
    "\n",
    "\n",
    "            num_classes = DEFAULT_NUM_CLASSES\n",
    "            config_details, training_summary, original_eval_metrics, quant_specific_details = {}, {}, {}, {}\n",
    "            specific_tech_parts, key_params_parts = [], []\n",
    "\n",
    "            if os.path.exists(log_path_str_current):\n",
    "                try:\n",
    "                    with open(log_path_str_current, 'r') as f: log_data_temp = json.load(f)\n",
    "                    config_details = log_data_temp.get('config_details', {})\n",
    "                    training_summary = log_data_temp.get('training_summary', {})\n",
    "                    original_eval_metrics = log_data_temp.get('original_evaluation_metrics_from_log', {})\n",
    "                    quant_specific_details = log_data_temp.get('quantization_specific_details', {})\n",
    "                    \n",
    "                    num_classes = config_details.get('num_classes', DEFAULT_NUM_CLASSES)\n",
    "                    if 'student_config' in config_details and isinstance(config_details['student_config'], dict):\n",
    "                        num_classes = config_details['student_config'].get('num_classes', num_classes)\n",
    "\n",
    "                    # --- Populate Specific_Technique, Key_Parameters (from original script) ---\n",
    "                    if config_details.get('teacher_model_architecture'):\n",
    "                        specific_tech_parts.append(\"Knowledge Distillation\")\n",
    "                        teacher = config_details.get('teacher_model_architecture')\n",
    "                        student = config_details.get('student_model_architecture', base_arch)\n",
    "                        key_params_parts.append(f\"T:{teacher}->S:{student}\")\n",
    "                        if base_arch == \"ResNet50\" and \"resnet18\" in student.lower(): base_arch = \"ResNet18\"\n",
    "\n",
    "                    quant_method_cfg = str(config_details.get('quantization_method_type', '')).lower()\n",
    "                    if \"kmeans\" in quant_method_cfg or \"kmeans\" in exp_name.lower():\n",
    "                        specific_tech_parts.append(\"KMeans Quant\")\n",
    "                        clusters = config_details.get('kmeans_clusters') or quant_specific_details.get('kmeans_clusters')\n",
    "                        if clusters: key_params_parts.append(f\"Clusters: {clusters}\")\n",
    "                    elif \"ptq\" in quant_method_cfg or (\"quant\" in exp_name.lower() and \"ptq\" in exp_name.lower()):\n",
    "                        tech = \"PTQ INT8\"\n",
    "                        if \"per_channel\" in quant_method_cfg or \"perchannel\" in exp_name.lower(): tech += \" (Per-Channel)\"\n",
    "                        elif \"per_tensor\" in quant_method_cfg or \"pertensor\" in exp_name.lower(): tech += \" (Per-Tensor)\"\n",
    "                        else: \n",
    "                             if \"perchannel\" in exp_name.lower(): tech += \" (Per-Channel)\"\n",
    "                             elif \"pertensor\" in exp_name.lower(): tech += \" (Per-Tensor)\"\n",
    "                        specific_tech_parts.append(tech)\n",
    "                    elif \"qat\" in quant_method_cfg or (\"quant\" in exp_name.lower() and \"qat\" in exp_name.lower()):\n",
    "                        specific_tech_parts.append(\"QAT INT8\")\n",
    "                        epochs = config_details.get('qat_epochs')\n",
    "                        if epochs is not None: key_params_parts.append(f\"QAT Epochs: {epochs}\")\n",
    "\n",
    "                    pruning_tech_exp_name = exp_name.lower()\n",
    "                    pruning_method_cfg = config_details.get('pruning_method_name', '').lower()\n",
    "                    pruning_strat_cfg = config_details.get('pruning_strategy_type', '').lower()\n",
    "                    \n",
    "                    # Check if specifically structured from name or config\n",
    "                    is_exp_name_struct_it = \"prune_struct_it\" in pruning_tech_exp_name or \\\n",
    "                                            \"iterative_structured\" in pruning_strat_cfg or \\\n",
    "                                            (base_exp_name_iterative is not None) # If parsed as iterative\n",
    "                    is_exp_name_struct_os = (\"prune_struct_os\" in pruning_tech_exp_name or \\\n",
    "                                            \"one_shot_structured\" in pruning_strat_cfg or \\\n",
    "                                            \"structured_l1_filter\" in pruning_method_cfg) and \\\n",
    "                                            not is_exp_name_struct_it # Ensure it's not also iterative\n",
    "\n",
    "                    if is_exp_name_struct_it:\n",
    "                        specific_tech_parts.append(\"Iterative Structured Pruning (L1 Filter)\")\n",
    "                        # For iterative, the key_params (rates) are derived from the log of the specific stage\n",
    "                        log_pr_conf = get_pruning_config_from_log_for_reconstruction_nb(Path(log_path_str_current))\n",
    "                        if log_pr_conf and log_pr_conf.get('type') == 'iterative_step': \n",
    "                            key_params_parts.append(f\"Stage Rate: {log_pr_conf['rate']*100:.1f}%\")\n",
    "                        # Also ensure current_exp_is_structured is True\n",
    "                        current_exp_is_structured = True\n",
    "                    elif is_exp_name_struct_os:\n",
    "                        specific_tech_parts.append(\"One-Shot Structured Pruning (L1 Filter)\")\n",
    "                        log_pr_conf = get_pruning_config_from_log_for_reconstruction_nb(Path(log_path_str_current))\n",
    "                        if log_pr_conf and log_pr_conf.get('type') == 'one-shot':\n",
    "                             key_params_parts.append(f\"Rate: {log_pr_conf['rate']*100:.1f}%\")\n",
    "                        current_exp_is_structured = True\n",
    "                    elif \"prune_nm\" in pruning_tech_exp_name or \"nm_sparsity\" in pruning_method_cfg:\n",
    "                        if \"N:M Sparsity\" not in specific_tech_parts: specific_tech_parts.append(\"N:M Sparsity\")\n",
    "                        n_val = config_details.get('nm_sparsity_n', 2); m_val = config_details.get('nm_sparsity_m', 4)\n",
    "                        key_params_parts.append(f\"N:{n_val}, M:{m_val}\")\n",
    "                    elif \"prune_unstruct_it\" in pruning_tech_exp_name or \"iterative_unstructured\" in pruning_strat_cfg:\n",
    "                        specific_tech_parts.append(\"Iterative Unstructured Pruning (L1)\")\n",
    "                    elif \"prune_unstruct_os\" in pruning_tech_exp_name or \"one_shot_unstructured\" in pruning_strat_cfg:\n",
    "                        specific_tech_parts.append(\"One-Shot Unstructured Pruning (L1)\")\n",
    "\n",
    "                    # General pruning sparsity parameter if not specifically handled by structured\n",
    "                    if any(\"Pruning\" in tech for tech in specific_tech_parts) and not (is_exp_name_struct_it or is_exp_name_struct_os):\n",
    "                        target_sparsities = [\n",
    "                            config_details.get('target_overall_sparsity_approx_for_this_stage'),\n",
    "                            # config_details.get('target_filter_pruning_rate_per_layer'), # Usually for structured\n",
    "                            config_details.get('target_sparsity_for_this_stage'),\n",
    "                            config_details.get('target_sparsity')\n",
    "                        ]\n",
    "                        for sp_val in target_sparsities:\n",
    "                            if sp_val is not None:\n",
    "                                try: key_params_parts.append(f\"Target Sparsity: {float(sp_val)*100:.1f}%\")\n",
    "                                except ValueError: key_params_parts.append(f\"Target Sparsity: {sp_val}\")\n",
    "                                break\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"    Warning: JSON error in {log_path_str_current} for {exp_name}\")\n",
    "                except Exception as e_log_parse:\n",
    "                    print(f\"    Warning: Error parsing log {log_path_str_current} for {exp_name}: {e_log_parse}\")\n",
    "\n",
    "\n",
    "            opt_cat_map = {\n",
    "                \"combined_distilled_quantized\": \"Combined\", \"knowledge_distillation\": \"Knowledge Distillation\",\n",
    "                \"pruning_nm_sparsity\": \"Pruning\", \"pruning_structured_iterative\": \"Pruning\",\n",
    "                \"pruning_structured_oneshot\": \"Pruning\", \"pruning_unstructured_iterative\": \"Pruning\",\n",
    "                \"pruning_unstructured_oneshot\": \"Pruning\", \"quantization_kmeans\": \"Quantization\",\n",
    "                \"quantization_ptq_int8\": \"Quantization\", \"quantization_qat_int8\": \"Quantization\",\n",
    "            }\n",
    "            optimization_category = opt_cat_map.get(cat_name, \"Other\")\n",
    "\n",
    "\n",
    "            exp_data = {\n",
    "                \"Experiment_ID\": exp_name,\n",
    "                \"Experiment_Path\": exp_path_str,\n",
    "                \"Log_Path\": log_path_str_current,\n",
    "                \"Model_File_Path\": model_file,\n",
    "                \"Base_Model_Arch\": base_arch,\n",
    "                \"Optimization_Category\": optimization_category,\n",
    "                \"Specific_Technique\": \" + \".join(list(dict.fromkeys(specific_tech_parts))) if specific_tech_parts else \"Other\",\n",
    "                \"Key_Parameters\": \"; \".join(list(dict.fromkeys(key_params_parts))) if key_params_parts else \"N/A\", # Remove duplicates\n",
    "                \"Is_Structured_Pruning\": current_exp_is_structured,\n",
    "                \"Base_Exp_Name_Iterative\": base_exp_name_iterative,\n",
    "                \"Stage_Num_Iterative\": stage_num_iterative,      \n",
    "                \"Num_Classes\": num_classes,\n",
    "                \"Config_Details_From_Log\": config_details, \n",
    "                \"Training_Summary_From_Log\": training_summary,\n",
    "                \"Original_Eval_Metrics_From_Log\": original_eval_metrics\n",
    "            }\n",
    "            discovered_experiments.append(exp_data)\n",
    "\n",
    "    df = pd.DataFrame(discovered_experiments)\n",
    "    if not df.empty:\n",
    "        # Ensure Stage_Num_Iterative is numeric for sorting, NaNs are fine\n",
    "        if 'Stage_Num_Iterative' in df.columns:\n",
    "             df['Stage_Num_Iterative'] = pd.to_numeric(df['Stage_Num_Iterative'], errors='coerce')\n",
    "        df = df.set_index(\"Experiment_ID\", drop=False) # Keep Experiment_ID also as a column\n",
    "    print(f\"--- Discovery finished. Found {len(df)} experiments. ---\")\n",
    "    return df\n",
    "\n",
    "# Initialize/Re-initialize the global DataFrame\n",
    "results_df = discover_experiments_nb() # This will be the single source of truth for experiment info\n",
    "if not results_df.empty:\n",
    "    # Display new columns for verification, especially for iterative models\n",
    "    iterative_check_df = results_df[results_df['Base_Exp_Name_Iterative'].notna()]\n",
    "    if not iterative_check_df.empty:\n",
    "        print(\"\\n--- Iterative Model Parsing Check (sample): ---\")\n",
    "        display(iterative_check_df[['Experiment_ID', 'Base_Exp_Name_Iterative', 'Stage_Num_Iterative', 'Log_Path']].head())\n",
    "    else:\n",
    "        print(\"\\n--- No iterative models parsed with Base_Exp_Name_Iterative. ---\")\n",
    "    \n",
    "    print(\"\\n--- All Discovered Experiments Sample: ---\")\n",
    "    display(results_df[['Experiment_ID', 'Base_Model_Arch', 'Is_Structured_Pruning', 'Model_File_Path', 'Log_Path']].head())\n",
    "\n",
    "else:\n",
    "    print(\"No experiments discovered. Check ROOT_DIR and folder structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c73c382",
   "metadata": {},
   "source": [
    "Cell 5: Calculate Model Disk Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc136f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Model Disk Sizes ---\n",
      "--- Disk sizes calculated and stored. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Model_Size_MB_Disk</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>44.669577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>97.796141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>44.667328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>11.302094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>11.300758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                    Model_Size_MB_Disk  \n",
       "Experiment_ID                                                           \n",
       "resnet18_baseline                                            44.669577  \n",
       "resnet50_baseline                                            97.796141  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...           44.667328  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...           11.302094  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...           11.300758  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_and_store_disk_sizes(df_to_update):\n",
    "    if df_to_update.empty:\n",
    "        print(\"Experiment DataFrame is empty. Run discovery cell first.\")\n",
    "        return\n",
    "    print(\"\\n--- Calculating Model Disk Sizes ---\")\n",
    "    sizes_mb = {}\n",
    "    for exp_id, row in df_to_update.iterrows():\n",
    "        model_file = row.get('Model_File_Path')\n",
    "        size = get_model_size_mb_nb(model_file)\n",
    "        sizes_mb[exp_id] = size if size is not None else \"N/A (File Missing/Error)\"\n",
    "        if exp_id.startswith(\"baseline\") and size is not None and pd.notna(size): # For baselines_metrics_nb\n",
    "             if row['Base_Model_Arch'] not in baseline_metrics_nb: baseline_metrics_nb[row['Base_Model_Arch']] = {}\n",
    "             baseline_metrics_nb[row['Base_Model_Arch']]['model_size_mb_disk'] = size\n",
    "\n",
    "\n",
    "    df_to_update['Model_Size_MB_Disk'] = pd.Series(sizes_mb)\n",
    "    print(\"--- Disk sizes calculated and stored. ---\")\n",
    "    display(df_to_update[['Experiment_ID', 'Model_Size_MB_Disk']].head())\n",
    "\n",
    "if not results_df.empty:\n",
    "    calculate_and_store_disk_sizes(results_df)\n",
    "else:\n",
    "    print(\"Skipping disk size calculation as no experiments were discovered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ba539",
   "metadata": {},
   "source": [
    "Cell 6: Calculate FLOPs and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e118cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating FLOPs and Parameters ---\n",
      "  Processing FLOPs/Params for: resnet18_baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\Temp\\ipykernel_19588\\744690716.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _raw_loaded_content = torch.load(model_path, map_location=device_to_load_on) # weights_only=False default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing FLOPs/Params for: resnet50_baseline\n",
      "  Processing FLOPs/Params for: resnet18pretrained_distilled_quant_kmeans_256clusters_post\n",
      "  Processing FLOPs/Params for: resnet18pretrained_distilled_quant_ptq_int8_perchannel_post\n",
      "  Processing FLOPs/Params for: resnet18pretrained_distilled_quant_ptq_int8_pertensor_post\n",
      "  Processing FLOPs/Params for: resnet18pretrained_distilled_quant_qat_int8_epochs8\n",
      "  Processing FLOPs/Params for: resnet50_to_resnet18pretrained_kd\n",
      "  Processing FLOPs/Params for: resnet50_to_resnet18scratch_kd\n",
      "  Processing FLOPs/Params for: resnet50_prune_nm24_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_struct_os_l1filter_fp30_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_struct_os_l1filter_fp55_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_struct_os_l1filter_fp70_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_unstruct_it_l1_stage1_sp50_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_unstruct_it_l1_stage2_sp75_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_unstruct_it_l1_stage3_sp90_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_unstruct_os_l1_sp50_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_unstruct_os_l1_sp75_ft\n",
      "  Processing FLOPs/Params for: resnet50_prune_unstruct_os_l1_sp90_ft\n",
      "  Processing FLOPs/Params for: resnet50_quant_kmeans_256clusters_post\n",
      "  Processing FLOPs/Params for: resnet50_quant_ptq_int8_perchannel_post\n",
      "  Processing FLOPs/Params for: resnet50_quant_ptq_int8_pertensor_post\n",
      "  Processing FLOPs/Params for: resnet50_quant_qat_int8_epochs8\n",
      "--- FLOPs and Parameters calculated and stored. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>FLOPs_GMACs</th>\n",
       "      <th>Params_Millions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>1.824034</td>\n",
       "      <td>11.689512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>4.133743</td>\n",
       "      <td>25.557032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>1.824034</td>\n",
       "      <td>11.689512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>N/A (JIT, thop N/A)</td>\n",
       "      <td>N/A (JIT, thop N/A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>N/A (JIT, thop N/A)</td>\n",
       "      <td>N/A (JIT, thop N/A)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                            FLOPs_GMACs  \\\n",
       "Experiment_ID                                                             \n",
       "resnet18_baseline                                              1.824034   \n",
       "resnet50_baseline                                              4.133743   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...             1.824034   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  N/A (JIT, thop N/A)   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  N/A (JIT, thop N/A)   \n",
       "\n",
       "                                                        Params_Millions  \n",
       "Experiment_ID                                                            \n",
       "resnet18_baseline                                             11.689512  \n",
       "resnet50_baseline                                             25.557032  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...            11.689512  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  N/A (JIT, thop N/A)  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  N/A (JIT, thop N/A)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_and_store_flops_params(df_to_update):\n",
    "    if df_to_update.empty:\n",
    "        print(\"Experiment DataFrame is empty. Run discovery cell first.\")\n",
    "        return\n",
    "    print(\"\\n--- Calculating FLOPs and Parameters ---\")\n",
    "    flops_list = {}\n",
    "    params_list = {}\n",
    "\n",
    "    for exp_id, row in df_to_update.iterrows():\n",
    "        print(f\"  Processing FLOPs/Params for: {exp_id}\")\n",
    "        # Load model on CPU for thop, unless it's JIT and we fallback to baseline\n",
    "        # For structured pruning, load_model_for_experiment_nb should reconstruct on CPU if target_device_str='cpu'\n",
    "        model_obj = load_model_for_experiment_nb(row, df_to_update, target_device_str='cpu')\n",
    "        \n",
    "        current_flops = \"N/A (Load Error)\"\n",
    "        current_params = \"N/A (Load Error)\"\n",
    "\n",
    "        if model_obj:\n",
    "            is_jit_module = isinstance(model_obj, torch.jit.ScriptModule)\n",
    "            thop_success = False\n",
    "            if not is_jit_module:\n",
    "                try:\n",
    "                    # Ensure model is on CPU for thop\n",
    "                    model_obj_cpu = model_obj.to(torch.device('cpu'))\n",
    "                    macs, params = profile(model_obj_cpu, inputs=(INPUT_TENSOR_CPU,), verbose=False)\n",
    "                    current_flops = macs / 1e9  # GMACs\n",
    "                    current_params = params / 1e6 # Millions\n",
    "                    thop_success = True\n",
    "                    del model_obj_cpu\n",
    "                except Exception as e_thop:\n",
    "                    # print(f\"      Warning ({exp_id}): thop failed: {e_thop}. Will try fallback.\")\n",
    "                    current_flops = \"N/A (thop Error)\"\n",
    "                    current_params = \"N/A (thop Error)\"\n",
    "            else: # Is JIT\n",
    "                # print(f\"      INFO ({exp_id}): Model is JIT ScriptModule. Skipping thop, will use baseline fallback if applicable.\")\n",
    "                current_flops = \"N/A (JIT, thop N/A)\" # Placeholder before fallback\n",
    "                current_params = \"N/A (JIT, thop N/A)\"\n",
    "\n",
    "            # Fallback for JIT or thop failure (quantized, kmeans, etc.)\n",
    "            is_ao_quant_or_kmeans = \"ptq\" in exp_id.lower() or \\\n",
    "                                    \"qat\" in exp_id.lower() or \\\n",
    "                                    \"kmeans\" in exp_id.lower()\n",
    "            \n",
    "            if (is_jit_module or not thop_success) and (is_ao_quant_or_kmeans or exp_id.startswith(\"baseline\")): # Baselines might be JIT saved\n",
    "                base_arch = row['Base_Model_Arch']\n",
    "                # Try to get baseline from already processed baselines if available\n",
    "                # This part is tricky as baselines themselves are being processed in this loop.\n",
    "                # We rely on baseline_metrics_nb potentially being populated if a baseline was processed by thop *before* this model.\n",
    "                # Or, if this *is* a baseline and thop failed, this fallback won't help for itself.\n",
    "                if base_arch in baseline_metrics_nb and baseline_metrics_nb[base_arch]:\n",
    "                    # print(f\"Attempting fallback to baseline for {exp_id} using {base_arch}\")\n",
    "                    baseline_f = baseline_metrics_nb[base_arch].get(\"flops_gmacs\")\n",
    "                    baseline_p = baseline_metrics_nb[base_arch].get(\"params_millions\")\n",
    "                    if pd.notna(baseline_f) and current_flops.startswith(\"N/A\"): current_flops = baseline_f\n",
    "                    if pd.notna(baseline_p) and current_params.startswith(\"N/A\"): current_params = baseline_p\n",
    "                elif not (current_flops != \"N/A (thop Error)\" and current_flops != \"N/A (Load Error)\"): # If not successfully calculated and no baseline\n",
    "                    current_flops = \"N/A (Fallback Miss)\"\n",
    "                    current_params = \"N/A (Fallback Miss)\"\n",
    "\n",
    "\n",
    "            del model_obj\n",
    "            if DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        flops_list[exp_id] = current_flops\n",
    "        params_list[exp_id] = current_params\n",
    "        \n",
    "        # Store for baseline_metrics_nb if this is a baseline and successfully calculated\n",
    "        if exp_id.startswith(\"baseline\"):\n",
    "            if row['Base_Model_Arch'] not in baseline_metrics_nb: baseline_metrics_nb[row['Base_Model_Arch']] = {}\n",
    "            if pd.notna(current_flops) and isinstance(current_flops, (int,float)):\n",
    "                 baseline_metrics_nb[row['Base_Model_Arch']]['flops_gmacs'] = current_flops\n",
    "            if pd.notna(current_params) and isinstance(current_params, (int,float)):\n",
    "                 baseline_metrics_nb[row['Base_Model_Arch']]['params_millions'] = current_params\n",
    "\n",
    "\n",
    "    df_to_update['FLOPs_GMACs'] = pd.Series(flops_list)\n",
    "    df_to_update['Params_Millions'] = pd.Series(params_list)\n",
    "    print(\"--- FLOPs and Parameters calculated and stored. ---\")\n",
    "    # print(\"DEBUG: baseline_metrics_nb after FLOPs/Params:\", baseline_metrics_nb)\n",
    "    display(df_to_update[['Experiment_ID', 'FLOPs_GMACs', 'Params_Millions']].head())\n",
    "\n",
    "if not results_df.empty:\n",
    "    calculate_and_store_flops_params(results_df)\n",
    "else:\n",
    "    print(\"Skipping FLOPs/Params calculation as no experiments were discovered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26478b29",
   "metadata": {},
   "source": [
    "Cell 7: Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eaef20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Model Accuracies ---\n",
      "  Processing Accuracy for: resnet18_baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\Temp\\ipykernel_19588\\744690716.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _raw_loaded_content = torch.load(model_path, map_location=device_to_load_on) # weights_only=False default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing Accuracy for: resnet50_baseline\n",
      "  Processing Accuracy for: resnet18pretrained_distilled_quant_kmeans_256clusters_post\n",
      "  Processing Accuracy for: resnet18pretrained_distilled_quant_ptq_int8_perchannel_post\n",
      "      INFO (resnet18pretrained_distilled_quant_ptq_int8_perchannel_post): Known GPU unstable. Forcing CPU evaluation.\n",
      "  Processing Accuracy for: resnet18pretrained_distilled_quant_ptq_int8_pertensor_post\n",
      "      INFO (resnet18pretrained_distilled_quant_ptq_int8_pertensor_post): Known GPU unstable. Forcing CPU evaluation.\n",
      "  Processing Accuracy for: resnet18pretrained_distilled_quant_qat_int8_epochs8\n",
      "      INFO (resnet18pretrained_distilled_quant_qat_int8_epochs8): Known GPU unstable. Forcing CPU evaluation.\n",
      "  Processing Accuracy for: resnet50_to_resnet18pretrained_kd\n",
      "  Processing Accuracy for: resnet50_to_resnet18scratch_kd\n",
      "  Processing Accuracy for: resnet50_prune_nm24_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_os_l1filter_fp30_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_os_l1filter_fp55_ft\n",
      "  Processing Accuracy for: resnet50_prune_struct_os_l1filter_fp70_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_it_l1_stage1_sp50_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_it_l1_stage2_sp75_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_it_l1_stage3_sp90_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_os_l1_sp50_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_os_l1_sp75_ft\n",
      "  Processing Accuracy for: resnet50_prune_unstruct_os_l1_sp90_ft\n",
      "  Processing Accuracy for: resnet50_quant_kmeans_256clusters_post\n",
      "  Processing Accuracy for: resnet50_quant_ptq_int8_perchannel_post\n",
      "      INFO (resnet50_quant_ptq_int8_perchannel_post): Known GPU unstable. Forcing CPU evaluation.\n",
      "  Processing Accuracy for: resnet50_quant_ptq_int8_pertensor_post\n",
      "      INFO (resnet50_quant_ptq_int8_pertensor_post): Known GPU unstable. Forcing CPU evaluation.\n",
      "  Processing Accuracy for: resnet50_quant_qat_int8_epochs8\n",
      "      INFO (resnet50_quant_qat_int8_epochs8): Known GPU unstable. Forcing CPU evaluation.\n",
      "--- Accuracies calculated and stored. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Final_Val_Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>50.089217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>64.950293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>53.683406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>50.777466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>53.352027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                    Final_Val_Accuracy  \n",
       "Experiment_ID                                                           \n",
       "resnet18_baseline                                            50.089217  \n",
       "resnet50_baseline                                            64.950293  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...           53.683406  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...           50.777466  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...           53.352027  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define evaluate_model_uniformly (from original script, slightly adapted for notebook context)\n",
    "@torch.no_grad()\n",
    "def evaluate_model_uniformly_nb(model, device_str_eval, num_classes_eval, max_batches_to_eval, exp_id_for_log):\n",
    "    global current_eval_experiment_id_nb # Use the notebook-specific global\n",
    "    current_eval_experiment_id_nb = exp_id_for_log # For logging inside this function\n",
    "\n",
    "    if not os.path.exists(VALIDATION_DATA_PATH):\n",
    "        print(f\"      ERROR ({current_eval_experiment_id_nb}): Val data path not found: {VALIDATION_DATA_PATH}\")\n",
    "        return \"N/A (Val Data Missing)\"\n",
    "    try:\n",
    "        val_dataset = ImageFolder(VALIDATION_DATA_PATH, eval_transforms)\n",
    "        if len(val_dataset.classes) != num_classes_eval and num_classes_eval != FIXED_NUM_CLASSES : # Allow FIXED_NUM_CLASSES for imagenet default\n",
    "             # Only warn if model's num_classes is truly different and not the standard 1000 for ImageNet pretrains\n",
    "            print(f\"      WARNING ({current_eval_experiment_id_nb}): Dataset classes ({len(val_dataset.classes)}) vs Model classes ({num_classes_eval}). Accuracy may be misleading.\")\n",
    "        if len(val_dataset) == 0:\n",
    "            print(f\"      WARNING ({current_eval_experiment_id_nb}): Validation dataset at '{VALIDATION_DATA_PATH}' is empty.\")\n",
    "            return 0.0 # Or \"N/A (Val Data Empty)\"\n",
    "        \n",
    "        # Limit workers for DataLoader if on Windows or for stability\n",
    "        current_num_workers = NUM_WORKERS_EVAL if DEVICE.type == 'cuda' else 0 # Often 0 is safer on Windows\n",
    "\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE_EVAL, shuffle=False,\n",
    "                                num_workers=current_num_workers, pin_memory=(True if device_str_eval=='cuda' else False))\n",
    "    except Exception as e:\n",
    "        print(f\"      ERROR ({current_eval_experiment_id_nb}): Could not load validation data: {e}\")\n",
    "        # traceback.print_exc()\n",
    "        return f\"N/A (Val Data Load Error: {str(e).splitlines()[0]})\"\n",
    "\n",
    "    device_obj_eval = torch.device(device_str_eval)\n",
    "    model.to(device_obj_eval)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batches_processed = 0\n",
    "    \n",
    "    # print(f\"      INFO ({current_eval_experiment_id_nb}): Evaluating on device {device_str_eval} for max {max_batches_to_eval} batches.\")\n",
    "\n",
    "    for images, labels in val_loader:\n",
    "        try:\n",
    "            images, labels = images.to(device_obj_eval), labels.to(device_obj_eval)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            batches_processed += 1\n",
    "            if batches_processed >= max_batches_to_eval:\n",
    "                break\n",
    "        except Exception as e_batch:\n",
    "            print(f\"      ERROR ({current_eval_experiment_id_nb}) during batch {batches_processed} eval: {e_batch}\")\n",
    "            # traceback.print_exc()\n",
    "            return \"N/A (Batch Eval Error)\"\n",
    "\n",
    "    accuracy = (correct / total) * 100.0 if total > 0 else 0.0 # As percentage\n",
    "    # print(f\"      INFO ({current_eval_experiment_id_nb}): Accuracy = {accuracy:.2f}% ({correct}/{total}) on {batches_processed} batches.\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_and_store_accuracy(df_to_update):\n",
    "    if df_to_update.empty:\n",
    "        print(\"Experiment DataFrame is empty. Run discovery cell first.\")\n",
    "        return\n",
    "    if not os.path.exists(VALIDATION_DATA_PATH):\n",
    "        print(f\"ERROR: Validation data path '{VALIDATION_DATA_PATH}' not found. Cannot calculate accuracy.\")\n",
    "        df_to_update['Final_Val_Accuracy'] = \"N/A (Val Data Missing)\"\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Calculating Model Accuracies ---\")\n",
    "    accuracies = {}\n",
    "    for exp_id, row in df_to_update.iterrows():\n",
    "        print(f\"  Processing Accuracy for: {exp_id}\")\n",
    "        \n",
    "        is_gpu_unstable = exp_id in GPU_UNSTABLE_QUANTIZED_MODELS\n",
    "        eval_device_str = 'cpu' if is_gpu_unstable else DEVICE.type\n",
    "        if is_gpu_unstable: print(f\"      INFO ({exp_id}): Known GPU unstable. Forcing CPU evaluation.\")\n",
    "\n",
    "        # Load model onto the evaluation device\n",
    "        model_obj = load_model_for_experiment_nb(row, df_to_update, target_device_str=eval_device_str)\n",
    "        \n",
    "        current_acc = \"N/A (Load Error)\"\n",
    "        if model_obj:\n",
    "            num_classes = row.get('Num_Classes', DEFAULT_NUM_CLASSES)\n",
    "            # The model_obj from load_model_for_experiment_nb is already on eval_device_str\n",
    "            current_acc = evaluate_model_uniformly_nb(model_obj, eval_device_str, num_classes, MAX_EVAL_BATCHES, exp_id)\n",
    "            \n",
    "            del model_obj\n",
    "            if DEVICE.type == 'cuda': torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        accuracies[exp_id] = current_acc\n",
    "        if exp_id.startswith(\"baseline\") and isinstance(current_acc, (float, int)): # For baselines_metrics_nb\n",
    "            if row['Base_Model_Arch'] not in baseline_metrics_nb: baseline_metrics_nb[row['Base_Model_Arch']] = {}\n",
    "            baseline_metrics_nb[row['Base_Model_Arch']]['val_accuracy'] = current_acc\n",
    "\n",
    "\n",
    "    df_to_update['Final_Val_Accuracy'] = pd.Series(accuracies)\n",
    "    print(\"--- Accuracies calculated and stored. ---\")\n",
    "    # print(\"DEBUG: baseline_metrics_nb after Accuracy:\", baseline_metrics_nb)\n",
    "    display(df_to_update[['Experiment_ID', 'Final_Val_Accuracy']].head())\n",
    "\n",
    "if not results_df.empty:\n",
    "    calculate_and_store_accuracy(results_df)\n",
    "else:\n",
    "    print(\"Skipping accuracy calculation as no experiments were discovered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3cc3ce",
   "metadata": {},
   "source": [
    "Cell 8: Calculate CPU Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b6d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating CPU Inference Times ---\n",
      "  Processing CPU Time for: resnet18_baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\Temp\\ipykernel_19588\\744690716.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _raw_loaded_content = torch.load(model_path, map_location=device_to_load_on) # weights_only=False default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing CPU Time for: resnet50_baseline\n",
      "  Processing CPU Time for: resnet18pretrained_distilled_quant_kmeans_256clusters_post\n",
      "  Processing CPU Time for: resnet18pretrained_distilled_quant_ptq_int8_perchannel_post\n",
      "  Processing CPU Time for: resnet18pretrained_distilled_quant_ptq_int8_pertensor_post\n",
      "  Processing CPU Time for: resnet18pretrained_distilled_quant_qat_int8_epochs8\n",
      "  Processing CPU Time for: resnet50_to_resnet18pretrained_kd\n",
      "  Processing CPU Time for: resnet50_to_resnet18scratch_kd\n",
      "  Processing CPU Time for: resnet50_prune_nm24_ft\n",
      "  Processing CPU Time for: resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft\n",
      "  Processing CPU Time for: resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft\n",
      "  Processing CPU Time for: resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft\n",
      "  Processing CPU Time for: resnet50_prune_struct_os_l1filter_fp30_ft\n",
      "  Processing CPU Time for: resnet50_prune_struct_os_l1filter_fp55_ft\n",
      "  Processing CPU Time for: resnet50_prune_struct_os_l1filter_fp70_ft\n",
      "  Processing CPU Time for: resnet50_prune_unstruct_it_l1_stage1_sp50_ft\n",
      "  Processing CPU Time for: resnet50_prune_unstruct_it_l1_stage2_sp75_ft\n",
      "  Processing CPU Time for: resnet50_prune_unstruct_it_l1_stage3_sp90_ft\n",
      "  Processing CPU Time for: resnet50_prune_unstruct_os_l1_sp50_ft\n",
      "  Processing CPU Time for: resnet50_prune_unstruct_os_l1_sp75_ft\n",
      "  Processing CPU Time for: resnet50_prune_unstruct_os_l1_sp90_ft\n",
      "  Processing CPU Time for: resnet50_quant_kmeans_256clusters_post\n",
      "  Processing CPU Time for: resnet50_quant_ptq_int8_perchannel_post\n",
      "  Processing CPU Time for: resnet50_quant_ptq_int8_pertensor_post\n",
      "  Processing CPU Time for: resnet50_quant_qat_int8_epochs8\n",
      "--- CPU Inference Times calculated and stored. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Inference_Time_ms_CPU (Batch 1)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>35.31372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>88.06000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>37.22856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>19.01976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>18.31738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                    Inference_Time_ms_CPU (Batch 1)  \n",
       "Experiment_ID                                                                        \n",
       "resnet18_baseline                                                          35.31372  \n",
       "resnet50_baseline                                                          88.06000  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                         37.22856  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                         19.01976  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                         18.31738  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_and_store_cpu_inference_time(df_to_update):\n",
    "    if df_to_update.empty:\n",
    "        print(\"Experiment DataFrame is empty. Run discovery cell first.\")\n",
    "        return\n",
    "    print(\"\\n--- Calculating CPU Inference Times ---\")\n",
    "    cpu_times = {}\n",
    "\n",
    "    for exp_id, row in df_to_update.iterrows():\n",
    "        print(f\"  Processing CPU Time for: {exp_id}\")\n",
    "        # Load model on CPU\n",
    "        model_obj = load_model_for_experiment_nb(row, df_to_update, target_device_str='cpu')\n",
    "        \n",
    "        current_cpu_time = \"N/A (Load Error)\"\n",
    "        if model_obj:\n",
    "            try:\n",
    "                model_obj.eval() # Ensure eval mode\n",
    "                with torch.no_grad():\n",
    "                    for _ in range(WARMUP_INFERENCES): _ = model_obj(INPUT_TENSOR_CPU)\n",
    "                    \n",
    "                    timings = []\n",
    "                    for _ in range(TIMED_INFERENCES):\n",
    "                        start_time = time.perf_counter()\n",
    "                        _ = model_obj(INPUT_TENSOR_CPU)\n",
    "                        end_time = time.perf_counter()\n",
    "                        timings.append((end_time - start_time) * 1000) # milliseconds\n",
    "                    current_cpu_time = sum(timings) / len(timings) if timings else \"N/A (Timing Error)\"\n",
    "            except Exception as e_cpu_time:\n",
    "                current_cpu_time = f\"N/A (CPU Time Error: {str(e_cpu_time).splitlines()[0]})\"\n",
    "            \n",
    "            del model_obj\n",
    "            # No CUDA cache clear needed for CPU, but gc.collect is good\n",
    "            gc.collect()\n",
    "            \n",
    "        cpu_times[exp_id] = current_cpu_time\n",
    "        if exp_id.startswith(\"baseline\") and isinstance(current_cpu_time, (float, int)): # For baselines_metrics_nb\n",
    "            if row['Base_Model_Arch'] not in baseline_metrics_nb: baseline_metrics_nb[row['Base_Model_Arch']] = {}\n",
    "            baseline_metrics_nb[row['Base_Model_Arch']]['inference_cpu_ms'] = current_cpu_time\n",
    "\n",
    "\n",
    "    df_to_update['Inference_Time_ms_CPU (Batch 1)'] = pd.Series(cpu_times)\n",
    "    print(\"--- CPU Inference Times calculated and stored. ---\")\n",
    "    # print(\"DEBUG: baseline_metrics_nb after CPU Time:\", baseline_metrics_nb)\n",
    "    display(df_to_update[['Experiment_ID', 'Inference_Time_ms_CPU (Batch 1)']].head())\n",
    "\n",
    "if not results_df.empty:\n",
    "    calculate_and_store_cpu_inference_time(results_df)\n",
    "else:\n",
    "    print(\"Skipping CPU inference time calculation as no experiments were discovered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba57238",
   "metadata": {},
   "source": [
    "Cell 9: Calculate GPU Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc10b579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating GPU Inference Times ---\n",
      "  Processing GPU Time for: resnet18_baseline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad\\AppData\\Local\\Temp\\ipykernel_19588\\744690716.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  _raw_loaded_content = torch.load(model_path, map_location=device_to_load_on) # weights_only=False default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing GPU Time for: resnet50_baseline\n",
      "  Processing GPU Time for: resnet18pretrained_distilled_quant_kmeans_256clusters_post\n",
      "  Processing GPU Time for: resnet18pretrained_distilled_quant_ptq_int8_perchannel_post\n",
      "      INFO (resnet18pretrained_distilled_quant_ptq_int8_perchannel_post): Known JIT GPU unstable. Skipping GPU timing.\n",
      "  Processing GPU Time for: resnet18pretrained_distilled_quant_ptq_int8_pertensor_post\n",
      "      INFO (resnet18pretrained_distilled_quant_ptq_int8_pertensor_post): Known JIT GPU unstable. Skipping GPU timing.\n",
      "  Processing GPU Time for: resnet18pretrained_distilled_quant_qat_int8_epochs8\n",
      "      INFO (resnet18pretrained_distilled_quant_qat_int8_epochs8): Known JIT GPU unstable. Skipping GPU timing.\n",
      "  Processing GPU Time for: resnet50_to_resnet18pretrained_kd\n",
      "  Processing GPU Time for: resnet50_to_resnet18scratch_kd\n",
      "  Processing GPU Time for: resnet50_prune_nm24_ft\n",
      "  Processing GPU Time for: resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft\n",
      "  Processing GPU Time for: resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft\n",
      "  Processing GPU Time for: resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft\n",
      "  Processing GPU Time for: resnet50_prune_struct_os_l1filter_fp30_ft\n",
      "  Processing GPU Time for: resnet50_prune_struct_os_l1filter_fp55_ft\n",
      "  Processing GPU Time for: resnet50_prune_struct_os_l1filter_fp70_ft\n",
      "  Processing GPU Time for: resnet50_prune_unstruct_it_l1_stage1_sp50_ft\n",
      "  Processing GPU Time for: resnet50_prune_unstruct_it_l1_stage2_sp75_ft\n",
      "  Processing GPU Time for: resnet50_prune_unstruct_it_l1_stage3_sp90_ft\n",
      "  Processing GPU Time for: resnet50_prune_unstruct_os_l1_sp50_ft\n",
      "  Processing GPU Time for: resnet50_prune_unstruct_os_l1_sp75_ft\n",
      "  Processing GPU Time for: resnet50_prune_unstruct_os_l1_sp90_ft\n",
      "  Processing GPU Time for: resnet50_quant_kmeans_256clusters_post\n",
      "  Processing GPU Time for: resnet50_quant_ptq_int8_perchannel_post\n",
      "      INFO (resnet50_quant_ptq_int8_perchannel_post): Known JIT GPU unstable. Skipping GPU timing.\n",
      "  Processing GPU Time for: resnet50_quant_ptq_int8_pertensor_post\n",
      "      INFO (resnet50_quant_ptq_int8_pertensor_post): Known JIT GPU unstable. Skipping GPU timing.\n",
      "  Processing GPU Time for: resnet50_quant_qat_int8_epochs8\n",
      "      INFO (resnet50_quant_qat_int8_epochs8): Known JIT GPU unstable. Skipping GPU timing.\n",
      "--- GPU Inference Times calculated and stored. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Inference_Time_ms_GPU (Batch 1)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>3.52352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>7.87376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>3.33568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>N/A (Known JIT GPU Unstable)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>N/A (Known JIT GPU Unstable)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                   Inference_Time_ms_GPU (Batch 1)  \n",
       "Experiment_ID                                                                       \n",
       "resnet18_baseline                                                          3.52352  \n",
       "resnet50_baseline                                                          7.87376  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                         3.33568  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...    N/A (Known JIT GPU Unstable)  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...    N/A (Known JIT GPU Unstable)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_and_store_gpu_inference_time(df_to_update):\n",
    "    if df_to_update.empty:\n",
    "        print(\"Experiment DataFrame is empty. Run discovery cell first.\")\n",
    "        return\n",
    "    if DEVICE.type != 'cuda' or INPUT_TENSOR_GPU is None:\n",
    "        print(\"CUDA not available or INPUT_TENSOR_GPU not initialized. Skipping GPU inference times.\")\n",
    "        df_to_update['Inference_Time_ms_GPU (Batch 1)'] = \"N/A (CUDA unavailable or init error)\"\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Calculating GPU Inference Times ---\")\n",
    "    gpu_times = {}\n",
    "\n",
    "    for exp_id, row in df_to_update.iterrows():\n",
    "        print(f\"  Processing GPU Time for: {exp_id}\")\n",
    "        \n",
    "        if exp_id in GPU_UNSTABLE_QUANTIZED_MODELS:\n",
    "            print(f\"      INFO ({exp_id}): Known JIT GPU unstable. Skipping GPU timing.\")\n",
    "            gpu_times[exp_id] = \"N/A (Known JIT GPU Unstable)\"\n",
    "            continue\n",
    "\n",
    "        # Load model on GPU\n",
    "        model_obj = load_model_for_experiment_nb(row, df_to_update, target_device_str='cuda')\n",
    "        current_gpu_time = \"N/A (Load Error)\"\n",
    "\n",
    "        if model_obj:\n",
    "            try:\n",
    "                model_obj.eval() # Ensure eval mode\n",
    "                with torch.no_grad():\n",
    "                    for _ in range(WARMUP_INFERENCES):\n",
    "                        _ = model_obj(INPUT_TENSOR_GPU)\n",
    "                        torch.cuda.synchronize(DEVICE) # Ensure warmup op is complete\n",
    "                    \n",
    "                    timings = []\n",
    "                    for _ in range(TIMED_INFERENCES):\n",
    "                        torch.cuda.synchronize(DEVICE) # Synchronize before starting timer\n",
    "                        start_time = time.perf_counter()\n",
    "                        _ = model_obj(INPUT_TENSOR_GPU)\n",
    "                        torch.cuda.synchronize(DEVICE) # Synchronize after op to ensure it's complete\n",
    "                        end_time = time.perf_counter()\n",
    "                        timings.append((end_time - start_time) * 1000) # milliseconds\n",
    "                    current_gpu_time = sum(timings) / len(timings) if timings else \"N/A (Timing Error)\"\n",
    "            except Exception as e_gpu_time:\n",
    "                current_gpu_time = f\"N/A (GPU Time Error: {str(e_gpu_time).splitlines()[0]})\"\n",
    "                # traceback.print_exc()\n",
    "            \n",
    "            del model_obj\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        gpu_times[exp_id] = current_gpu_time\n",
    "        if exp_id.startswith(\"baseline\") and isinstance(current_gpu_time, (float, int)): # For baselines_metrics_nb\n",
    "            if row['Base_Model_Arch'] not in baseline_metrics_nb: baseline_metrics_nb[row['Base_Model_Arch']] = {}\n",
    "            baseline_metrics_nb[row['Base_Model_Arch']]['inference_gpu_ms'] = current_gpu_time\n",
    "\n",
    "\n",
    "    df_to_update['Inference_Time_ms_GPU (Batch 1)'] = pd.Series(gpu_times)\n",
    "    print(\"--- GPU Inference Times calculated and stored. ---\")\n",
    "    # print(\"DEBUG: baseline_metrics_nb after GPU Time:\", baseline_metrics_nb)\n",
    "    display(df_to_update[['Experiment_ID', 'Inference_Time_ms_GPU (Batch 1)']].head())\n",
    "\n",
    "if not results_df.empty:\n",
    "    calculate_and_store_gpu_inference_time(results_df)\n",
    "else:\n",
    "    print(\"Skipping GPU inference time calculation as no experiments were discovered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d64755",
   "metadata": {},
   "source": [
    "Cell 10: Add Log-Based Information and Calculate Relative Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d85f6248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Adding Log-Based Information and Calculating Relative Metrics ---\n",
      "  Populated baseline_metrics_nb for relative calculation: {}\n",
      "    Warning: Baseline metrics for ResNet18 not found for exp resnet18pretrained_distilled_quant_kmeans_256clusters_post. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet18 not found for exp resnet18pretrained_distilled_quant_ptq_int8_perchannel_post. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet18 not found for exp resnet18pretrained_distilled_quant_ptq_int8_pertensor_post. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet18 not found for exp resnet18pretrained_distilled_quant_qat_int8_epochs8. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet18 not found for exp resnet50_to_resnet18pretrained_kd. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet18 not found for exp resnet50_to_resnet18scratch_kd. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_nm24_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_struct_it_l1filter_stage1_approx_sp50_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_struct_it_l1filter_stage2_approx_sp75_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_struct_it_l1filter_stage3_approx_sp90_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_struct_os_l1filter_fp30_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_struct_os_l1filter_fp55_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_struct_os_l1filter_fp70_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_unstruct_it_l1_stage1_sp50_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_unstruct_it_l1_stage2_sp75_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_unstruct_it_l1_stage3_sp90_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_unstruct_os_l1_sp50_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_unstruct_os_l1_sp75_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_prune_unstruct_os_l1_sp90_ft. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_quant_kmeans_256clusters_post. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_quant_ptq_int8_perchannel_post. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_quant_ptq_int8_pertensor_post. Skipping relative metrics.\n",
      "    Warning: Baseline metrics for ResNet50 not found for exp resnet50_quant_qat_int8_epochs8. Skipping relative metrics.\n",
      "--- Log-based info added and relative metrics calculated. ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Final_Val_Accuracy</th>\n",
       "      <th>Baseline_Val_Accuracy</th>\n",
       "      <th>Accuracy_Retention_Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>50.089217</td>\n",
       "      <td>50.089217</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>64.950293</td>\n",
       "      <td>64.950293</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>53.683406</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>50.777466</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>53.352027</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                    Final_Val_Accuracy  \\\n",
       "Experiment_ID                                                            \n",
       "resnet18_baseline                                            50.089217   \n",
       "resnet50_baseline                                            64.950293   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...           53.683406   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...           50.777466   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...           53.352027   \n",
       "\n",
       "                                                   Baseline_Val_Accuracy  \\\n",
       "Experiment_ID                                                              \n",
       "resnet18_baseline                                              50.089217   \n",
       "resnet50_baseline                                              64.950293   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                  <NA>   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                  <NA>   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                  <NA>   \n",
       "\n",
       "                                                   Accuracy_Retention_Percent  \n",
       "Experiment_ID                                                                  \n",
       "resnet18_baseline                                                       100.0  \n",
       "resnet50_baseline                                                       100.0  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                       <NA>  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                       <NA>  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                       <NA>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_log_based_and_relative_metrics(df_to_update):\n",
    "    if df_to_update.empty:\n",
    "        print(\"Experiment DataFrame is empty. Cannot add log/relative metrics.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n--- Adding Log-Based Information and Calculating Relative Metrics ---\")\n",
    "\n",
    "    # Columns to extract from logs (if not already present from discovery)\n",
    "    # Some might be slightly different from your original script, adjust as needed\n",
    "    # Training_Summary_From_Log and Original_Eval_Metrics_From_Log are already in df_to_update from discovery\n",
    "    \n",
    "    acc_before_ft_list = {}\n",
    "    model_size_log_list = {}\n",
    "    ach_sparsity_list = {}\n",
    "    ft_epochs_list = {}\n",
    "    ft_time_list = {}\n",
    "    notes_list = {}\n",
    "\n",
    "    for exp_id, row in df_to_update.iterrows():\n",
    "        training_summary = row.get('Training_Summary_From_Log', {})\n",
    "        original_eval_metrics = row.get('Original_Eval_Metrics_From_Log', {})\n",
    "\n",
    "        # Accuracy Before FT\n",
    "        acc_b_ft = training_summary.get('accuracy_before_ft')\n",
    "        if acc_b_ft is None: acc_b_ft = training_summary.get('accuracy_before_ft_this_stage')\n",
    "        if acc_b_ft is None: acc_b_ft = training_summary.get('evaluation_accuracy_after_pruning_before_ft')\n",
    "        acc_before_ft_list[exp_id] = acc_b_ft if acc_b_ft is not None else \"N/A\"\n",
    "        \n",
    "        # Model Size from Log\n",
    "        model_size_log_list[exp_id] = original_eval_metrics.get('model_size_mb', \"N/A\")\n",
    "        \n",
    "        # Achieved Sparsity\n",
    "        ach_sp = training_summary.get('achieved_overall_parameter_sparsity_percent')\n",
    "        if ach_sp is None: ach_sp = training_summary.get('achieved_overall_sparsity_percent_after_stage')\n",
    "        ach_sparsity_list[exp_id] = ach_sp if ach_sp is not None else \"N/A\"\n",
    "        \n",
    "        # FT Epochs\n",
    "        ft_ep = training_summary.get('num_epochs_trained') or training_summary.get('num_epochs_trained_in_stage', 0)\n",
    "        ft_epochs_list[exp_id] = ft_ep if ft_ep is not None else 0\n",
    "        \n",
    "        # FT Time\n",
    "        ft_t = training_summary.get('total_training_time_seconds')\n",
    "        if ft_t is None: ft_t = training_summary.get('total_training_time_seconds_in_stage')\n",
    "        ft_time_list[exp_id] = ft_t if ft_t is not None and ft_epochs_list[exp_id] > 0 else 0.0\n",
    "        \n",
    "        # Notes\n",
    "        notes_list[exp_id] = training_summary.get('notes', '')\n",
    "\n",
    "    df_to_update['Accuracy_Before_FT'] = pd.Series(acc_before_ft_list)\n",
    "    df_to_update['Model_Size_MB_Log'] = pd.Series(model_size_log_list)\n",
    "    df_to_update['Achieved_Sparsity_Percent'] = pd.Series(ach_sparsity_list)\n",
    "    df_to_update['FT_Epochs_Run'] = pd.Series(ft_epochs_list)\n",
    "    df_to_update['FT_Time_seconds'] = pd.Series(ft_time_list)\n",
    "    df_to_update['Notes_from_Log'] = pd.Series(notes_list)\n",
    "    \n",
    "    # --- Calculate Relative Metrics ---\n",
    "    # Ensure baseline_metrics_nb is populated by running previous cells, especially for baselines.\n",
    "    print(\"  Populated baseline_metrics_nb for relative calculation:\", baseline_metrics_nb)\n",
    "\n",
    "    for index, row_series in df_to_update.iterrows():\n",
    "        exp_id = row_series.get(\"Experiment_ID\")\n",
    "        opt_cat_str = str(row_series.get(\"Optimization_Category\",\"\")).strip()\n",
    "        base_model_arch_str = str(row_series.get(\"Base_Model_Arch\", \"\")).strip()\n",
    "\n",
    "        # Determine which baseline arch to use (logic from your script)\n",
    "        baseline_arch_to_use = \"ResNet50\" # Default\n",
    "        if opt_cat_str in [\"Knowledge Distillation\", \"Combined\"] and base_model_arch_str == \"ResNet18\":\n",
    "            baseline_arch_to_use = \"ResNet18\"\n",
    "        elif base_model_arch_str == \"ResNet18\": # If model is ResNet18, compare to ResNet18 baseline\n",
    "            baseline_arch_to_use = \"ResNet18\"\n",
    "        # else: use default ResNet50\n",
    "\n",
    "        if opt_cat_str == \"Baseline\":\n",
    "            # For baselines, their own values are the \"baseline\" values. Reductions are 0, speedups are 1.\n",
    "            df_to_update.loc[index, \"Baseline_Val_Accuracy\"] = pd.to_numeric(row_series.get(\"Final_Val_Accuracy\"), errors='coerce')\n",
    "            df_to_update.loc[index, \"Accuracy_Change_vs_Baseline_pp\"] = 0.0\n",
    "            df_to_update.loc[index, \"Accuracy_Retention_Percent\"] = 100.0\n",
    "            df_to_update.loc[index, \"Baseline_Model_Size_MB_Disk\"] = pd.to_numeric(row_series.get(\"Model_Size_MB_Disk\"), errors='coerce')\n",
    "            df_to_update.loc[index, \"Model_Size_Reduction_vs_Baseline_Percent\"] = 0.0\n",
    "            df_to_update.loc[index, \"Baseline_Params_Millions\"] = pd.to_numeric(row_series.get(\"Params_Millions\"), errors='coerce')\n",
    "            df_to_update.loc[index, \"Params_Reduction_vs_Baseline_Percent\"] = 0.0\n",
    "            df_to_update.loc[index, \"Baseline_FLOPs_GMACs\"] = pd.to_numeric(row_series.get(\"FLOPs_GMACs\"), errors='coerce')\n",
    "            df_to_update.loc[index, \"FLOPs_Reduction_vs_Baseline_Percent\"] = 0.0\n",
    "            df_to_update.loc[index, \"Baseline_Inference_Time_ms_CPU\"] = pd.to_numeric(row_series.get(\"Inference_Time_ms_CPU (Batch 1)\"), errors='coerce')\n",
    "            df_to_update.loc[index, \"Inference_Speedup_vs_Baseline_CPU\"] = 1.0\n",
    "            if DEVICE.type == 'cuda' and \"Baseline_Inference_Time_ms_GPU\" in df_to_update.columns:\n",
    "                df_to_update.loc[index, \"Baseline_Inference_Time_ms_GPU\"] = pd.to_numeric(row_series.get(\"Inference_Time_ms_GPU (Batch 1)\"), errors='coerce')\n",
    "                df_to_update.loc[index, \"Inference_Speedup_vs_Baseline_GPU\"] = 1.0\n",
    "            continue\n",
    "\n",
    "        if baseline_arch_to_use not in baseline_metrics_nb or not baseline_metrics_nb[baseline_arch_to_use]:\n",
    "            print(f\"    Warning: Baseline metrics for {baseline_arch_to_use} not found for exp {exp_id}. Skipping relative metrics.\")\n",
    "            continue\n",
    "        \n",
    "        current_baseline = baseline_metrics_nb[baseline_arch_to_use]\n",
    "        # print(f\"Exp: {exp_id}, Base_Arch_Model: {base_model_arch_str}, Using Baseline: {baseline_arch_to_use}, Metrics: {current_baseline}\")\n",
    "\n",
    "        # Accuracy\n",
    "        baseline_acc = pd.to_numeric(current_baseline.get(\"val_accuracy\"), errors='coerce')\n",
    "        df_to_update.loc[index, \"Baseline_Val_Accuracy\"] = baseline_acc\n",
    "        final_acc = pd.to_numeric(row_series.get(\"Final_Val_Accuracy\"), errors='coerce')\n",
    "        if pd.notna(final_acc) and pd.notna(baseline_acc):\n",
    "            df_to_update.loc[index, \"Accuracy_Change_vs_Baseline_pp\"] = (final_acc - baseline_acc) # Already in pp if acc is %\n",
    "            if baseline_acc != 0: df_to_update.loc[index, \"Accuracy_Retention_Percent\"] = (final_acc / baseline_acc) * 100\n",
    "            else: df_to_update.loc[index, \"Accuracy_Retention_Percent\"] = pd.NA\n",
    "        \n",
    "        # Model Size (Disk)\n",
    "        baseline_size_disk = pd.to_numeric(current_baseline.get(\"model_size_mb_disk\"), errors='coerce')\n",
    "        df_to_update.loc[index, \"Baseline_Model_Size_MB_Disk\"] = baseline_size_disk\n",
    "        model_size_disk = pd.to_numeric(row_series.get(\"Model_Size_MB_Disk\"), errors='coerce')\n",
    "        if pd.notna(model_size_disk) and pd.notna(baseline_size_disk) and baseline_size_disk != 0:\n",
    "            df_to_update.loc[index, \"Model_Size_Reduction_vs_Baseline_Percent\"] = ((baseline_size_disk - model_size_disk) / baseline_size_disk) * 100\n",
    "        \n",
    "        # Params\n",
    "        baseline_params = pd.to_numeric(current_baseline.get(\"params_millions\"), errors='coerce')\n",
    "        df_to_update.loc[index, \"Baseline_Params_Millions\"] = baseline_params\n",
    "        current_params = pd.to_numeric(row_series.get(\"Params_Millions\"), errors='coerce')\n",
    "        if pd.notna(current_params) and pd.notna(baseline_params) and baseline_params != 0:\n",
    "            df_to_update.loc[index, \"Params_Reduction_vs_Baseline_Percent\"] = ((baseline_params - current_params) / baseline_params) * 100\n",
    "\n",
    "        # FLOPs\n",
    "        baseline_flops = pd.to_numeric(current_baseline.get(\"flops_gmacs\"), errors='coerce')\n",
    "        df_to_update.loc[index, \"Baseline_FLOPs_GMACs\"] = baseline_flops\n",
    "        current_flops = pd.to_numeric(row_series.get(\"FLOPs_GMACs\"), errors='coerce')\n",
    "        if pd.notna(current_flops) and pd.notna(baseline_flops) and baseline_flops != 0:\n",
    "            df_to_update.loc[index, \"FLOPs_Reduction_vs_Baseline_Percent\"] = ((baseline_flops - current_flops) / baseline_flops) * 100\n",
    "\n",
    "        # CPU Inference Time\n",
    "        baseline_infer_cpu = pd.to_numeric(current_baseline.get(\"inference_cpu_ms\"), errors='coerce')\n",
    "        df_to_update.loc[index, \"Baseline_Inference_Time_ms_CPU\"] = baseline_infer_cpu\n",
    "        infer_cpu = pd.to_numeric(row_series.get(\"Inference_Time_ms_CPU (Batch 1)\"), errors='coerce')\n",
    "        if pd.notna(infer_cpu) and pd.notna(baseline_infer_cpu) and infer_cpu != 0:\n",
    "            df_to_update.loc[index, \"Inference_Speedup_vs_Baseline_CPU\"] = baseline_infer_cpu / infer_cpu\n",
    "        \n",
    "        # GPU Inference Time\n",
    "        if DEVICE.type == 'cuda' and \"Baseline_Inference_Time_ms_GPU\" in df_to_update.columns:\n",
    "            baseline_infer_gpu = pd.to_numeric(current_baseline.get(\"inference_gpu_ms\"), errors='coerce')\n",
    "            df_to_update.loc[index, \"Baseline_Inference_Time_ms_GPU\"] = baseline_infer_gpu\n",
    "            infer_gpu = pd.to_numeric(row_series.get(\"Inference_Time_ms_GPU (Batch 1)\"), errors='coerce')\n",
    "            if pd.notna(infer_gpu) and pd.notna(baseline_infer_gpu) and infer_gpu != 0:\n",
    "                df_to_update.loc[index, \"Inference_Speedup_vs_Baseline_GPU\"] = baseline_infer_gpu / infer_gpu\n",
    "    \n",
    "    print(\"--- Log-based info added and relative metrics calculated. ---\")\n",
    "    display(df_to_update[['Experiment_ID', 'Final_Val_Accuracy', 'Baseline_Val_Accuracy', 'Accuracy_Retention_Percent']].head())\n",
    "\n",
    "\n",
    "if not results_df.empty:\n",
    "    # Ensure all desired columns exist before calculating relative metrics\n",
    "    desired_columns_final = [\n",
    "        \"Experiment_ID\", \"Base_Model_Arch\", \"Optimization_Category\", \"Specific_Technique\", \"Key_Parameters\",\n",
    "        \"Final_Val_Accuracy\", \"Accuracy_Drop_From_Best_Epoch_pp\", \"Accuracy_Before_FT\", # Accuracy_Drop_From_Best_Epoch_pp is still N/A\n",
    "        \"Model_Size_MB_Disk\", \"Model_Size_MB_Log\",\n",
    "        \"Params_Millions\", \"FLOPs_GMACs\",\n",
    "        \"Achieved_Sparsity_Percent\", \"FT_Epochs_Run\", \"FT_Time_seconds\",\n",
    "        \"Inference_Time_ms_CPU (Batch 1)\", \"Inference_Time_ms_GPU (Batch 1)\", \"Notes_from_Log\",\n",
    "        \"Baseline_Val_Accuracy\", \"Accuracy_Change_vs_Baseline_pp\", \"Accuracy_Retention_Percent\",\n",
    "        \"Baseline_Model_Size_MB_Disk\", \"Model_Size_Reduction_vs_Baseline_Percent\",\n",
    "        \"Baseline_Params_Millions\", \"Params_Reduction_vs_Baseline_Percent\",\n",
    "        \"Baseline_FLOPs_GMACs\", \"FLOPs_Reduction_vs_Baseline_Percent\",\n",
    "        \"Baseline_Inference_Time_ms_CPU\", \"Inference_Speedup_vs_Baseline_CPU\"\n",
    "    ]\n",
    "    if DEVICE.type == 'cuda':\n",
    "        desired_columns_final.extend([\"Baseline_Inference_Time_ms_GPU\", \"Inference_Speedup_vs_Baseline_GPU\"])\n",
    "\n",
    "    for col in desired_columns_final:\n",
    "        if col not in results_df.columns:\n",
    "            results_df[col] = pd.NA # Use pandas' NA\n",
    "\n",
    "    add_log_based_and_relative_metrics(results_df)\n",
    "    results_df = results_df.reindex(columns=desired_columns_final) # Reorder and ensure all are present\n",
    "else:\n",
    "    print(\"Skipping log/relative metrics as no experiments were discovered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b18b4",
   "metadata": {},
   "source": [
    "Cell 11: Final Review and Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de9d342d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final DataFrame Review (First 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th>Base_Model_Arch</th>\n",
       "      <th>Optimization_Category</th>\n",
       "      <th>Specific_Technique</th>\n",
       "      <th>Key_Parameters</th>\n",
       "      <th>Final_Val_Accuracy</th>\n",
       "      <th>Accuracy_Drop_From_Best_Epoch_pp</th>\n",
       "      <th>Accuracy_Before_FT</th>\n",
       "      <th>Model_Size_MB_Disk</th>\n",
       "      <th>Model_Size_MB_Log</th>\n",
       "      <th>...</th>\n",
       "      <th>Baseline_Model_Size_MB_Disk</th>\n",
       "      <th>Model_Size_Reduction_vs_Baseline_Percent</th>\n",
       "      <th>Baseline_Params_Millions</th>\n",
       "      <th>Params_Reduction_vs_Baseline_Percent</th>\n",
       "      <th>Baseline_FLOPs_GMACs</th>\n",
       "      <th>FLOPs_Reduction_vs_Baseline_Percent</th>\n",
       "      <th>Baseline_Inference_Time_ms_CPU</th>\n",
       "      <th>Inference_Speedup_vs_Baseline_CPU</th>\n",
       "      <th>Baseline_Inference_Time_ms_GPU</th>\n",
       "      <th>Inference_Speedup_vs_Baseline_GPU</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resnet18_baseline</th>\n",
       "      <td>resnet18_baseline</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>N/A</td>\n",
       "      <td>50.0892</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>44.6696</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.6895</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.8240</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>35.3137</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.5235</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet50_baseline</th>\n",
       "      <td>resnet50_baseline</td>\n",
       "      <td>ResNet50</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>N/A</td>\n",
       "      <td>64.9503</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.7961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>97.7961</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>25.5570</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.1337</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>88.0600</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.8738</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_kmeans_256clusters_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_kmeans_256c...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Combined</td>\n",
       "      <td>KMeans Quant</td>\n",
       "      <td>Clusters: 256</td>\n",
       "      <td>53.6834</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6673</td>\n",
       "      <td>44.6673</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_perchannel_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Combined</td>\n",
       "      <td>PTQ INT8 (Per-Channel)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>50.7775</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.3021</td>\n",
       "      <td>11.3021</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resnet18pretrained_distilled_quant_ptq_int8_pertensor_post</th>\n",
       "      <td>resnet18pretrained_distilled_quant_ptq_int8_pe...</td>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Combined</td>\n",
       "      <td>PTQ INT8 (Per-Tensor)</td>\n",
       "      <td>N/A</td>\n",
       "      <td>53.3520</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.3008</td>\n",
       "      <td>11.3008</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Experiment_ID  \\\n",
       "Experiment_ID                                                                                           \n",
       "resnet18_baseline                                                                   resnet18_baseline   \n",
       "resnet50_baseline                                                                   resnet50_baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  resnet18pretrained_distilled_quant_kmeans_256c...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  resnet18pretrained_distilled_quant_ptq_int8_pe...   \n",
       "\n",
       "                                                   Base_Model_Arch  \\\n",
       "Experiment_ID                                                        \n",
       "resnet18_baseline                                         ResNet18   \n",
       "resnet50_baseline                                         ResNet50   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...        ResNet18   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...        ResNet18   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...        ResNet18   \n",
       "\n",
       "                                                   Optimization_Category  \\\n",
       "Experiment_ID                                                              \n",
       "resnet18_baseline                                               Baseline   \n",
       "resnet50_baseline                                               Baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...              Combined   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...              Combined   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...              Combined   \n",
       "\n",
       "                                                        Specific_Technique  \\\n",
       "Experiment_ID                                                                \n",
       "resnet18_baseline                                                 Baseline   \n",
       "resnet50_baseline                                                 Baseline   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...            KMeans Quant   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...  PTQ INT8 (Per-Channel)   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...   PTQ INT8 (Per-Tensor)   \n",
       "\n",
       "                                                   Key_Parameters  \\\n",
       "Experiment_ID                                                       \n",
       "resnet18_baseline                                             N/A   \n",
       "resnet50_baseline                                             N/A   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...  Clusters: 256   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...            N/A   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...            N/A   \n",
       "\n",
       "                                                    Final_Val_Accuracy  \\\n",
       "Experiment_ID                                                            \n",
       "resnet18_baseline                                              50.0892   \n",
       "resnet50_baseline                                              64.9503   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...             53.6834   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...             50.7775   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...             53.3520   \n",
       "\n",
       "                                                   Accuracy_Drop_From_Best_Epoch_pp  \\\n",
       "Experiment_ID                                                                         \n",
       "resnet18_baseline                                                              <NA>   \n",
       "resnet50_baseline                                                              <NA>   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                             <NA>   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                             <NA>   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                             <NA>   \n",
       "\n",
       "                                                    Accuracy_Before_FT  \\\n",
       "Experiment_ID                                                            \n",
       "resnet18_baseline                                                  NaN   \n",
       "resnet50_baseline                                                  NaN   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                 NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                 NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                 NaN   \n",
       "\n",
       "                                                    Model_Size_MB_Disk  \\\n",
       "Experiment_ID                                                            \n",
       "resnet18_baseline                                              44.6696   \n",
       "resnet50_baseline                                              97.7961   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...             44.6673   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...             11.3021   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...             11.3008   \n",
       "\n",
       "                                                    Model_Size_MB_Log  ...  \\\n",
       "Experiment_ID                                                          ...   \n",
       "resnet18_baseline                                                 NaN  ...   \n",
       "resnet50_baseline                                                 NaN  ...   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...            44.6673  ...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...            11.3021  ...   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...            11.3008  ...   \n",
       "\n",
       "                                                    Baseline_Model_Size_MB_Disk  \\\n",
       "Experiment_ID                                                                     \n",
       "resnet18_baseline                                                       44.6696   \n",
       "resnet50_baseline                                                       97.7961   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                          NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                          NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                          NaN   \n",
       "\n",
       "                                                    Model_Size_Reduction_vs_Baseline_Percent  \\\n",
       "Experiment_ID                                                                                  \n",
       "resnet18_baseline                                                                     0.0000   \n",
       "resnet50_baseline                                                                     0.0000   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                                       NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                                       NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                                       NaN   \n",
       "\n",
       "                                                    Baseline_Params_Millions  \\\n",
       "Experiment_ID                                                                  \n",
       "resnet18_baseline                                                    11.6895   \n",
       "resnet50_baseline                                                    25.5570   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                       NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                       NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                       NaN   \n",
       "\n",
       "                                                    Params_Reduction_vs_Baseline_Percent  \\\n",
       "Experiment_ID                                                                              \n",
       "resnet18_baseline                                                                 0.0000   \n",
       "resnet50_baseline                                                                 0.0000   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                                   NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                                   NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                                   NaN   \n",
       "\n",
       "                                                    Baseline_FLOPs_GMACs  \\\n",
       "Experiment_ID                                                              \n",
       "resnet18_baseline                                                 1.8240   \n",
       "resnet50_baseline                                                 4.1337   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                   NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                   NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                   NaN   \n",
       "\n",
       "                                                    FLOPs_Reduction_vs_Baseline_Percent  \\\n",
       "Experiment_ID                                                                             \n",
       "resnet18_baseline                                                                0.0000   \n",
       "resnet50_baseline                                                                0.0000   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                                  NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                                  NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                                  NaN   \n",
       "\n",
       "                                                    Baseline_Inference_Time_ms_CPU  \\\n",
       "Experiment_ID                                                                        \n",
       "resnet18_baseline                                                          35.3137   \n",
       "resnet50_baseline                                                          88.0600   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                             NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                             NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                             NaN   \n",
       "\n",
       "                                                   Inference_Speedup_vs_Baseline_CPU  \\\n",
       "Experiment_ID                                                                          \n",
       "resnet18_baseline                                                             1.0000   \n",
       "resnet50_baseline                                                             1.0000   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                               NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                               NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                               NaN   \n",
       "\n",
       "                                                    Baseline_Inference_Time_ms_GPU  \\\n",
       "Experiment_ID                                                                        \n",
       "resnet18_baseline                                                           3.5235   \n",
       "resnet50_baseline                                                           7.8738   \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                             NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                             NaN   \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                             NaN   \n",
       "\n",
       "                                                    Inference_Speedup_vs_Baseline_GPU  \n",
       "Experiment_ID                                                                          \n",
       "resnet18_baseline                                                              1.0000  \n",
       "resnet50_baseline                                                              1.0000  \n",
       "resnet18pretrained_distilled_quant_kmeans_256cl...                                NaN  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                                NaN  \n",
       "resnet18pretrained_distilled_quant_ptq_int8_per...                                NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary saved to model_optimization_summary_notebook.csv ---\n",
      "Total experiments processed: 25\n",
      "\n",
      "--- Notebook processing finished ---\n"
     ]
    }
   ],
   "source": [
    "if not results_df.empty:\n",
    "    print(\"\\n--- Final DataFrame Review (First 5 rows) ---\")\n",
    "    # Convert relevant columns to numeric, coercing errors for display and consistent CSV.\n",
    "    # This helps if \"N/A\" strings are present from errors.\n",
    "    cols_to_numeric = [\n",
    "        'Final_Val_Accuracy', 'Model_Size_MB_Disk', 'Model_Size_MB_Log', \n",
    "        'Params_Millions', 'FLOPs_GMACs', 'Achieved_Sparsity_Percent',\n",
    "        'Inference_Time_ms_CPU (Batch 1)', 'Inference_Time_ms_GPU (Batch 1)',\n",
    "        'Baseline_Val_Accuracy', 'Accuracy_Change_vs_Baseline_pp', 'Accuracy_Retention_Percent',\n",
    "        'Baseline_Model_Size_MB_Disk', 'Model_Size_Reduction_vs_Baseline_Percent',\n",
    "        'Baseline_Params_Millions', 'Params_Reduction_vs_Baseline_Percent',\n",
    "        'Baseline_FLOPs_GMACs', 'FLOPs_Reduction_vs_Baseline_Percent',\n",
    "        'Baseline_Inference_Time_ms_CPU', 'Inference_Speedup_vs_Baseline_CPU',\n",
    "        'FT_Epochs_Run', 'FT_Time_seconds', 'Accuracy_Before_FT'\n",
    "    ]\n",
    "    if DEVICE.type == 'cuda':\n",
    "        cols_to_numeric.extend(['Baseline_Inference_Time_ms_GPU', 'Inference_Speedup_vs_Baseline_GPU'])\n",
    "\n",
    "    for col in cols_to_numeric:\n",
    "        if col in results_df.columns:\n",
    "            results_df[col] = pd.to_numeric(results_df[col], errors='coerce')\n",
    "\n",
    "\n",
    "    # Set float_format for to_string and to_csv\n",
    "    pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "    display(results_df.head())\n",
    "    \n",
    "    # Save to CSV\n",
    "    try:\n",
    "        results_df.to_csv(OUTPUT_CSV_NB, index=False, lineterminator='\\n', float_format='%.5f')\n",
    "        print(f\"\\n--- Summary saved to {OUTPUT_CSV_NB} ---\")\n",
    "        print(f\"Total experiments processed: {len(results_df)}\")\n",
    "    except Exception as e_csv:\n",
    "        print(f\"Error saving CSV: {e_csv}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty. Nothing to save.\")\n",
    "\n",
    "print(\"\\n--- Notebook processing finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
